{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://colab.research.google.com/drive/1dmgloT5ADF_6rH9t5FvK2MuwPPBKtm9d?usp=sharing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "More instructions and examples in the notebook\n",
    "The purpose of the project is to learn the mapping from polar coordinates to a a discrete 10x10 grid of cells in the plane, using a neural network.\n",
    "\n",
    "The supervised dataset is given to you in the form of a generator (to be considered as a black box).\n",
    "\n",
    "The model must achieve an accuracy of 95%, and it will be evaluated in a way **inversely proportional to the number of its parameters: the smaller, the better.**\n",
    "\n",
    "**WARNING**: Any solution taking advantage of meta-knowledge about the generator will be automatically rejected."
   ],
   "metadata": {
    "id": "Zw_326KLT9dF",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "id": "ynz-4_4cFmbJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the generator. It returns triples of the form ((theta,rho),out) where (theta,rho) are the polar coordinates of a point in the first quadrant of the plane, and out is a 10x10 map with \"1\" in the cell corresponding to the point position, and \"0\" everywhere else.\n",
    "\n",
    "By setting flat=True, the resulting map is flattened into a vector with a single dimension 100. You can use this variant, if you wish. "
   ],
   "metadata": {
    "id": "iA01pkKbUt7Q",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
    "  while True:\n",
    "    x = np.random.rand(batchsize)\n",
    "    y = np.random.rand(batchsize)\n",
    "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
    "    xc = (x*grid[0]).astype(int)\n",
    "    yc = (y*grid[1]).astype(int)\n",
    "    for b in range(batchsize):\n",
    "      out[b,xc[b],yc[b]] = 1\n",
    "    #compute rho and theta and add some noise\n",
    "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
    "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
    "    if flat:\n",
    "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
    "    yield ((theta,rho),out)"
   ],
   "metadata": {
    "id": "DsA1GqAeWAdo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 451,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create an instance of the generator on a grid with dimension 3x4"
   ],
   "metadata": {
    "id": "ZF-jlaqAWc2o",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "g1,g2 = 3,4\n",
    "gen = polar_generator(1,grid=(g1,g2),noise=0.0,flat=True)"
   ],
   "metadata": {
    "id": "Ov3rXaLVHDCT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 452,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now let's see a few samples."
   ],
   "metadata": {
    "id": "b4hntQtSWjPk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "(theta,rho),maps = next(gen)\n",
    "for i,map in enumerate(maps):\n",
    "  #let us compute the cartesian coordinates\n",
    "  x = np.cos(theta[i])*rho[i]\n",
    "  y = np.sin(theta[i])*rho[i]\n",
    "  print(\"x coordinate (row): {}\".format(int(x*g1)))\n",
    "  print(\"y coordinate (col): {}\".format(int(y*g2)))\n",
    "  print(\"map:\")\n",
    "  print(np.reshape(map,(g1,g2)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PM7R8ZZZHN7p",
    "outputId": "0bacea32-6460-43b0-f5c8-d5c9b5783d70",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 453,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x coordinate (row): 1\n",
      "y coordinate (col): 3\n",
      "map:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exercise: add noise to the generator, and check the effect on the \"ground truth\"."
   ],
   "metadata": {
    "id": "NTY5fu8Hg7RE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What to deliver\n",
    "\n",
    "For the purposes of the project you are supposed to work with the **default 10x10 grid, and the default noise=.002**\n",
    "\n",
    "The generator must be treatead as a black box, do not tweak it, and do not exploit its semantics that is supposed to be unknown. You are allowed to work with the \"flat\" modality, if you prefer so.\n",
    "\n",
    "You need to:\n",
    "1.   define an accuracy function (take inspiration from the code of the previous cell)\n",
    "2.   define a neural network taking in input theta and rho, and returning out\n",
    "3. measure the network's accuracy that must be above 95% (accuracy must be evaluated over at least 20000 samples)\n",
    "4. tune the network trying to decrease as much as possible the numer of parameters, preserving an accuracy above 95%. Only your best network must be delivered.\n",
    "\n",
    "You must deliver a SINGLE notebook working on colab, containing the code of the network, its summary, the training history, the code for the accurary metric and its evaluation on the network.\n",
    "\n",
    "**N.B.** The accuracy must be above 95% but apart from that it does not influence the evaluation. You score will only depend on the number of parameters: the lower, the better.\n",
    "\n",
    "#Good work!\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PROJECT\n",
    "\n",
    "In this project I created a neural network that takes in input theta and rho, and returns out.\n",
    "The network make use of the Transfer Learning technique, in order to reduce the number of parameters.\n",
    "I created one first model, capable of taking in input theta and rho, and returning 2 vectors indicating the row and the column of the 10x10 grid. These 2 vectors are represented as vectors of zeros with a single 1 in the position corresponding to the row and column of the 10x10 grid. Then I created a second model, that takes in input the 2 vectors and returns the 10x10 grid.\n",
    "Then I created a second model, that takes in input the output of the first model, and returns out as a map of 10x10.\n",
    "This is done by applying a Lambda layer, that takes in input the 2 vectors and returns the 10x10 flattened grid.\n",
    "This way, the output of the net is that required by the project, and the accuracy is not affected.\n",
    "\n",
    "So, for example, if we have the following map:\n",
    "  [0 0 0 0 1 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0\n",
    "   0 0 0 0 0 0 0 0 0 0]\n",
    "  the output of the first net will be y=[row, col] where:\n",
    "  row = [1 0 0 0 0 0 0 0 0 0]\n",
    "  col = [0 0 0 0 1 0 0 0 0 0]\n",
    "  but the general output (the output of the second model) will be the initial map.\n",
    "\n",
    "It is better to use the 2x10 representation in the first model instead of 10x10 to indicate rows and columns within a neural network because using a more specific representation can help prevent errors and improve the overall performance of the network.\n",
    "\n",
    "- **generate_data(num_samples)** generates dataset.\n",
    "  For every example it generates theta,rho and maps.\n",
    "  It then appends theta and rho as an array as the input of the net.\n",
    "  Maps the current maps item from array of 100 to 1 element (y_item) indicating the position of the element 1 in flat maps.\n",
    "  Then it calculates row and column of the 10x10 grid of the item.\n",
    "  Then it creates two arrays, one representing the row and the other representing the column, with a 1 in the corresponding index, and 0's elsewhere.\n",
    "  These two arrays are the output y of the first net.\n",
    "  grid is the flat map of 100 elements, with a 1 in the position of the element 1 in maps, and 0's elsewhere.\n",
    "  Finally, it returns the above-generated dataset returning the tuple <x,y, grid>.\n",
    "\n",
    "- **create_model(current_layers, dims)** creates a neural network model.\n",
    "  It takes in input two arguments: current_layers (the input layer of the model), dims (the dimensions of the hidden layers in the model).\n",
    "  The function then loops through the dims list, and for each hidden layer, it creates a Dense layer with the specified dimension, and the activation function 'swish'.\n",
    "  Then it creates two Dense layers with 10 neurons and 'softmax' activation function, called o1, o2, which are the output layers of the model corrispondent to the row and column of the 10x10 grid.\n",
    "  Finally, it creates a model with the input layer current_layers, and the two output layers o1, o2, and returns it.\n",
    "\n",
    "- **transform(tensor)** takes in input a tensor of shape 2x10 and applies a transformation on it.\n",
    "  It finds the maximum element's row and column position using tf.argmax() function, so it finds the position where 1 is stored in the tensor.\n",
    "  Then it creates a new tensor of shape [10,10] filled with zeros, with 1 on the position [row][col] using the tf.tensor_scatter_nd_update() function.\n",
    "  Finally, it returns the modified tensor as the output of the function.\n",
    "\n",
    "- **my_accuracy(y_true, y_pred)** calculates the accuracy of the model. It takes in input two arguments: y_true (the true output values of the dataset), y_pred (the predicted output values of the model)\n",
    "  The function uses the tf.argmax() function to find the index of the maximum element in both y_pred and y_true (i.e. in which position is 1).\n",
    "  Then it compares these indices using the tf.equal() function to determine if the model's prediction was correct.\n",
    "  The method reduce_all is used to check if the prediction of both row and col was correct, instead considering them as 2 different examples.\n",
    "  It then cast the resulting boolean tensor to the mean of this tensor, this mean represents the accuracy of the model.\n",
    "  It returns this accuracy as the output of the function.\n",
    "\n",
    "- **my_accuracy(y_true, y_pred)** calculates the accuracy of the second model. It takes in input two arguments: y_true (the true output values of the dataset), y_pred (the predicted output values of the model)\n",
    "  The function uses the tf.argmax() function to find the index of the maximum element in both y_pred and y_true (i.e. in which position is 1).\n",
    "  Then it compares these indices using the tf.equal() function to determine if the model's prediction was correct.\n",
    "  The difference here is that the model's output is a tensor of shape [100] and no more a tensor of shape [2,10], so we don't need to use the reduce_all method.\n",
    "  It then cast the resulting boolean tensor to the mean of this tensor, this mean represents the accuracy of the model.\n",
    "  It returns this accuracy as the output of the function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generates dataset\n",
    "def generate_data_grid(num_samples):\n",
    "  x = []\n",
    "  y = []\n",
    "  grid = []\n",
    "  gen = polar_generator(1,grid=(10,10),noise=0.002,flat=True)\n",
    "  for i in range(num_samples):\n",
    "    (theta,rho),maps = next(gen)\n",
    "    x_item = np.array([theta[0], rho[0]])\n",
    "    x.append(x_item)\n",
    "    y_item = maps[0] # maps from float to int\n",
    "    y_item = np.where(y_item==1)[0] # maps from array of 100 to 1 element\n",
    "    row = ((y_item) / 10)[0].astype(int) # calculates row of the 10x10 grid\n",
    "    col = ((y_item) % 10)[0] # calculates col of the 10x10 grid\n",
    "    r = np.zeros(10)\n",
    "    r[row] = 1\n",
    "    c = np.zeros(10)\n",
    "    c[col] = 1\n",
    "    y_item = np.array([r, c])\n",
    "    y.append(y_item)\n",
    "    grid.append(maps[0])\n",
    "  return np.array(x), np.array(y), np.array(grid)\n",
    "\n",
    "'''\n",
    "x_prova, y_prova, grid_prova = [], [], []\n",
    "x_prova, y_prova, grid_prova = generate_data_grid(2)\n",
    "grid_prova = tf.reshape(grid_prova, [2,10,10])\n",
    "# test to print some generated data\n",
    "for i in range(2):\n",
    "  #print(\"x_train[\", i, \"] = \", x_prova[i])\n",
    "  print(\"y_train[\", i, \"] = \", y_prova[i])\n",
    "  print(\"grid_train[\", i, \"] = \", grid_prova[i])\n",
    "print(\"x_train.shape = \", x_prova.shape)\n",
    "print(\"y_train.shape = \", y_prova.shape)\n",
    "print(\"grid_train.shape = \", grid_prova.shape)\n",
    "'''\n",
    "\n",
    "\n",
    "# create the first model\n",
    "def create_model(current_layers, dims):\n",
    "  for i in range(0,len(dims)):\n",
    "    current_layers = Dense(dims[i], activation='swish')(current_layers)\n",
    "  o1 = Dense(10, activation='softmax')(current_layers)\n",
    "  o2 = Dense(10, activation='softmax')(current_layers)\n",
    "  out = tf.stack([o1, o2], axis=1)\n",
    "  return out\n",
    "\n",
    "# trasform tensor from tensors row and col to one_hot grid 10x10 with 1 in [row, col] position\n",
    "def transform(tensor):\n",
    "  row = tf.cast(tf.argmax(tensor[:, 0], axis=-1), dtype=tf.int32)\n",
    "  col = tf.cast(tf.argmax(tensor[:, 1], axis=-1), dtype=tf.int32)\n",
    "  one_hot = tf.cast(tf.one_hot(row*10+col, 100), dtype=tf.float32)\n",
    "  return one_hot\n",
    "\n",
    "'''\n",
    "# test transform with a tensor\n",
    "x_test = tf.constant([[[1,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,1]],[[0,0,0,0,0,0,0,0,0,1],[0,0,0,0,0,0,0,0,0,1]]])\n",
    "print(\"transform(x_test): \", transform(x_test))\n",
    "'''\n",
    "\n",
    "\n",
    "# accuracy for the first model\n",
    "def my_accuracy(y_true, y_pred):\n",
    "  correct_predictions = tf.equal(tf.argmax(y_pred, -1), tf.argmax(y_true, -1))\n",
    "  correct_predictions = tf.reduce_all(correct_predictions, axis=1)\n",
    "  return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "# accuracy for the second model\n",
    "def my_accuracy_grid(y_true, y_pred):\n",
    "  correct_predictions = tf.equal(tf.argmax(y_pred, axis=1), tf.argmax(y_true, axis=1))\n",
    "  return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "'''\n",
    "# generate some examples to use accuracy\n",
    "labels = tf.constant([[[1,0,0,0,0,0,0,0,0,0], [0,0,1,0,0,0,0,0,0,0]]])\n",
    "predictions = tf.constant([[[1,0,0,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0,0,0]]])\n",
    "tf.print(\"accuracy: \", my_accuracy(labels, predictions))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x_train and y_train are the training dataset\n",
    "x_train, y_train, _ = generate_data_grid(80000)\n",
    "\n",
    "\"\"\"\n",
    "# test to print some generated data\n",
    "for i in range(3):\n",
    "  print(\"x_train[\", i, \"] = \", x_train[i])\n",
    "  print(\"y_train[\", i, \"] = \", y_train[i])\n",
    "print(\"x_train.shape = \", x_train.shape)\n",
    "print(\"y_train.shape = \", y_train.shape)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(2,))\n",
    "# size of hidden layers (one for each of them)\n",
    "inner_layers_dims = [5,3]\n",
    "layers = create_model(input_layer, inner_layers_dims)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "outputs": [],
   "source": [
    "first_model = Model(inputs=input_layer,outputs=layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 5)            15          ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 3)            18          ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_170 (Dense)              (None, 10)           40          ['dense_169[0][0]']              \n",
      "                                                                                                  \n",
      " dense_171 (Dense)              (None, 10)           40          ['dense_169[0][0]']              \n",
      "                                                                                                  \n",
      " tf.stack_30 (TFOpLambda)       (None, 2, 10)        0           ['dense_170[0][0]',              \n",
      "                                                                  'dense_171[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "first_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [],
   "source": [
    "my_optimizer = Adam(learning_rate=0.01)\n",
    "first_model.compile(optimizer=my_optimizer, loss=['categorical_crossentropy'], metrics=my_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "125/125 - 2s - loss: 2.0123 - my_accuracy: 0.0310 - val_loss: 1.7227 - val_my_accuracy: 0.0623 - 2s/epoch - 17ms/step\n",
      "Epoch 2/1000\n",
      "125/125 - 1s - loss: 1.3153 - my_accuracy: 0.1815 - val_loss: 1.0338 - val_my_accuracy: 0.2879 - 502ms/epoch - 4ms/step\n",
      "Epoch 3/1000\n",
      "125/125 - 1s - loss: 0.9403 - my_accuracy: 0.3313 - val_loss: 0.8758 - val_my_accuracy: 0.3776 - 519ms/epoch - 4ms/step\n",
      "Epoch 4/1000\n",
      "125/125 - 1s - loss: 0.8115 - my_accuracy: 0.4420 - val_loss: 0.7752 - val_my_accuracy: 0.4913 - 527ms/epoch - 4ms/step\n",
      "Epoch 5/1000\n",
      "125/125 - 1s - loss: 0.7295 - my_accuracy: 0.5132 - val_loss: 0.6965 - val_my_accuracy: 0.5610 - 519ms/epoch - 4ms/step\n",
      "Epoch 6/1000\n",
      "125/125 - 0s - loss: 0.6615 - my_accuracy: 0.5670 - val_loss: 0.6366 - val_my_accuracy: 0.5779 - 458ms/epoch - 4ms/step\n",
      "Epoch 7/1000\n",
      "125/125 - 0s - loss: 0.6013 - my_accuracy: 0.6121 - val_loss: 0.5745 - val_my_accuracy: 0.6472 - 491ms/epoch - 4ms/step\n",
      "Epoch 8/1000\n",
      "125/125 - 0s - loss: 0.5449 - my_accuracy: 0.6658 - val_loss: 0.5227 - val_my_accuracy: 0.6875 - 453ms/epoch - 4ms/step\n",
      "Epoch 9/1000\n",
      "125/125 - 0s - loss: 0.4967 - my_accuracy: 0.7076 - val_loss: 0.4792 - val_my_accuracy: 0.7314 - 409ms/epoch - 3ms/step\n",
      "Epoch 10/1000\n",
      "125/125 - 0s - loss: 0.4537 - my_accuracy: 0.7458 - val_loss: 0.4406 - val_my_accuracy: 0.7664 - 424ms/epoch - 3ms/step\n",
      "Epoch 11/1000\n",
      "125/125 - 0s - loss: 0.4201 - my_accuracy: 0.7664 - val_loss: 0.4130 - val_my_accuracy: 0.7673 - 393ms/epoch - 3ms/step\n",
      "Epoch 12/1000\n",
      "125/125 - 0s - loss: 0.3924 - my_accuracy: 0.7787 - val_loss: 0.3802 - val_my_accuracy: 0.7925 - 432ms/epoch - 3ms/step\n",
      "Epoch 13/1000\n",
      "125/125 - 0s - loss: 0.3666 - my_accuracy: 0.7941 - val_loss: 0.3648 - val_my_accuracy: 0.7832 - 442ms/epoch - 4ms/step\n",
      "Epoch 14/1000\n",
      "125/125 - 1s - loss: 0.3496 - my_accuracy: 0.7967 - val_loss: 0.3373 - val_my_accuracy: 0.8126 - 547ms/epoch - 4ms/step\n",
      "Epoch 15/1000\n",
      "125/125 - 0s - loss: 0.3322 - my_accuracy: 0.8028 - val_loss: 0.3314 - val_my_accuracy: 0.7878 - 494ms/epoch - 4ms/step\n",
      "Epoch 16/1000\n",
      "125/125 - 1s - loss: 0.3193 - my_accuracy: 0.8060 - val_loss: 0.3137 - val_my_accuracy: 0.8090 - 626ms/epoch - 5ms/step\n",
      "Epoch 17/1000\n",
      "125/125 - 0s - loss: 0.3050 - my_accuracy: 0.8139 - val_loss: 0.3044 - val_my_accuracy: 0.8123 - 462ms/epoch - 4ms/step\n",
      "Epoch 18/1000\n",
      "125/125 - 0s - loss: 0.2952 - my_accuracy: 0.8138 - val_loss: 0.2922 - val_my_accuracy: 0.8148 - 428ms/epoch - 3ms/step\n",
      "Epoch 19/1000\n",
      "125/125 - 0s - loss: 0.2853 - my_accuracy: 0.8220 - val_loss: 0.2780 - val_my_accuracy: 0.8350 - 429ms/epoch - 3ms/step\n",
      "Epoch 20/1000\n",
      "125/125 - 0s - loss: 0.2774 - my_accuracy: 0.8240 - val_loss: 0.2770 - val_my_accuracy: 0.8262 - 413ms/epoch - 3ms/step\n",
      "Epoch 21/1000\n",
      "125/125 - 0s - loss: 0.2699 - my_accuracy: 0.8271 - val_loss: 0.2663 - val_my_accuracy: 0.8303 - 436ms/epoch - 3ms/step\n",
      "Epoch 22/1000\n",
      "125/125 - 0s - loss: 0.2624 - my_accuracy: 0.8314 - val_loss: 0.2593 - val_my_accuracy: 0.8322 - 418ms/epoch - 3ms/step\n",
      "Epoch 23/1000\n",
      "125/125 - 0s - loss: 0.2560 - my_accuracy: 0.8359 - val_loss: 0.2593 - val_my_accuracy: 0.8299 - 455ms/epoch - 4ms/step\n",
      "Epoch 24/1000\n",
      "125/125 - 0s - loss: 0.2498 - my_accuracy: 0.8385 - val_loss: 0.2451 - val_my_accuracy: 0.8427 - 440ms/epoch - 4ms/step\n",
      "Epoch 25/1000\n",
      "125/125 - 0s - loss: 0.2433 - my_accuracy: 0.8448 - val_loss: 0.2400 - val_my_accuracy: 0.8518 - 491ms/epoch - 4ms/step\n",
      "Epoch 26/1000\n",
      "125/125 - 1s - loss: 0.2395 - my_accuracy: 0.8422 - val_loss: 0.2472 - val_my_accuracy: 0.8304 - 543ms/epoch - 4ms/step\n",
      "Epoch 27/1000\n",
      "125/125 - 1s - loss: 0.2366 - my_accuracy: 0.8429 - val_loss: 0.2346 - val_my_accuracy: 0.8483 - 555ms/epoch - 4ms/step\n",
      "Epoch 28/1000\n",
      "125/125 - 1s - loss: 0.2295 - my_accuracy: 0.8520 - val_loss: 0.2346 - val_my_accuracy: 0.8398 - 803ms/epoch - 6ms/step\n",
      "Epoch 29/1000\n",
      "125/125 - 1s - loss: 0.2271 - my_accuracy: 0.8508 - val_loss: 0.2337 - val_my_accuracy: 0.8410 - 738ms/epoch - 6ms/step\n",
      "Epoch 30/1000\n",
      "125/125 - 1s - loss: 0.2210 - my_accuracy: 0.8567 - val_loss: 0.2252 - val_my_accuracy: 0.8525 - 506ms/epoch - 4ms/step\n",
      "Epoch 31/1000\n",
      "125/125 - 0s - loss: 0.2206 - my_accuracy: 0.8522 - val_loss: 0.2274 - val_my_accuracy: 0.8506 - 492ms/epoch - 4ms/step\n",
      "Epoch 32/1000\n",
      "125/125 - 0s - loss: 0.2162 - my_accuracy: 0.8561 - val_loss: 0.2142 - val_my_accuracy: 0.8598 - 479ms/epoch - 4ms/step\n",
      "Epoch 33/1000\n",
      "125/125 - 0s - loss: 0.2129 - my_accuracy: 0.8565 - val_loss: 0.2141 - val_my_accuracy: 0.8499 - 400ms/epoch - 3ms/step\n",
      "Epoch 34/1000\n",
      "125/125 - 0s - loss: 0.2082 - my_accuracy: 0.8616 - val_loss: 0.2159 - val_my_accuracy: 0.8588 - 415ms/epoch - 3ms/step\n",
      "Epoch 35/1000\n",
      "125/125 - 0s - loss: 0.2043 - my_accuracy: 0.8655 - val_loss: 0.2035 - val_my_accuracy: 0.8671 - 438ms/epoch - 4ms/step\n",
      "Epoch 36/1000\n",
      "125/125 - 0s - loss: 0.2030 - my_accuracy: 0.8636 - val_loss: 0.2067 - val_my_accuracy: 0.8611 - 431ms/epoch - 3ms/step\n",
      "Epoch 37/1000\n",
      "125/125 - 0s - loss: 0.1987 - my_accuracy: 0.8694 - val_loss: 0.2058 - val_my_accuracy: 0.8586 - 441ms/epoch - 4ms/step\n",
      "Epoch 38/1000\n",
      "125/125 - 0s - loss: 0.1970 - my_accuracy: 0.8677 - val_loss: 0.2034 - val_my_accuracy: 0.8659 - 477ms/epoch - 4ms/step\n",
      "Epoch 39/1000\n",
      "125/125 - 0s - loss: 0.1958 - my_accuracy: 0.8675 - val_loss: 0.2067 - val_my_accuracy: 0.8554 - 416ms/epoch - 3ms/step\n",
      "Epoch 40/1000\n",
      "125/125 - 0s - loss: 0.1930 - my_accuracy: 0.8709 - val_loss: 0.1893 - val_my_accuracy: 0.8783 - 423ms/epoch - 3ms/step\n",
      "Epoch 41/1000\n",
      "125/125 - 1s - loss: 0.1908 - my_accuracy: 0.8705 - val_loss: 0.1889 - val_my_accuracy: 0.8821 - 594ms/epoch - 5ms/step\n",
      "Epoch 42/1000\n",
      "125/125 - 1s - loss: 0.1864 - my_accuracy: 0.8771 - val_loss: 0.1981 - val_my_accuracy: 0.8604 - 574ms/epoch - 5ms/step\n",
      "Epoch 43/1000\n",
      "125/125 - 0s - loss: 0.1843 - my_accuracy: 0.8765 - val_loss: 0.1834 - val_my_accuracy: 0.8812 - 469ms/epoch - 4ms/step\n",
      "Epoch 44/1000\n",
      "125/125 - 0s - loss: 0.1829 - my_accuracy: 0.8780 - val_loss: 0.1821 - val_my_accuracy: 0.8799 - 400ms/epoch - 3ms/step\n",
      "Epoch 45/1000\n",
      "125/125 - 0s - loss: 0.1816 - my_accuracy: 0.8762 - val_loss: 0.1885 - val_my_accuracy: 0.8663 - 398ms/epoch - 3ms/step\n",
      "Epoch 46/1000\n",
      "125/125 - 0s - loss: 0.1798 - my_accuracy: 0.8770 - val_loss: 0.1896 - val_my_accuracy: 0.8644 - 419ms/epoch - 3ms/step\n",
      "Epoch 47/1000\n",
      "125/125 - 0s - loss: 0.1792 - my_accuracy: 0.8761 - val_loss: 0.1821 - val_my_accuracy: 0.8687 - 411ms/epoch - 3ms/step\n",
      "Epoch 48/1000\n",
      "125/125 - 0s - loss: 0.1755 - my_accuracy: 0.8803 - val_loss: 0.1766 - val_my_accuracy: 0.8811 - 408ms/epoch - 3ms/step\n",
      "Epoch 49/1000\n",
      "125/125 - 0s - loss: 0.1756 - my_accuracy: 0.8796 - val_loss: 0.1855 - val_my_accuracy: 0.8654 - 426ms/epoch - 3ms/step\n",
      "Epoch 50/1000\n",
      "125/125 - 0s - loss: 0.1727 - my_accuracy: 0.8829 - val_loss: 0.1691 - val_my_accuracy: 0.8912 - 427ms/epoch - 3ms/step\n",
      "Epoch 51/1000\n",
      "125/125 - 0s - loss: 0.1702 - my_accuracy: 0.8848 - val_loss: 0.1763 - val_my_accuracy: 0.8759 - 431ms/epoch - 3ms/step\n",
      "Epoch 52/1000\n",
      "125/125 - 0s - loss: 0.1694 - my_accuracy: 0.8834 - val_loss: 0.1697 - val_my_accuracy: 0.8836 - 435ms/epoch - 3ms/step\n",
      "Epoch 53/1000\n",
      "125/125 - 0s - loss: 0.1679 - my_accuracy: 0.8852 - val_loss: 0.1663 - val_my_accuracy: 0.8910 - 407ms/epoch - 3ms/step\n",
      "Epoch 54/1000\n",
      "125/125 - 1s - loss: 0.1666 - my_accuracy: 0.8856 - val_loss: 0.1699 - val_my_accuracy: 0.8785 - 546ms/epoch - 4ms/step\n",
      "Epoch 55/1000\n",
      "125/125 - 0s - loss: 0.1639 - my_accuracy: 0.8885 - val_loss: 0.1640 - val_my_accuracy: 0.8910 - 485ms/epoch - 4ms/step\n",
      "Epoch 56/1000\n",
      "125/125 - 0s - loss: 0.1660 - my_accuracy: 0.8841 - val_loss: 0.1667 - val_my_accuracy: 0.8807 - 425ms/epoch - 3ms/step\n",
      "Epoch 57/1000\n",
      "125/125 - 0s - loss: 0.1624 - my_accuracy: 0.8875 - val_loss: 0.1660 - val_my_accuracy: 0.8788 - 438ms/epoch - 4ms/step\n",
      "Epoch 58/1000\n",
      "125/125 - 0s - loss: 0.1622 - my_accuracy: 0.8861 - val_loss: 0.1747 - val_my_accuracy: 0.8719 - 420ms/epoch - 3ms/step\n",
      "Epoch 59/1000\n",
      "125/125 - 0s - loss: 0.1586 - my_accuracy: 0.8918 - val_loss: 0.1654 - val_my_accuracy: 0.8815 - 402ms/epoch - 3ms/step\n",
      "Epoch 60/1000\n",
      "125/125 - 1s - loss: 0.1619 - my_accuracy: 0.8843 - val_loss: 0.1593 - val_my_accuracy: 0.8864 - 575ms/epoch - 5ms/step\n",
      "Epoch 61/1000\n",
      "125/125 - 1s - loss: 0.1574 - my_accuracy: 0.8896 - val_loss: 0.1567 - val_my_accuracy: 0.8918 - 594ms/epoch - 5ms/step\n",
      "Epoch 62/1000\n",
      "125/125 - 0s - loss: 0.1551 - my_accuracy: 0.8928 - val_loss: 0.1600 - val_my_accuracy: 0.8814 - 463ms/epoch - 4ms/step\n",
      "Epoch 63/1000\n",
      "125/125 - 0s - loss: 0.1559 - my_accuracy: 0.8912 - val_loss: 0.1553 - val_my_accuracy: 0.8897 - 459ms/epoch - 4ms/step\n",
      "Epoch 64/1000\n",
      "125/125 - 0s - loss: 0.1549 - my_accuracy: 0.8913 - val_loss: 0.1551 - val_my_accuracy: 0.8894 - 478ms/epoch - 4ms/step\n",
      "Epoch 65/1000\n",
      "125/125 - 0s - loss: 0.1541 - my_accuracy: 0.8913 - val_loss: 0.1496 - val_my_accuracy: 0.8984 - 462ms/epoch - 4ms/step\n",
      "Epoch 66/1000\n",
      "125/125 - 0s - loss: 0.1524 - my_accuracy: 0.8930 - val_loss: 0.1585 - val_my_accuracy: 0.8806 - 447ms/epoch - 4ms/step\n",
      "Epoch 67/1000\n",
      "125/125 - 0s - loss: 0.1529 - my_accuracy: 0.8908 - val_loss: 0.1532 - val_my_accuracy: 0.8957 - 467ms/epoch - 4ms/step\n",
      "Epoch 68/1000\n",
      "125/125 - 0s - loss: 0.1509 - my_accuracy: 0.8945 - val_loss: 0.1513 - val_my_accuracy: 0.8903 - 455ms/epoch - 4ms/step\n",
      "Epoch 69/1000\n",
      "125/125 - 0s - loss: 0.1502 - my_accuracy: 0.8938 - val_loss: 0.1505 - val_my_accuracy: 0.8923 - 419ms/epoch - 3ms/step\n",
      "Epoch 70/1000\n",
      "125/125 - 0s - loss: 0.1478 - my_accuracy: 0.8957 - val_loss: 0.1473 - val_my_accuracy: 0.8981 - 447ms/epoch - 4ms/step\n",
      "Epoch 71/1000\n",
      "125/125 - 1s - loss: 0.1475 - my_accuracy: 0.8950 - val_loss: 0.1527 - val_my_accuracy: 0.8864 - 538ms/epoch - 4ms/step\n",
      "Epoch 72/1000\n",
      "125/125 - 0s - loss: 0.1483 - my_accuracy: 0.8928 - val_loss: 0.1504 - val_my_accuracy: 0.8907 - 457ms/epoch - 4ms/step\n",
      "Epoch 73/1000\n",
      "125/125 - 0s - loss: 0.1486 - my_accuracy: 0.8922 - val_loss: 0.1495 - val_my_accuracy: 0.8964 - 446ms/epoch - 4ms/step\n",
      "Epoch 74/1000\n",
      "125/125 - 1s - loss: 0.1475 - my_accuracy: 0.8932 - val_loss: 0.1441 - val_my_accuracy: 0.8964 - 553ms/epoch - 4ms/step\n",
      "Epoch 75/1000\n",
      "125/125 - 0s - loss: 0.1465 - my_accuracy: 0.8933 - val_loss: 0.1458 - val_my_accuracy: 0.8947 - 438ms/epoch - 4ms/step\n",
      "Epoch 76/1000\n",
      "125/125 - 0s - loss: 0.1442 - my_accuracy: 0.8963 - val_loss: 0.1452 - val_my_accuracy: 0.8968 - 458ms/epoch - 4ms/step\n",
      "Epoch 77/1000\n",
      "125/125 - 0s - loss: 0.1436 - my_accuracy: 0.8971 - val_loss: 0.1411 - val_my_accuracy: 0.9003 - 456ms/epoch - 4ms/step\n",
      "Epoch 78/1000\n",
      "125/125 - 0s - loss: 0.1417 - my_accuracy: 0.8978 - val_loss: 0.1406 - val_my_accuracy: 0.8998 - 472ms/epoch - 4ms/step\n",
      "Epoch 79/1000\n",
      "125/125 - 0s - loss: 0.1420 - my_accuracy: 0.8982 - val_loss: 0.1414 - val_my_accuracy: 0.9025 - 444ms/epoch - 4ms/step\n",
      "Epoch 80/1000\n",
      "125/125 - 0s - loss: 0.1410 - my_accuracy: 0.8987 - val_loss: 0.1470 - val_my_accuracy: 0.8871 - 450ms/epoch - 4ms/step\n",
      "Epoch 81/1000\n",
      "125/125 - 0s - loss: 0.1419 - my_accuracy: 0.8960 - val_loss: 0.1500 - val_my_accuracy: 0.8901 - 451ms/epoch - 4ms/step\n",
      "Epoch 82/1000\n",
      "125/125 - 0s - loss: 0.1383 - my_accuracy: 0.9010 - val_loss: 0.1366 - val_my_accuracy: 0.9002 - 478ms/epoch - 4ms/step\n",
      "Epoch 83/1000\n",
      "125/125 - 1s - loss: 0.1392 - my_accuracy: 0.8993 - val_loss: 0.1366 - val_my_accuracy: 0.9033 - 514ms/epoch - 4ms/step\n",
      "Epoch 84/1000\n",
      "125/125 - 0s - loss: 0.1382 - my_accuracy: 0.8998 - val_loss: 0.1392 - val_my_accuracy: 0.8997 - 455ms/epoch - 4ms/step\n",
      "Epoch 85/1000\n",
      "125/125 - 0s - loss: 0.1392 - my_accuracy: 0.8986 - val_loss: 0.1346 - val_my_accuracy: 0.9062 - 449ms/epoch - 4ms/step\n",
      "Epoch 86/1000\n",
      "125/125 - 0s - loss: 0.1374 - my_accuracy: 0.8998 - val_loss: 0.1481 - val_my_accuracy: 0.8855 - 485ms/epoch - 4ms/step\n",
      "Epoch 87/1000\n",
      "125/125 - 0s - loss: 0.1400 - my_accuracy: 0.8957 - val_loss: 0.1370 - val_my_accuracy: 0.9009 - 489ms/epoch - 4ms/step\n",
      "Epoch 88/1000\n",
      "125/125 - 0s - loss: 0.1371 - my_accuracy: 0.8985 - val_loss: 0.1401 - val_my_accuracy: 0.8958 - 497ms/epoch - 4ms/step\n",
      "Epoch 89/1000\n",
      "125/125 - 0s - loss: 0.1360 - my_accuracy: 0.9001 - val_loss: 0.1407 - val_my_accuracy: 0.8959 - 430ms/epoch - 3ms/step\n",
      "Epoch 90/1000\n",
      "125/125 - 0s - loss: 0.1364 - my_accuracy: 0.8997 - val_loss: 0.1320 - val_my_accuracy: 0.9039 - 460ms/epoch - 4ms/step\n",
      "Epoch 91/1000\n",
      "125/125 - 0s - loss: 0.1357 - my_accuracy: 0.8999 - val_loss: 0.1288 - val_my_accuracy: 0.9119 - 455ms/epoch - 4ms/step\n",
      "Epoch 92/1000\n",
      "125/125 - 0s - loss: 0.1329 - my_accuracy: 0.9027 - val_loss: 0.1334 - val_my_accuracy: 0.9020 - 452ms/epoch - 4ms/step\n",
      "Epoch 93/1000\n",
      "125/125 - 0s - loss: 0.1314 - my_accuracy: 0.9063 - val_loss: 0.1392 - val_my_accuracy: 0.8953 - 435ms/epoch - 3ms/step\n",
      "Epoch 94/1000\n",
      "125/125 - 0s - loss: 0.1313 - my_accuracy: 0.9042 - val_loss: 0.1342 - val_my_accuracy: 0.9044 - 435ms/epoch - 3ms/step\n",
      "Epoch 95/1000\n",
      "125/125 - 0s - loss: 0.1330 - my_accuracy: 0.9003 - val_loss: 0.1346 - val_my_accuracy: 0.9020 - 414ms/epoch - 3ms/step\n",
      "Epoch 96/1000\n",
      "125/125 - 0s - loss: 0.1311 - my_accuracy: 0.9038 - val_loss: 0.1371 - val_my_accuracy: 0.8978 - 410ms/epoch - 3ms/step\n",
      "Epoch 97/1000\n",
      "125/125 - 0s - loss: 0.1276 - my_accuracy: 0.9078 - val_loss: 0.1313 - val_my_accuracy: 0.9055 - 410ms/epoch - 3ms/step\n",
      "Epoch 98/1000\n",
      "125/125 - 0s - loss: 0.1306 - my_accuracy: 0.9045 - val_loss: 0.1327 - val_my_accuracy: 0.9015 - 459ms/epoch - 4ms/step\n",
      "Epoch 99/1000\n",
      "125/125 - 0s - loss: 0.1292 - my_accuracy: 0.9050 - val_loss: 0.1294 - val_my_accuracy: 0.9060 - 442ms/epoch - 4ms/step\n",
      "Epoch 100/1000\n",
      "125/125 - 0s - loss: 0.1305 - my_accuracy: 0.9039 - val_loss: 0.1318 - val_my_accuracy: 0.9041 - 426ms/epoch - 3ms/step\n",
      "Epoch 101/1000\n",
      "125/125 - 0s - loss: 0.1291 - my_accuracy: 0.9028 - val_loss: 0.1350 - val_my_accuracy: 0.8975 - 441ms/epoch - 4ms/step\n",
      "Epoch 102/1000\n",
      "125/125 - 0s - loss: 0.1297 - my_accuracy: 0.9031 - val_loss: 0.1287 - val_my_accuracy: 0.9056 - 482ms/epoch - 4ms/step\n",
      "Epoch 103/1000\n",
      "125/125 - 0s - loss: 0.1264 - my_accuracy: 0.9069 - val_loss: 0.1283 - val_my_accuracy: 0.9065 - 410ms/epoch - 3ms/step\n",
      "Epoch 104/1000\n",
      "125/125 - 0s - loss: 0.1287 - my_accuracy: 0.9044 - val_loss: 0.1287 - val_my_accuracy: 0.9050 - 437ms/epoch - 3ms/step\n",
      "Epoch 105/1000\n",
      "125/125 - 0s - loss: 0.1254 - my_accuracy: 0.9083 - val_loss: 0.1242 - val_my_accuracy: 0.9089 - 416ms/epoch - 3ms/step\n",
      "Epoch 106/1000\n",
      "125/125 - 0s - loss: 0.1250 - my_accuracy: 0.9069 - val_loss: 0.1249 - val_my_accuracy: 0.9061 - 481ms/epoch - 4ms/step\n",
      "Epoch 107/1000\n",
      "125/125 - 0s - loss: 0.1222 - my_accuracy: 0.9114 - val_loss: 0.1222 - val_my_accuracy: 0.9131 - 415ms/epoch - 3ms/step\n",
      "Epoch 108/1000\n",
      "125/125 - 1s - loss: 0.1238 - my_accuracy: 0.9083 - val_loss: 0.1326 - val_my_accuracy: 0.9031 - 528ms/epoch - 4ms/step\n",
      "Epoch 109/1000\n",
      "125/125 - 1s - loss: 0.1249 - my_accuracy: 0.9084 - val_loss: 0.1210 - val_my_accuracy: 0.9177 - 523ms/epoch - 4ms/step\n",
      "Epoch 110/1000\n",
      "125/125 - 0s - loss: 0.1240 - my_accuracy: 0.9085 - val_loss: 0.1252 - val_my_accuracy: 0.9068 - 474ms/epoch - 4ms/step\n",
      "Epoch 111/1000\n",
      "125/125 - 0s - loss: 0.1213 - my_accuracy: 0.9110 - val_loss: 0.1225 - val_my_accuracy: 0.9123 - 459ms/epoch - 4ms/step\n",
      "Epoch 112/1000\n",
      "125/125 - 1s - loss: 0.1227 - my_accuracy: 0.9094 - val_loss: 0.1185 - val_my_accuracy: 0.9149 - 504ms/epoch - 4ms/step\n",
      "Epoch 113/1000\n",
      "125/125 - 1s - loss: 0.1211 - my_accuracy: 0.9123 - val_loss: 0.1252 - val_my_accuracy: 0.9075 - 541ms/epoch - 4ms/step\n",
      "Epoch 114/1000\n",
      "125/125 - 0s - loss: 0.1217 - my_accuracy: 0.9096 - val_loss: 0.1240 - val_my_accuracy: 0.9106 - 464ms/epoch - 4ms/step\n",
      "Epoch 115/1000\n",
      "125/125 - 0s - loss: 0.1191 - my_accuracy: 0.9137 - val_loss: 0.1196 - val_my_accuracy: 0.9129 - 421ms/epoch - 3ms/step\n",
      "Epoch 116/1000\n",
      "125/125 - 0s - loss: 0.1203 - my_accuracy: 0.9100 - val_loss: 0.1162 - val_my_accuracy: 0.9173 - 445ms/epoch - 4ms/step\n",
      "Epoch 117/1000\n",
      "125/125 - 0s - loss: 0.1219 - my_accuracy: 0.9083 - val_loss: 0.1125 - val_my_accuracy: 0.9222 - 446ms/epoch - 4ms/step\n",
      "Epoch 118/1000\n",
      "125/125 - 1s - loss: 0.1179 - my_accuracy: 0.9132 - val_loss: 0.1206 - val_my_accuracy: 0.9109 - 544ms/epoch - 4ms/step\n",
      "Epoch 119/1000\n",
      "125/125 - 0s - loss: 0.1195 - my_accuracy: 0.9097 - val_loss: 0.1211 - val_my_accuracy: 0.9101 - 452ms/epoch - 4ms/step\n",
      "Epoch 120/1000\n",
      "125/125 - 0s - loss: 0.1170 - my_accuracy: 0.9143 - val_loss: 0.1138 - val_my_accuracy: 0.9198 - 423ms/epoch - 3ms/step\n",
      "Epoch 121/1000\n",
      "125/125 - 0s - loss: 0.1178 - my_accuracy: 0.9133 - val_loss: 0.1216 - val_my_accuracy: 0.9086 - 437ms/epoch - 3ms/step\n",
      "Epoch 122/1000\n",
      "125/125 - 0s - loss: 0.1182 - my_accuracy: 0.9132 - val_loss: 0.1112 - val_my_accuracy: 0.9211 - 452ms/epoch - 4ms/step\n",
      "Epoch 123/1000\n",
      "125/125 - 0s - loss: 0.1171 - my_accuracy: 0.9134 - val_loss: 0.1188 - val_my_accuracy: 0.9134 - 467ms/epoch - 4ms/step\n",
      "Epoch 124/1000\n",
      "125/125 - 0s - loss: 0.1162 - my_accuracy: 0.9148 - val_loss: 0.1158 - val_my_accuracy: 0.9139 - 448ms/epoch - 4ms/step\n",
      "Epoch 125/1000\n",
      "125/125 - 0s - loss: 0.1151 - my_accuracy: 0.9149 - val_loss: 0.1177 - val_my_accuracy: 0.9098 - 445ms/epoch - 4ms/step\n",
      "Epoch 126/1000\n",
      "125/125 - 0s - loss: 0.1149 - my_accuracy: 0.9151 - val_loss: 0.1164 - val_my_accuracy: 0.9153 - 455ms/epoch - 4ms/step\n",
      "Epoch 127/1000\n",
      "125/125 - 0s - loss: 0.1167 - my_accuracy: 0.9124 - val_loss: 0.1098 - val_my_accuracy: 0.9220 - 390ms/epoch - 3ms/step\n",
      "Epoch 128/1000\n",
      "125/125 - 0s - loss: 0.1157 - my_accuracy: 0.9141 - val_loss: 0.1164 - val_my_accuracy: 0.9144 - 390ms/epoch - 3ms/step\n",
      "Epoch 129/1000\n",
      "125/125 - 0s - loss: 0.1146 - my_accuracy: 0.9151 - val_loss: 0.1071 - val_my_accuracy: 0.9274 - 466ms/epoch - 4ms/step\n",
      "Epoch 130/1000\n",
      "125/125 - 0s - loss: 0.1157 - my_accuracy: 0.9142 - val_loss: 0.1167 - val_my_accuracy: 0.9149 - 485ms/epoch - 4ms/step\n",
      "Epoch 131/1000\n",
      "125/125 - 0s - loss: 0.1129 - my_accuracy: 0.9162 - val_loss: 0.1097 - val_my_accuracy: 0.9206 - 441ms/epoch - 4ms/step\n",
      "Epoch 132/1000\n",
      "125/125 - 0s - loss: 0.1136 - my_accuracy: 0.9147 - val_loss: 0.1082 - val_my_accuracy: 0.9215 - 422ms/epoch - 3ms/step\n",
      "Epoch 133/1000\n",
      "125/125 - 0s - loss: 0.1107 - my_accuracy: 0.9188 - val_loss: 0.1143 - val_my_accuracy: 0.9108 - 488ms/epoch - 4ms/step\n",
      "Epoch 134/1000\n",
      "125/125 - 0s - loss: 0.1130 - my_accuracy: 0.9151 - val_loss: 0.1125 - val_my_accuracy: 0.9158 - 437ms/epoch - 3ms/step\n",
      "Epoch 135/1000\n",
      "125/125 - 0s - loss: 0.1109 - my_accuracy: 0.9183 - val_loss: 0.1112 - val_my_accuracy: 0.9161 - 420ms/epoch - 3ms/step\n",
      "Epoch 136/1000\n",
      "125/125 - 0s - loss: 0.1111 - my_accuracy: 0.9183 - val_loss: 0.1113 - val_my_accuracy: 0.9184 - 468ms/epoch - 4ms/step\n",
      "Epoch 137/1000\n",
      "125/125 - 0s - loss: 0.1117 - my_accuracy: 0.9160 - val_loss: 0.1100 - val_my_accuracy: 0.9224 - 460ms/epoch - 4ms/step\n",
      "Epoch 138/1000\n",
      "125/125 - 0s - loss: 0.1140 - my_accuracy: 0.9126 - val_loss: 0.1128 - val_my_accuracy: 0.9161 - 449ms/epoch - 4ms/step\n",
      "Epoch 139/1000\n",
      "125/125 - 0s - loss: 0.1101 - my_accuracy: 0.9184 - val_loss: 0.1182 - val_my_accuracy: 0.9051 - 483ms/epoch - 4ms/step\n",
      "Epoch 140/1000\n",
      "125/125 - 0s - loss: 0.1118 - my_accuracy: 0.9167 - val_loss: 0.1089 - val_my_accuracy: 0.9190 - 408ms/epoch - 3ms/step\n",
      "Epoch 141/1000\n",
      "125/125 - 0s - loss: 0.1118 - my_accuracy: 0.9160 - val_loss: 0.1155 - val_my_accuracy: 0.9113 - 451ms/epoch - 4ms/step\n",
      "Epoch 142/1000\n",
      "125/125 - 0s - loss: 0.1103 - my_accuracy: 0.9179 - val_loss: 0.1036 - val_my_accuracy: 0.9265 - 447ms/epoch - 4ms/step\n",
      "Epoch 143/1000\n",
      "125/125 - 0s - loss: 0.1092 - my_accuracy: 0.9195 - val_loss: 0.1150 - val_my_accuracy: 0.9119 - 405ms/epoch - 3ms/step\n",
      "Epoch 144/1000\n",
      "125/125 - 0s - loss: 0.1102 - my_accuracy: 0.9174 - val_loss: 0.1125 - val_my_accuracy: 0.9131 - 417ms/epoch - 3ms/step\n",
      "Epoch 145/1000\n",
      "125/125 - 0s - loss: 0.1108 - my_accuracy: 0.9163 - val_loss: 0.1126 - val_my_accuracy: 0.9162 - 449ms/epoch - 4ms/step\n",
      "Epoch 146/1000\n",
      "125/125 - 0s - loss: 0.1079 - my_accuracy: 0.9206 - val_loss: 0.1159 - val_my_accuracy: 0.9171 - 401ms/epoch - 3ms/step\n",
      "Epoch 147/1000\n",
      "125/125 - 1s - loss: 0.1078 - my_accuracy: 0.9183 - val_loss: 0.1066 - val_my_accuracy: 0.9205 - 503ms/epoch - 4ms/step\n",
      "Epoch 148/1000\n",
      "125/125 - 0s - loss: 0.1081 - my_accuracy: 0.9193 - val_loss: 0.1042 - val_my_accuracy: 0.9235 - 444ms/epoch - 4ms/step\n",
      "Epoch 149/1000\n",
      "125/125 - 0s - loss: 0.1102 - my_accuracy: 0.9162 - val_loss: 0.1087 - val_my_accuracy: 0.9177 - 453ms/epoch - 4ms/step\n",
      "Epoch 150/1000\n",
      "125/125 - 0s - loss: 0.1077 - my_accuracy: 0.9196 - val_loss: 0.1091 - val_my_accuracy: 0.9224 - 433ms/epoch - 3ms/step\n",
      "Epoch 151/1000\n",
      "125/125 - 0s - loss: 0.1075 - my_accuracy: 0.9203 - val_loss: 0.1033 - val_my_accuracy: 0.9257 - 456ms/epoch - 4ms/step\n",
      "Epoch 152/1000\n",
      "125/125 - 0s - loss: 0.1073 - my_accuracy: 0.9181 - val_loss: 0.1084 - val_my_accuracy: 0.9193 - 494ms/epoch - 4ms/step\n",
      "Epoch 153/1000\n",
      "125/125 - 0s - loss: 0.1072 - my_accuracy: 0.9192 - val_loss: 0.1150 - val_my_accuracy: 0.9089 - 452ms/epoch - 4ms/step\n",
      "Epoch 154/1000\n",
      "125/125 - 0s - loss: 0.1072 - my_accuracy: 0.9196 - val_loss: 0.1075 - val_my_accuracy: 0.9171 - 480ms/epoch - 4ms/step\n",
      "Epoch 155/1000\n",
      "125/125 - 1s - loss: 0.1070 - my_accuracy: 0.9193 - val_loss: 0.1082 - val_my_accuracy: 0.9183 - 615ms/epoch - 5ms/step\n",
      "Epoch 156/1000\n",
      "125/125 - 1s - loss: 0.1062 - my_accuracy: 0.9202 - val_loss: 0.1142 - val_my_accuracy: 0.9133 - 624ms/epoch - 5ms/step\n",
      "Epoch 157/1000\n",
      "125/125 - 1s - loss: 0.1058 - my_accuracy: 0.9200 - val_loss: 0.1038 - val_my_accuracy: 0.9235 - 622ms/epoch - 5ms/step\n",
      "Epoch 158/1000\n",
      "125/125 - 0s - loss: 0.1078 - my_accuracy: 0.9178 - val_loss: 0.0998 - val_my_accuracy: 0.9313 - 487ms/epoch - 4ms/step\n",
      "Epoch 159/1000\n",
      "125/125 - 0s - loss: 0.1057 - my_accuracy: 0.9202 - val_loss: 0.1088 - val_my_accuracy: 0.9192 - 455ms/epoch - 4ms/step\n",
      "Epoch 160/1000\n",
      "125/125 - 0s - loss: 0.1048 - my_accuracy: 0.9205 - val_loss: 0.1034 - val_my_accuracy: 0.9262 - 437ms/epoch - 3ms/step\n",
      "Epoch 161/1000\n",
      "125/125 - 0s - loss: 0.1039 - my_accuracy: 0.9220 - val_loss: 0.1099 - val_my_accuracy: 0.9160 - 486ms/epoch - 4ms/step\n",
      "Epoch 162/1000\n",
      "125/125 - 0s - loss: 0.1047 - my_accuracy: 0.9199 - val_loss: 0.1105 - val_my_accuracy: 0.9128 - 452ms/epoch - 4ms/step\n",
      "Epoch 163/1000\n",
      "125/125 - 0s - loss: 0.1042 - my_accuracy: 0.9209 - val_loss: 0.1046 - val_my_accuracy: 0.9203 - 461ms/epoch - 4ms/step\n",
      "Epoch 164/1000\n",
      "125/125 - 0s - loss: 0.1043 - my_accuracy: 0.9214 - val_loss: 0.1048 - val_my_accuracy: 0.9228 - 465ms/epoch - 4ms/step\n",
      "Epoch 165/1000\n",
      "125/125 - 0s - loss: 0.1063 - my_accuracy: 0.9191 - val_loss: 0.1050 - val_my_accuracy: 0.9225 - 432ms/epoch - 3ms/step\n",
      "Epoch 166/1000\n",
      "125/125 - 0s - loss: 0.1033 - my_accuracy: 0.9224 - val_loss: 0.1022 - val_my_accuracy: 0.9254 - 440ms/epoch - 4ms/step\n",
      "Epoch 167/1000\n",
      "125/125 - 0s - loss: 0.1055 - my_accuracy: 0.9184 - val_loss: 0.1032 - val_my_accuracy: 0.9229 - 442ms/epoch - 4ms/step\n",
      "Epoch 168/1000\n",
      "125/125 - 0s - loss: 0.1047 - my_accuracy: 0.9197 - val_loss: 0.1004 - val_my_accuracy: 0.9242 - 429ms/epoch - 3ms/step\n",
      "Epoch 169/1000\n",
      "125/125 - 0s - loss: 0.1057 - my_accuracy: 0.9191 - val_loss: 0.1118 - val_my_accuracy: 0.9098 - 462ms/epoch - 4ms/step\n",
      "Epoch 170/1000\n",
      "125/125 - 1s - loss: 0.1031 - my_accuracy: 0.9210 - val_loss: 0.1031 - val_my_accuracy: 0.9223 - 578ms/epoch - 5ms/step\n",
      "Epoch 171/1000\n",
      "125/125 - 1s - loss: 0.1035 - my_accuracy: 0.9208 - val_loss: 0.0972 - val_my_accuracy: 0.9307 - 577ms/epoch - 5ms/step\n",
      "Epoch 172/1000\n",
      "125/125 - 0s - loss: 0.1028 - my_accuracy: 0.9211 - val_loss: 0.1064 - val_my_accuracy: 0.9144 - 474ms/epoch - 4ms/step\n",
      "Epoch 173/1000\n",
      "125/125 - 0s - loss: 0.1017 - my_accuracy: 0.9237 - val_loss: 0.1064 - val_my_accuracy: 0.9221 - 479ms/epoch - 4ms/step\n",
      "Epoch 174/1000\n",
      "125/125 - 1s - loss: 0.1053 - my_accuracy: 0.9185 - val_loss: 0.1068 - val_my_accuracy: 0.9144 - 517ms/epoch - 4ms/step\n",
      "Epoch 175/1000\n",
      "125/125 - 0s - loss: 0.1010 - my_accuracy: 0.9240 - val_loss: 0.1069 - val_my_accuracy: 0.9155 - 471ms/epoch - 4ms/step\n",
      "Epoch 176/1000\n",
      "125/125 - 0s - loss: 0.1041 - my_accuracy: 0.9205 - val_loss: 0.1021 - val_my_accuracy: 0.9265 - 465ms/epoch - 4ms/step\n",
      "Epoch 177/1000\n",
      "125/125 - 0s - loss: 0.1012 - my_accuracy: 0.9241 - val_loss: 0.1039 - val_my_accuracy: 0.9178 - 485ms/epoch - 4ms/step\n",
      "Epoch 178/1000\n",
      "125/125 - 1s - loss: 0.1021 - my_accuracy: 0.9219 - val_loss: 0.1011 - val_my_accuracy: 0.9238 - 522ms/epoch - 4ms/step\n",
      "Epoch 179/1000\n",
      "125/125 - 1s - loss: 0.1025 - my_accuracy: 0.9210 - val_loss: 0.1005 - val_my_accuracy: 0.9261 - 857ms/epoch - 7ms/step\n",
      "Epoch 180/1000\n",
      "125/125 - 1s - loss: 0.1006 - my_accuracy: 0.9239 - val_loss: 0.0995 - val_my_accuracy: 0.9251 - 845ms/epoch - 7ms/step\n",
      "Epoch 181/1000\n",
      "125/125 - 1s - loss: 0.1002 - my_accuracy: 0.9236 - val_loss: 0.1056 - val_my_accuracy: 0.9210 - 882ms/epoch - 7ms/step\n",
      "Epoch 182/1000\n",
      "125/125 - 1s - loss: 0.0986 - my_accuracy: 0.9266 - val_loss: 0.1008 - val_my_accuracy: 0.9241 - 906ms/epoch - 7ms/step\n",
      "Epoch 183/1000\n",
      "125/125 - 1s - loss: 0.1023 - my_accuracy: 0.9217 - val_loss: 0.0996 - val_my_accuracy: 0.9255 - 959ms/epoch - 8ms/step\n",
      "Epoch 184/1000\n",
      "125/125 - 1s - loss: 0.0991 - my_accuracy: 0.9247 - val_loss: 0.1028 - val_my_accuracy: 0.9219 - 928ms/epoch - 7ms/step\n",
      "Epoch 185/1000\n",
      "125/125 - 1s - loss: 0.1015 - my_accuracy: 0.9220 - val_loss: 0.1000 - val_my_accuracy: 0.9264 - 766ms/epoch - 6ms/step\n",
      "Epoch 186/1000\n",
      "125/125 - 1s - loss: 0.1032 - my_accuracy: 0.9200 - val_loss: 0.0985 - val_my_accuracy: 0.9281 - 882ms/epoch - 7ms/step\n",
      "Epoch 187/1000\n",
      "125/125 - 1s - loss: 0.0996 - my_accuracy: 0.9239 - val_loss: 0.0976 - val_my_accuracy: 0.9254 - 930ms/epoch - 7ms/step\n",
      "Epoch 188/1000\n",
      "125/125 - 1s - loss: 0.1003 - my_accuracy: 0.9218 - val_loss: 0.0959 - val_my_accuracy: 0.9291 - 982ms/epoch - 8ms/step\n",
      "Epoch 189/1000\n",
      "125/125 - 1s - loss: 0.0968 - my_accuracy: 0.9274 - val_loss: 0.1005 - val_my_accuracy: 0.9242 - 973ms/epoch - 8ms/step\n",
      "Epoch 190/1000\n",
      "125/125 - 1s - loss: 0.0995 - my_accuracy: 0.9242 - val_loss: 0.1037 - val_my_accuracy: 0.9201 - 876ms/epoch - 7ms/step\n",
      "Epoch 191/1000\n",
      "125/125 - 1s - loss: 0.1012 - my_accuracy: 0.9210 - val_loss: 0.1004 - val_my_accuracy: 0.9215 - 688ms/epoch - 6ms/step\n",
      "Epoch 192/1000\n",
      "125/125 - 1s - loss: 0.0996 - my_accuracy: 0.9233 - val_loss: 0.0993 - val_my_accuracy: 0.9221 - 761ms/epoch - 6ms/step\n",
      "Epoch 193/1000\n",
      "125/125 - 1s - loss: 0.0995 - my_accuracy: 0.9222 - val_loss: 0.1072 - val_my_accuracy: 0.9145 - 789ms/epoch - 6ms/step\n",
      "Epoch 194/1000\n",
      "125/125 - 1s - loss: 0.1008 - my_accuracy: 0.9213 - val_loss: 0.1032 - val_my_accuracy: 0.9165 - 949ms/epoch - 8ms/step\n",
      "Epoch 195/1000\n",
      "125/125 - 1s - loss: 0.0987 - my_accuracy: 0.9243 - val_loss: 0.0998 - val_my_accuracy: 0.9213 - 1s/epoch - 9ms/step\n",
      "Epoch 196/1000\n",
      "125/125 - 1s - loss: 0.0992 - my_accuracy: 0.9235 - val_loss: 0.1016 - val_my_accuracy: 0.9235 - 1s/epoch - 11ms/step\n",
      "Epoch 197/1000\n",
      "125/125 - 1s - loss: 0.0980 - my_accuracy: 0.9251 - val_loss: 0.0928 - val_my_accuracy: 0.9336 - 1s/epoch - 10ms/step\n",
      "Epoch 198/1000\n",
      "125/125 - 1s - loss: 0.0992 - my_accuracy: 0.9236 - val_loss: 0.0945 - val_my_accuracy: 0.9314 - 1s/epoch - 8ms/step\n",
      "Epoch 199/1000\n",
      "125/125 - 1s - loss: 0.0978 - my_accuracy: 0.9249 - val_loss: 0.0949 - val_my_accuracy: 0.9288 - 827ms/epoch - 7ms/step\n",
      "Epoch 200/1000\n",
      "125/125 - 1s - loss: 0.0970 - my_accuracy: 0.9249 - val_loss: 0.0920 - val_my_accuracy: 0.9335 - 903ms/epoch - 7ms/step\n",
      "Epoch 201/1000\n",
      "125/125 - 1s - loss: 0.0963 - my_accuracy: 0.9272 - val_loss: 0.0986 - val_my_accuracy: 0.9222 - 966ms/epoch - 8ms/step\n",
      "Epoch 202/1000\n",
      "125/125 - 1s - loss: 0.0962 - my_accuracy: 0.9277 - val_loss: 0.1028 - val_my_accuracy: 0.9214 - 1s/epoch - 9ms/step\n",
      "Epoch 203/1000\n",
      "125/125 - 1s - loss: 0.0971 - my_accuracy: 0.9248 - val_loss: 0.0952 - val_my_accuracy: 0.9274 - 1s/epoch - 8ms/step\n",
      "Epoch 204/1000\n",
      "125/125 - 1s - loss: 0.0980 - my_accuracy: 0.9237 - val_loss: 0.0947 - val_my_accuracy: 0.9282 - 606ms/epoch - 5ms/step\n",
      "Epoch 205/1000\n",
      "125/125 - 1s - loss: 0.0963 - my_accuracy: 0.9255 - val_loss: 0.0952 - val_my_accuracy: 0.9282 - 1s/epoch - 9ms/step\n",
      "Epoch 206/1000\n",
      "125/125 - 1s - loss: 0.0983 - my_accuracy: 0.9251 - val_loss: 0.1006 - val_my_accuracy: 0.9211 - 1s/epoch - 8ms/step\n",
      "Epoch 207/1000\n",
      "125/125 - 1s - loss: 0.0975 - my_accuracy: 0.9242 - val_loss: 0.0990 - val_my_accuracy: 0.9255 - 734ms/epoch - 6ms/step\n",
      "Epoch 208/1000\n",
      "125/125 - 1s - loss: 0.0984 - my_accuracy: 0.9235 - val_loss: 0.1050 - val_my_accuracy: 0.9168 - 827ms/epoch - 7ms/step\n",
      "Epoch 209/1000\n",
      "125/125 - 1s - loss: 0.0971 - my_accuracy: 0.9255 - val_loss: 0.0948 - val_my_accuracy: 0.9318 - 890ms/epoch - 7ms/step\n",
      "Epoch 210/1000\n",
      "125/125 - 1s - loss: 0.0966 - my_accuracy: 0.9254 - val_loss: 0.0961 - val_my_accuracy: 0.9283 - 799ms/epoch - 6ms/step\n",
      "Epoch 211/1000\n",
      "125/125 - 1s - loss: 0.0971 - my_accuracy: 0.9259 - val_loss: 0.0923 - val_my_accuracy: 0.9343 - 796ms/epoch - 6ms/step\n",
      "Epoch 212/1000\n",
      "125/125 - 1s - loss: 0.0962 - my_accuracy: 0.9259 - val_loss: 0.0918 - val_my_accuracy: 0.9317 - 792ms/epoch - 6ms/step\n",
      "Epoch 213/1000\n",
      "125/125 - 1s - loss: 0.0958 - my_accuracy: 0.9255 - val_loss: 0.0954 - val_my_accuracy: 0.9283 - 743ms/epoch - 6ms/step\n",
      "Epoch 214/1000\n",
      "125/125 - 1s - loss: 0.0979 - my_accuracy: 0.9221 - val_loss: 0.0907 - val_my_accuracy: 0.9331 - 552ms/epoch - 4ms/step\n",
      "Epoch 215/1000\n",
      "125/125 - 1s - loss: 0.0952 - my_accuracy: 0.9270 - val_loss: 0.0978 - val_my_accuracy: 0.9249 - 509ms/epoch - 4ms/step\n",
      "Epoch 216/1000\n",
      "125/125 - 1s - loss: 0.0955 - my_accuracy: 0.9252 - val_loss: 0.0916 - val_my_accuracy: 0.9318 - 518ms/epoch - 4ms/step\n",
      "Epoch 217/1000\n",
      "125/125 - 1s - loss: 0.0955 - my_accuracy: 0.9261 - val_loss: 0.0934 - val_my_accuracy: 0.9277 - 550ms/epoch - 4ms/step\n",
      "Epoch 218/1000\n",
      "125/125 - 1s - loss: 0.0981 - my_accuracy: 0.9229 - val_loss: 0.0970 - val_my_accuracy: 0.9236 - 551ms/epoch - 4ms/step\n",
      "Epoch 219/1000\n",
      "125/125 - 1s - loss: 0.0952 - my_accuracy: 0.9261 - val_loss: 0.0957 - val_my_accuracy: 0.9298 - 600ms/epoch - 5ms/step\n",
      "Epoch 220/1000\n",
      "125/125 - 1s - loss: 0.0965 - my_accuracy: 0.9248 - val_loss: 0.0911 - val_my_accuracy: 0.9324 - 603ms/epoch - 5ms/step\n",
      "Epoch 221/1000\n",
      "125/125 - 0s - loss: 0.0971 - my_accuracy: 0.9237 - val_loss: 0.0903 - val_my_accuracy: 0.9344 - 493ms/epoch - 4ms/step\n",
      "Epoch 222/1000\n",
      "125/125 - 1s - loss: 0.0938 - my_accuracy: 0.9271 - val_loss: 0.0952 - val_my_accuracy: 0.9272 - 530ms/epoch - 4ms/step\n",
      "Epoch 223/1000\n",
      "125/125 - 1s - loss: 0.0934 - my_accuracy: 0.9275 - val_loss: 0.0930 - val_my_accuracy: 0.9308 - 562ms/epoch - 4ms/step\n",
      "Epoch 224/1000\n",
      "125/125 - 1s - loss: 0.0933 - my_accuracy: 0.9285 - val_loss: 0.0931 - val_my_accuracy: 0.9296 - 841ms/epoch - 7ms/step\n",
      "Epoch 225/1000\n",
      "125/125 - 1s - loss: 0.0930 - my_accuracy: 0.9277 - val_loss: 0.0912 - val_my_accuracy: 0.9327 - 1s/epoch - 10ms/step\n",
      "Epoch 226/1000\n",
      "125/125 - 1s - loss: 0.0973 - my_accuracy: 0.9243 - val_loss: 0.0951 - val_my_accuracy: 0.9227 - 690ms/epoch - 6ms/step\n",
      "Epoch 227/1000\n",
      "125/125 - 1s - loss: 0.0932 - my_accuracy: 0.9277 - val_loss: 0.0915 - val_my_accuracy: 0.9317 - 617ms/epoch - 5ms/step\n",
      "Epoch 228/1000\n",
      "125/125 - 1s - loss: 0.0927 - my_accuracy: 0.9283 - val_loss: 0.0895 - val_my_accuracy: 0.9344 - 1s/epoch - 10ms/step\n",
      "Epoch 229/1000\n",
      "125/125 - 1s - loss: 0.0957 - my_accuracy: 0.9248 - val_loss: 0.0975 - val_my_accuracy: 0.9249 - 1s/epoch - 10ms/step\n",
      "Epoch 230/1000\n",
      "125/125 - 1s - loss: 0.0924 - my_accuracy: 0.9290 - val_loss: 0.0874 - val_my_accuracy: 0.9358 - 1s/epoch - 11ms/step\n",
      "Epoch 231/1000\n",
      "125/125 - 1s - loss: 0.0923 - my_accuracy: 0.9293 - val_loss: 0.0958 - val_my_accuracy: 0.9247 - 1s/epoch - 8ms/step\n",
      "Epoch 232/1000\n",
      "125/125 - 1s - loss: 0.0965 - my_accuracy: 0.9234 - val_loss: 0.1024 - val_my_accuracy: 0.9177 - 1s/epoch - 8ms/step\n",
      "Epoch 233/1000\n",
      "125/125 - 1s - loss: 0.0966 - my_accuracy: 0.9237 - val_loss: 0.0902 - val_my_accuracy: 0.9306 - 987ms/epoch - 8ms/step\n",
      "Epoch 234/1000\n",
      "125/125 - 1s - loss: 0.0962 - my_accuracy: 0.9236 - val_loss: 0.0980 - val_my_accuracy: 0.9244 - 804ms/epoch - 6ms/step\n",
      "Epoch 235/1000\n",
      "125/125 - 1s - loss: 0.0939 - my_accuracy: 0.9268 - val_loss: 0.0954 - val_my_accuracy: 0.9241 - 908ms/epoch - 7ms/step\n",
      "Epoch 236/1000\n",
      "125/125 - 1s - loss: 0.0929 - my_accuracy: 0.9277 - val_loss: 0.1011 - val_my_accuracy: 0.9182 - 883ms/epoch - 7ms/step\n",
      "Epoch 237/1000\n",
      "125/125 - 1s - loss: 0.0946 - my_accuracy: 0.9257 - val_loss: 0.0952 - val_my_accuracy: 0.9262 - 1s/epoch - 8ms/step\n",
      "Epoch 238/1000\n",
      "125/125 - 1s - loss: 0.0931 - my_accuracy: 0.9275 - val_loss: 0.0938 - val_my_accuracy: 0.9258 - 1s/epoch - 10ms/step\n",
      "Epoch 239/1000\n",
      "125/125 - 1s - loss: 0.0921 - my_accuracy: 0.9284 - val_loss: 0.0893 - val_my_accuracy: 0.9346 - 1s/epoch - 8ms/step\n",
      "Epoch 240/1000\n",
      "125/125 - 1s - loss: 0.0919 - my_accuracy: 0.9288 - val_loss: 0.0925 - val_my_accuracy: 0.9288 - 1s/epoch - 10ms/step\n",
      "Epoch 241/1000\n",
      "125/125 - 1s - loss: 0.0901 - my_accuracy: 0.9298 - val_loss: 0.0959 - val_my_accuracy: 0.9262 - 1s/epoch - 9ms/step\n",
      "Epoch 242/1000\n",
      "125/125 - 1s - loss: 0.0914 - my_accuracy: 0.9286 - val_loss: 0.0934 - val_my_accuracy: 0.9294 - 1s/epoch - 9ms/step\n",
      "Epoch 243/1000\n",
      "125/125 - 1s - loss: 0.0927 - my_accuracy: 0.9280 - val_loss: 0.0843 - val_my_accuracy: 0.9377 - 1s/epoch - 8ms/step\n",
      "Epoch 244/1000\n",
      "125/125 - 1s - loss: 0.0916 - my_accuracy: 0.9291 - val_loss: 0.0892 - val_my_accuracy: 0.9337 - 991ms/epoch - 8ms/step\n",
      "Epoch 245/1000\n",
      "125/125 - 1s - loss: 0.0897 - my_accuracy: 0.9307 - val_loss: 0.0914 - val_my_accuracy: 0.9301 - 999ms/epoch - 8ms/step\n",
      "Epoch 246/1000\n",
      "125/125 - 1s - loss: 0.0929 - my_accuracy: 0.9270 - val_loss: 0.0875 - val_my_accuracy: 0.9355 - 1s/epoch - 8ms/step\n",
      "Epoch 247/1000\n",
      "125/125 - 1s - loss: 0.0911 - my_accuracy: 0.9297 - val_loss: 0.0907 - val_my_accuracy: 0.9272 - 929ms/epoch - 7ms/step\n",
      "Epoch 248/1000\n",
      "125/125 - 1s - loss: 0.0922 - my_accuracy: 0.9290 - val_loss: 0.0886 - val_my_accuracy: 0.9338 - 882ms/epoch - 7ms/step\n",
      "Epoch 249/1000\n",
      "125/125 - 1s - loss: 0.0913 - my_accuracy: 0.9288 - val_loss: 0.0902 - val_my_accuracy: 0.9326 - 807ms/epoch - 6ms/step\n",
      "Epoch 250/1000\n",
      "125/125 - 1s - loss: 0.0896 - my_accuracy: 0.9300 - val_loss: 0.0939 - val_my_accuracy: 0.9219 - 1s/epoch - 9ms/step\n",
      "Epoch 251/1000\n",
      "125/125 - 1s - loss: 0.0962 - my_accuracy: 0.9220 - val_loss: 0.0936 - val_my_accuracy: 0.9271 - 1s/epoch - 8ms/step\n",
      "Epoch 252/1000\n",
      "125/125 - 1s - loss: 0.0907 - my_accuracy: 0.9291 - val_loss: 0.0880 - val_my_accuracy: 0.9338 - 1s/epoch - 9ms/step\n",
      "Epoch 253/1000\n",
      "125/125 - 1s - loss: 0.0924 - my_accuracy: 0.9275 - val_loss: 0.0909 - val_my_accuracy: 0.9317 - 995ms/epoch - 8ms/step\n",
      "Epoch 254/1000\n",
      "125/125 - 1s - loss: 0.0896 - my_accuracy: 0.9299 - val_loss: 0.1011 - val_my_accuracy: 0.9164 - 986ms/epoch - 8ms/step\n",
      "Epoch 255/1000\n",
      "125/125 - 1s - loss: 0.0916 - my_accuracy: 0.9279 - val_loss: 0.0824 - val_my_accuracy: 0.9417 - 1s/epoch - 9ms/step\n",
      "Epoch 256/1000\n",
      "125/125 - 1s - loss: 0.0893 - my_accuracy: 0.9306 - val_loss: 0.0922 - val_my_accuracy: 0.9310 - 1s/epoch - 9ms/step\n",
      "Epoch 257/1000\n",
      "125/125 - 1s - loss: 0.0917 - my_accuracy: 0.9266 - val_loss: 0.0978 - val_my_accuracy: 0.9198 - 1s/epoch - 12ms/step\n",
      "Epoch 258/1000\n",
      "125/125 - 1s - loss: 0.0915 - my_accuracy: 0.9274 - val_loss: 0.0997 - val_my_accuracy: 0.9150 - 1s/epoch - 11ms/step\n",
      "Epoch 259/1000\n",
      "125/125 - 1s - loss: 0.0895 - my_accuracy: 0.9303 - val_loss: 0.0873 - val_my_accuracy: 0.9316 - 1s/epoch - 10ms/step\n",
      "Epoch 260/1000\n",
      "125/125 - 1s - loss: 0.0902 - my_accuracy: 0.9290 - val_loss: 0.0858 - val_my_accuracy: 0.9349 - 1s/epoch - 11ms/step\n",
      "Epoch 261/1000\n",
      "125/125 - 1s - loss: 0.0926 - my_accuracy: 0.9255 - val_loss: 0.0963 - val_my_accuracy: 0.9205 - 1s/epoch - 9ms/step\n",
      "Epoch 262/1000\n",
      "125/125 - 1s - loss: 0.0947 - my_accuracy: 0.9235 - val_loss: 0.0927 - val_my_accuracy: 0.9255 - 825ms/epoch - 7ms/step\n",
      "Epoch 263/1000\n",
      "125/125 - 1s - loss: 0.0898 - my_accuracy: 0.9293 - val_loss: 0.0885 - val_my_accuracy: 0.9332 - 811ms/epoch - 6ms/step\n",
      "Epoch 264/1000\n",
      "125/125 - 1s - loss: 0.0934 - my_accuracy: 0.9255 - val_loss: 0.0888 - val_my_accuracy: 0.9315 - 821ms/epoch - 7ms/step\n",
      "Epoch 265/1000\n",
      "125/125 - 1s - loss: 0.0920 - my_accuracy: 0.9272 - val_loss: 0.0952 - val_my_accuracy: 0.9249 - 727ms/epoch - 6ms/step\n",
      "Epoch 266/1000\n",
      "125/125 - 1s - loss: 0.0917 - my_accuracy: 0.9271 - val_loss: 0.0875 - val_my_accuracy: 0.9308 - 705ms/epoch - 6ms/step\n",
      "Epoch 267/1000\n",
      "125/125 - 1s - loss: 0.0887 - my_accuracy: 0.9306 - val_loss: 0.0950 - val_my_accuracy: 0.9216 - 738ms/epoch - 6ms/step\n",
      "Epoch 268/1000\n",
      "125/125 - 1s - loss: 0.0898 - my_accuracy: 0.9289 - val_loss: 0.0881 - val_my_accuracy: 0.9307 - 759ms/epoch - 6ms/step\n",
      "Epoch 269/1000\n",
      "125/125 - 1s - loss: 0.0898 - my_accuracy: 0.9293 - val_loss: 0.0933 - val_my_accuracy: 0.9284 - 722ms/epoch - 6ms/step\n",
      "Epoch 270/1000\n",
      "125/125 - 1s - loss: 0.0878 - my_accuracy: 0.9315 - val_loss: 0.0859 - val_my_accuracy: 0.9335 - 979ms/epoch - 8ms/step\n",
      "Epoch 271/1000\n",
      "125/125 - 1s - loss: 0.0883 - my_accuracy: 0.9310 - val_loss: 0.0861 - val_my_accuracy: 0.9323 - 1s/epoch - 9ms/step\n",
      "Epoch 272/1000\n",
      "125/125 - 1s - loss: 0.0888 - my_accuracy: 0.9301 - val_loss: 0.1002 - val_my_accuracy: 0.9209 - 1s/epoch - 9ms/step\n",
      "Epoch 273/1000\n",
      "125/125 - 1s - loss: 0.0890 - my_accuracy: 0.9302 - val_loss: 0.0952 - val_my_accuracy: 0.9232 - 752ms/epoch - 6ms/step\n",
      "Epoch 274/1000\n",
      "125/125 - 1s - loss: 0.0888 - my_accuracy: 0.9299 - val_loss: 0.0826 - val_my_accuracy: 0.9365 - 748ms/epoch - 6ms/step\n",
      "Epoch 275/1000\n",
      "125/125 - 1s - loss: 0.0855 - my_accuracy: 0.9345 - val_loss: 0.0835 - val_my_accuracy: 0.9366 - 802ms/epoch - 6ms/step\n",
      "Epoch 276/1000\n",
      "125/125 - 1s - loss: 0.0883 - my_accuracy: 0.9295 - val_loss: 0.0888 - val_my_accuracy: 0.9322 - 763ms/epoch - 6ms/step\n",
      "Epoch 277/1000\n",
      "125/125 - 1s - loss: 0.0905 - my_accuracy: 0.9286 - val_loss: 0.0895 - val_my_accuracy: 0.9293 - 738ms/epoch - 6ms/step\n",
      "Epoch 278/1000\n",
      "125/125 - 1s - loss: 0.0877 - my_accuracy: 0.9303 - val_loss: 0.0945 - val_my_accuracy: 0.9229 - 675ms/epoch - 5ms/step\n",
      "Epoch 279/1000\n",
      "125/125 - 1s - loss: 0.0884 - my_accuracy: 0.9307 - val_loss: 0.0940 - val_my_accuracy: 0.9211 - 740ms/epoch - 6ms/step\n",
      "Epoch 280/1000\n",
      "125/125 - 1s - loss: 0.0895 - my_accuracy: 0.9292 - val_loss: 0.0898 - val_my_accuracy: 0.9286 - 705ms/epoch - 6ms/step\n",
      "Epoch 281/1000\n",
      "125/125 - 1s - loss: 0.0899 - my_accuracy: 0.9288 - val_loss: 0.0903 - val_my_accuracy: 0.9333 - 703ms/epoch - 6ms/step\n",
      "Epoch 282/1000\n",
      "125/125 - 1s - loss: 0.0882 - my_accuracy: 0.9301 - val_loss: 0.0883 - val_my_accuracy: 0.9303 - 1s/epoch - 9ms/step\n",
      "Epoch 283/1000\n",
      "125/125 - 1s - loss: 0.0902 - my_accuracy: 0.9282 - val_loss: 0.0889 - val_my_accuracy: 0.9291 - 974ms/epoch - 8ms/step\n",
      "Epoch 284/1000\n",
      "125/125 - 1s - loss: 0.0880 - my_accuracy: 0.9311 - val_loss: 0.0930 - val_my_accuracy: 0.9232 - 1s/epoch - 8ms/step\n",
      "Epoch 285/1000\n",
      "125/125 - 1s - loss: 0.0872 - my_accuracy: 0.9316 - val_loss: 0.0838 - val_my_accuracy: 0.9371 - 969ms/epoch - 8ms/step\n",
      "Epoch 286/1000\n",
      "125/125 - 1s - loss: 0.0859 - my_accuracy: 0.9331 - val_loss: 0.0904 - val_my_accuracy: 0.9271 - 899ms/epoch - 7ms/step\n",
      "Epoch 287/1000\n",
      "125/125 - 1s - loss: 0.0886 - my_accuracy: 0.9302 - val_loss: 0.0902 - val_my_accuracy: 0.9291 - 962ms/epoch - 8ms/step\n",
      "Epoch 288/1000\n",
      "125/125 - 1s - loss: 0.0885 - my_accuracy: 0.9287 - val_loss: 0.0881 - val_my_accuracy: 0.9328 - 939ms/epoch - 8ms/step\n",
      "Epoch 289/1000\n",
      "125/125 - 1s - loss: 0.0872 - my_accuracy: 0.9306 - val_loss: 0.0880 - val_my_accuracy: 0.9304 - 750ms/epoch - 6ms/step\n",
      "Epoch 290/1000\n",
      "125/125 - 1s - loss: 0.0870 - my_accuracy: 0.9316 - val_loss: 0.0944 - val_my_accuracy: 0.9243 - 614ms/epoch - 5ms/step\n",
      "Epoch 291/1000\n",
      "125/125 - 1s - loss: 0.0861 - my_accuracy: 0.9323 - val_loss: 0.0877 - val_my_accuracy: 0.9316 - 633ms/epoch - 5ms/step\n",
      "Epoch 292/1000\n",
      "125/125 - 1s - loss: 0.0884 - my_accuracy: 0.9303 - val_loss: 0.0864 - val_my_accuracy: 0.9318 - 611ms/epoch - 5ms/step\n",
      "Epoch 293/1000\n",
      "125/125 - 1s - loss: 0.0863 - my_accuracy: 0.9330 - val_loss: 0.0835 - val_my_accuracy: 0.9343 - 605ms/epoch - 5ms/step\n",
      "Epoch 294/1000\n",
      "125/125 - 1s - loss: 0.0858 - my_accuracy: 0.9332 - val_loss: 0.0885 - val_my_accuracy: 0.9288 - 593ms/epoch - 5ms/step\n",
      "Epoch 295/1000\n",
      "125/125 - 1s - loss: 0.0873 - my_accuracy: 0.9295 - val_loss: 0.0920 - val_my_accuracy: 0.9263 - 1s/epoch - 8ms/step\n",
      "Epoch 296/1000\n",
      "125/125 - 1s - loss: 0.0881 - my_accuracy: 0.9305 - val_loss: 0.0905 - val_my_accuracy: 0.9315 - 847ms/epoch - 7ms/step\n",
      "Epoch 297/1000\n",
      "125/125 - 1s - loss: 0.0866 - my_accuracy: 0.9329 - val_loss: 0.0852 - val_my_accuracy: 0.9333 - 702ms/epoch - 6ms/step\n",
      "Epoch 298/1000\n",
      "125/125 - 1s - loss: 0.0873 - my_accuracy: 0.9296 - val_loss: 0.0842 - val_my_accuracy: 0.9400 - 724ms/epoch - 6ms/step\n",
      "Epoch 299/1000\n",
      "125/125 - 1s - loss: 0.0864 - my_accuracy: 0.9332 - val_loss: 0.0870 - val_my_accuracy: 0.9316 - 824ms/epoch - 7ms/step\n",
      "Epoch 300/1000\n",
      "125/125 - 1s - loss: 0.0856 - my_accuracy: 0.9329 - val_loss: 0.0809 - val_my_accuracy: 0.9374 - 842ms/epoch - 7ms/step\n",
      "Epoch 301/1000\n",
      "125/125 - 1s - loss: 0.0864 - my_accuracy: 0.9329 - val_loss: 0.0812 - val_my_accuracy: 0.9377 - 883ms/epoch - 7ms/step\n",
      "Epoch 302/1000\n",
      "125/125 - 1s - loss: 0.0853 - my_accuracy: 0.9324 - val_loss: 0.0996 - val_my_accuracy: 0.9191 - 823ms/epoch - 7ms/step\n",
      "Epoch 303/1000\n",
      "125/125 - 1s - loss: 0.0875 - my_accuracy: 0.9305 - val_loss: 0.0880 - val_my_accuracy: 0.9294 - 765ms/epoch - 6ms/step\n",
      "Epoch 304/1000\n",
      "125/125 - 1s - loss: 0.0886 - my_accuracy: 0.9296 - val_loss: 0.0970 - val_my_accuracy: 0.9244 - 593ms/epoch - 5ms/step\n",
      "Epoch 305/1000\n",
      "125/125 - 1s - loss: 0.0883 - my_accuracy: 0.9308 - val_loss: 0.0848 - val_my_accuracy: 0.9315 - 617ms/epoch - 5ms/step\n",
      "Epoch 306/1000\n",
      "125/125 - 1s - loss: 0.0872 - my_accuracy: 0.9312 - val_loss: 0.0863 - val_my_accuracy: 0.9320 - 552ms/epoch - 4ms/step\n",
      "Epoch 307/1000\n",
      "125/125 - 1s - loss: 0.0852 - my_accuracy: 0.9321 - val_loss: 0.0887 - val_my_accuracy: 0.9296 - 641ms/epoch - 5ms/step\n",
      "Epoch 308/1000\n",
      "125/125 - 1s - loss: 0.0846 - my_accuracy: 0.9330 - val_loss: 0.0900 - val_my_accuracy: 0.9254 - 591ms/epoch - 5ms/step\n",
      "Epoch 309/1000\n",
      "125/125 - 1s - loss: 0.0836 - my_accuracy: 0.9348 - val_loss: 0.0799 - val_my_accuracy: 0.9414 - 571ms/epoch - 5ms/step\n",
      "Epoch 310/1000\n",
      "125/125 - 1s - loss: 0.0844 - my_accuracy: 0.9332 - val_loss: 0.0968 - val_my_accuracy: 0.9148 - 578ms/epoch - 5ms/step\n",
      "Epoch 311/1000\n",
      "125/125 - 1s - loss: 0.0884 - my_accuracy: 0.9285 - val_loss: 0.0808 - val_my_accuracy: 0.9391 - 594ms/epoch - 5ms/step\n",
      "Epoch 312/1000\n",
      "125/125 - 1s - loss: 0.0861 - my_accuracy: 0.9310 - val_loss: 0.0875 - val_my_accuracy: 0.9307 - 658ms/epoch - 5ms/step\n",
      "Epoch 313/1000\n",
      "125/125 - 1s - loss: 0.0854 - my_accuracy: 0.9329 - val_loss: 0.0777 - val_my_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
      "Epoch 314/1000\n",
      "125/125 - 1s - loss: 0.0858 - my_accuracy: 0.9322 - val_loss: 0.0866 - val_my_accuracy: 0.9302 - 917ms/epoch - 7ms/step\n",
      "Epoch 315/1000\n",
      "125/125 - 1s - loss: 0.0871 - my_accuracy: 0.9303 - val_loss: 0.0821 - val_my_accuracy: 0.9365 - 736ms/epoch - 6ms/step\n",
      "Epoch 316/1000\n",
      "125/125 - 1s - loss: 0.0861 - my_accuracy: 0.9310 - val_loss: 0.0832 - val_my_accuracy: 0.9371 - 768ms/epoch - 6ms/step\n",
      "Epoch 317/1000\n",
      "125/125 - 1s - loss: 0.0824 - my_accuracy: 0.9350 - val_loss: 0.0802 - val_my_accuracy: 0.9410 - 1s/epoch - 9ms/step\n",
      "Epoch 318/1000\n",
      "125/125 - 1s - loss: 0.0860 - my_accuracy: 0.9312 - val_loss: 0.0809 - val_my_accuracy: 0.9376 - 822ms/epoch - 7ms/step\n",
      "Epoch 319/1000\n",
      "125/125 - 1s - loss: 0.0852 - my_accuracy: 0.9334 - val_loss: 0.0823 - val_my_accuracy: 0.9362 - 794ms/epoch - 6ms/step\n",
      "Epoch 320/1000\n",
      "125/125 - 1s - loss: 0.0827 - my_accuracy: 0.9357 - val_loss: 0.0799 - val_my_accuracy: 0.9401 - 928ms/epoch - 7ms/step\n",
      "Epoch 321/1000\n",
      "125/125 - 1s - loss: 0.0853 - my_accuracy: 0.9322 - val_loss: 0.0988 - val_my_accuracy: 0.9241 - 952ms/epoch - 8ms/step\n",
      "Epoch 322/1000\n",
      "125/125 - 1s - loss: 0.0845 - my_accuracy: 0.9330 - val_loss: 0.0954 - val_my_accuracy: 0.9227 - 702ms/epoch - 6ms/step\n",
      "Epoch 323/1000\n",
      "125/125 - 1s - loss: 0.0841 - my_accuracy: 0.9331 - val_loss: 0.0828 - val_my_accuracy: 0.9348 - 611ms/epoch - 5ms/step\n",
      "Epoch 324/1000\n",
      "125/125 - 1s - loss: 0.0834 - my_accuracy: 0.9335 - val_loss: 0.0857 - val_my_accuracy: 0.9322 - 575ms/epoch - 5ms/step\n",
      "Epoch 325/1000\n",
      "125/125 - 1s - loss: 0.0849 - my_accuracy: 0.9338 - val_loss: 0.0854 - val_my_accuracy: 0.9286 - 700ms/epoch - 6ms/step\n",
      "Epoch 326/1000\n",
      "125/125 - 1s - loss: 0.0856 - my_accuracy: 0.9310 - val_loss: 0.0937 - val_my_accuracy: 0.9234 - 855ms/epoch - 7ms/step\n",
      "Epoch 327/1000\n",
      "125/125 - 1s - loss: 0.0854 - my_accuracy: 0.9309 - val_loss: 0.0900 - val_my_accuracy: 0.9281 - 974ms/epoch - 8ms/step\n",
      "Epoch 328/1000\n",
      "125/125 - 1s - loss: 0.0840 - my_accuracy: 0.9336 - val_loss: 0.0810 - val_my_accuracy: 0.9367 - 730ms/epoch - 6ms/step\n",
      "Epoch 329/1000\n",
      "125/125 - 1s - loss: 0.0851 - my_accuracy: 0.9317 - val_loss: 0.0811 - val_my_accuracy: 0.9384 - 670ms/epoch - 5ms/step\n",
      "Epoch 330/1000\n",
      "125/125 - 1s - loss: 0.0830 - my_accuracy: 0.9341 - val_loss: 0.0848 - val_my_accuracy: 0.9340 - 936ms/epoch - 7ms/step\n",
      "Epoch 331/1000\n",
      "125/125 - 1s - loss: 0.0815 - my_accuracy: 0.9354 - val_loss: 0.0841 - val_my_accuracy: 0.9320 - 918ms/epoch - 7ms/step\n",
      "Epoch 332/1000\n",
      "125/125 - 1s - loss: 0.0831 - my_accuracy: 0.9341 - val_loss: 0.0914 - val_my_accuracy: 0.9240 - 1s/epoch - 9ms/step\n",
      "Epoch 333/1000\n",
      "125/125 - 1s - loss: 0.0856 - my_accuracy: 0.9316 - val_loss: 0.0826 - val_my_accuracy: 0.9371 - 873ms/epoch - 7ms/step\n",
      "Epoch 334/1000\n",
      "125/125 - 1s - loss: 0.0844 - my_accuracy: 0.9326 - val_loss: 0.0905 - val_my_accuracy: 0.9247 - 981ms/epoch - 8ms/step\n",
      "Epoch 335/1000\n",
      "125/125 - 1s - loss: 0.0869 - my_accuracy: 0.9308 - val_loss: 0.0918 - val_my_accuracy: 0.9240 - 917ms/epoch - 7ms/step\n",
      "Epoch 336/1000\n",
      "125/125 - 1s - loss: 0.0844 - my_accuracy: 0.9323 - val_loss: 0.0990 - val_my_accuracy: 0.9161 - 872ms/epoch - 7ms/step\n",
      "Epoch 337/1000\n",
      "125/125 - 1s - loss: 0.0829 - my_accuracy: 0.9342 - val_loss: 0.0881 - val_my_accuracy: 0.9290 - 817ms/epoch - 7ms/step\n",
      "Epoch 338/1000\n",
      "125/125 - 1s - loss: 0.0823 - my_accuracy: 0.9343 - val_loss: 0.0772 - val_my_accuracy: 0.9440 - 1s/epoch - 9ms/step\n",
      "Epoch 339/1000\n",
      "125/125 - 1s - loss: 0.0850 - my_accuracy: 0.9315 - val_loss: 0.0818 - val_my_accuracy: 0.9344 - 1s/epoch - 9ms/step\n",
      "Epoch 340/1000\n",
      "125/125 - 1s - loss: 0.0826 - my_accuracy: 0.9356 - val_loss: 0.0882 - val_my_accuracy: 0.9286 - 1s/epoch - 9ms/step\n",
      "Epoch 341/1000\n",
      "125/125 - 1s - loss: 0.0854 - my_accuracy: 0.9315 - val_loss: 0.0818 - val_my_accuracy: 0.9363 - 814ms/epoch - 7ms/step\n",
      "Epoch 342/1000\n",
      "125/125 - 1s - loss: 0.0846 - my_accuracy: 0.9318 - val_loss: 0.0891 - val_my_accuracy: 0.9279 - 1s/epoch - 8ms/step\n",
      "Epoch 343/1000\n",
      "125/125 - 1s - loss: 0.0840 - my_accuracy: 0.9328 - val_loss: 0.0845 - val_my_accuracy: 0.9321 - 1s/epoch - 9ms/step\n",
      "Epoch 344/1000\n",
      "125/125 - 1s - loss: 0.0859 - my_accuracy: 0.9295 - val_loss: 0.0855 - val_my_accuracy: 0.9351 - 910ms/epoch - 7ms/step\n",
      "Epoch 345/1000\n",
      "125/125 - 1s - loss: 0.0841 - my_accuracy: 0.9323 - val_loss: 0.0774 - val_my_accuracy: 0.9424 - 813ms/epoch - 7ms/step\n",
      "Epoch 346/1000\n",
      "125/125 - 1s - loss: 0.0805 - my_accuracy: 0.9357 - val_loss: 0.0808 - val_my_accuracy: 0.9388 - 758ms/epoch - 6ms/step\n",
      "Epoch 347/1000\n",
      "125/125 - 1s - loss: 0.0842 - my_accuracy: 0.9329 - val_loss: 0.0850 - val_my_accuracy: 0.9322 - 940ms/epoch - 8ms/step\n",
      "Epoch 348/1000\n",
      "125/125 - 1s - loss: 0.0856 - my_accuracy: 0.9301 - val_loss: 0.0860 - val_my_accuracy: 0.9283 - 1s/epoch - 8ms/step\n",
      "Epoch 349/1000\n",
      "125/125 - 1s - loss: 0.0863 - my_accuracy: 0.9293 - val_loss: 0.0820 - val_my_accuracy: 0.9354 - 814ms/epoch - 7ms/step\n",
      "Epoch 350/1000\n",
      "125/125 - 1s - loss: 0.0826 - my_accuracy: 0.9340 - val_loss: 0.0809 - val_my_accuracy: 0.9360 - 911ms/epoch - 7ms/step\n",
      "Epoch 351/1000\n",
      "125/125 - 1s - loss: 0.0817 - my_accuracy: 0.9350 - val_loss: 0.0793 - val_my_accuracy: 0.9398 - 971ms/epoch - 8ms/step\n",
      "Epoch 352/1000\n",
      "125/125 - 1s - loss: 0.0821 - my_accuracy: 0.9350 - val_loss: 0.0824 - val_my_accuracy: 0.9335 - 825ms/epoch - 7ms/step\n",
      "Epoch 353/1000\n",
      "125/125 - 1s - loss: 0.0836 - my_accuracy: 0.9333 - val_loss: 0.0976 - val_my_accuracy: 0.9243 - 1s/epoch - 9ms/step\n",
      "Epoch 354/1000\n",
      "125/125 - 1s - loss: 0.0828 - my_accuracy: 0.9336 - val_loss: 0.0794 - val_my_accuracy: 0.9387 - 900ms/epoch - 7ms/step\n",
      "Epoch 355/1000\n",
      "125/125 - 1s - loss: 0.0845 - my_accuracy: 0.9321 - val_loss: 0.0837 - val_my_accuracy: 0.9352 - 828ms/epoch - 7ms/step\n",
      "Epoch 356/1000\n",
      "125/125 - 1s - loss: 0.0810 - my_accuracy: 0.9356 - val_loss: 0.0816 - val_my_accuracy: 0.9363 - 1s/epoch - 8ms/step\n",
      "Epoch 357/1000\n",
      "125/125 - 1s - loss: 0.0826 - my_accuracy: 0.9344 - val_loss: 0.0987 - val_my_accuracy: 0.9161 - 786ms/epoch - 6ms/step\n",
      "Epoch 358/1000\n",
      "125/125 - 1s - loss: 0.0834 - my_accuracy: 0.9343 - val_loss: 0.0845 - val_my_accuracy: 0.9329 - 1s/epoch - 8ms/step\n",
      "Epoch 359/1000\n",
      "125/125 - 1s - loss: 0.0842 - my_accuracy: 0.9313 - val_loss: 0.0840 - val_my_accuracy: 0.9342 - 947ms/epoch - 8ms/step\n",
      "Epoch 360/1000\n",
      "125/125 - 1s - loss: 0.0844 - my_accuracy: 0.9314 - val_loss: 0.0818 - val_my_accuracy: 0.9361 - 957ms/epoch - 8ms/step\n",
      "Epoch 361/1000\n",
      "125/125 - 1s - loss: 0.0802 - my_accuracy: 0.9379 - val_loss: 0.0886 - val_my_accuracy: 0.9255 - 724ms/epoch - 6ms/step\n",
      "Epoch 362/1000\n",
      "125/125 - 1s - loss: 0.0861 - my_accuracy: 0.9294 - val_loss: 0.0881 - val_my_accuracy: 0.9253 - 1s/epoch - 8ms/step\n",
      "Epoch 363/1000\n",
      "125/125 - 1s - loss: 0.0813 - my_accuracy: 0.9353 - val_loss: 0.0754 - val_my_accuracy: 0.9438 - 1s/epoch - 8ms/step\n",
      "Epoch 364/1000\n",
      "125/125 - 1s - loss: 0.0794 - my_accuracy: 0.9374 - val_loss: 0.0834 - val_my_accuracy: 0.9310 - 897ms/epoch - 7ms/step\n",
      "Epoch 365/1000\n",
      "125/125 - 1s - loss: 0.0835 - my_accuracy: 0.9327 - val_loss: 0.0813 - val_my_accuracy: 0.9345 - 848ms/epoch - 7ms/step\n",
      "Epoch 366/1000\n",
      "125/125 - 1s - loss: 0.0812 - my_accuracy: 0.9357 - val_loss: 0.0866 - val_my_accuracy: 0.9306 - 835ms/epoch - 7ms/step\n",
      "Epoch 367/1000\n",
      "125/125 - 1s - loss: 0.0811 - my_accuracy: 0.9349 - val_loss: 0.0901 - val_my_accuracy: 0.9244 - 1s/epoch - 9ms/step\n",
      "Epoch 368/1000\n",
      "125/125 - 1s - loss: 0.0827 - my_accuracy: 0.9340 - val_loss: 0.0783 - val_my_accuracy: 0.9382 - 899ms/epoch - 7ms/step\n",
      "Epoch 369/1000\n",
      "125/125 - 1s - loss: 0.0849 - my_accuracy: 0.9311 - val_loss: 0.0816 - val_my_accuracy: 0.9330 - 875ms/epoch - 7ms/step\n",
      "Epoch 370/1000\n",
      "125/125 - 1s - loss: 0.0804 - my_accuracy: 0.9350 - val_loss: 0.0945 - val_my_accuracy: 0.9197 - 844ms/epoch - 7ms/step\n",
      "Epoch 371/1000\n",
      "125/125 - 1s - loss: 0.0825 - my_accuracy: 0.9341 - val_loss: 0.0748 - val_my_accuracy: 0.9433 - 801ms/epoch - 6ms/step\n",
      "Epoch 372/1000\n",
      "125/125 - 1s - loss: 0.0816 - my_accuracy: 0.9342 - val_loss: 0.0789 - val_my_accuracy: 0.9374 - 724ms/epoch - 6ms/step\n",
      "Epoch 373/1000\n",
      "125/125 - 1s - loss: 0.0781 - my_accuracy: 0.9396 - val_loss: 0.0796 - val_my_accuracy: 0.9378 - 757ms/epoch - 6ms/step\n",
      "Epoch 374/1000\n",
      "125/125 - 1s - loss: 0.0817 - my_accuracy: 0.9340 - val_loss: 0.0923 - val_my_accuracy: 0.9238 - 644ms/epoch - 5ms/step\n",
      "Epoch 375/1000\n",
      "125/125 - 1s - loss: 0.0793 - my_accuracy: 0.9376 - val_loss: 0.0891 - val_my_accuracy: 0.9293 - 622ms/epoch - 5ms/step\n",
      "Epoch 376/1000\n",
      "125/125 - 1s - loss: 0.0808 - my_accuracy: 0.9351 - val_loss: 0.0825 - val_my_accuracy: 0.9354 - 584ms/epoch - 5ms/step\n",
      "Epoch 377/1000\n",
      "125/125 - 1s - loss: 0.0796 - my_accuracy: 0.9365 - val_loss: 0.0843 - val_my_accuracy: 0.9314 - 556ms/epoch - 4ms/step\n",
      "Epoch 378/1000\n",
      "125/125 - 1s - loss: 0.0851 - my_accuracy: 0.9321 - val_loss: 0.0829 - val_my_accuracy: 0.9319 - 528ms/epoch - 4ms/step\n",
      "Epoch 379/1000\n",
      "125/125 - 1s - loss: 0.0823 - my_accuracy: 0.9335 - val_loss: 0.0776 - val_my_accuracy: 0.9420 - 516ms/epoch - 4ms/step\n",
      "Epoch 380/1000\n",
      "125/125 - 1s - loss: 0.0823 - my_accuracy: 0.9331 - val_loss: 0.0816 - val_my_accuracy: 0.9337 - 610ms/epoch - 5ms/step\n",
      "Epoch 381/1000\n",
      "125/125 - 1s - loss: 0.0813 - my_accuracy: 0.9356 - val_loss: 0.0862 - val_my_accuracy: 0.9335 - 632ms/epoch - 5ms/step\n",
      "Epoch 382/1000\n",
      "125/125 - 1s - loss: 0.0824 - my_accuracy: 0.9338 - val_loss: 0.0763 - val_my_accuracy: 0.9414 - 576ms/epoch - 5ms/step\n",
      "Epoch 383/1000\n",
      "125/125 - 1s - loss: 0.0798 - my_accuracy: 0.9368 - val_loss: 0.0752 - val_my_accuracy: 0.9449 - 582ms/epoch - 5ms/step\n",
      "Epoch 384/1000\n",
      "125/125 - 1s - loss: 0.0796 - my_accuracy: 0.9372 - val_loss: 0.0834 - val_my_accuracy: 0.9318 - 566ms/epoch - 5ms/step\n",
      "Epoch 385/1000\n",
      "125/125 - 1s - loss: 0.0802 - my_accuracy: 0.9365 - val_loss: 0.0778 - val_my_accuracy: 0.9369 - 571ms/epoch - 5ms/step\n",
      "Epoch 386/1000\n",
      "125/125 - 1s - loss: 0.0800 - my_accuracy: 0.9369 - val_loss: 0.0754 - val_my_accuracy: 0.9423 - 557ms/epoch - 4ms/step\n",
      "Epoch 387/1000\n",
      "125/125 - 1s - loss: 0.0809 - my_accuracy: 0.9349 - val_loss: 0.0836 - val_my_accuracy: 0.9324 - 533ms/epoch - 4ms/step\n",
      "Epoch 388/1000\n",
      "125/125 - 1s - loss: 0.0804 - my_accuracy: 0.9344 - val_loss: 0.0755 - val_my_accuracy: 0.9404 - 539ms/epoch - 4ms/step\n",
      "Epoch 389/1000\n",
      "125/125 - 0s - loss: 0.0816 - my_accuracy: 0.9339 - val_loss: 0.0862 - val_my_accuracy: 0.9301 - 496ms/epoch - 4ms/step\n",
      "Epoch 390/1000\n",
      "125/125 - 1s - loss: 0.0797 - my_accuracy: 0.9358 - val_loss: 0.0800 - val_my_accuracy: 0.9388 - 663ms/epoch - 5ms/step\n",
      "Epoch 391/1000\n",
      "125/125 - 1s - loss: 0.0795 - my_accuracy: 0.9383 - val_loss: 0.0860 - val_my_accuracy: 0.9330 - 1s/epoch - 8ms/step\n",
      "Epoch 392/1000\n",
      "125/125 - 1s - loss: 0.0798 - my_accuracy: 0.9362 - val_loss: 0.0790 - val_my_accuracy: 0.9380 - 1s/epoch - 11ms/step\n",
      "Epoch 393/1000\n",
      "125/125 - 1s - loss: 0.0787 - my_accuracy: 0.9378 - val_loss: 0.0748 - val_my_accuracy: 0.9443 - 1s/epoch - 9ms/step\n",
      "Epoch 394/1000\n",
      "125/125 - 1s - loss: 0.0791 - my_accuracy: 0.9379 - val_loss: 0.0765 - val_my_accuracy: 0.9427 - 942ms/epoch - 8ms/step\n",
      "Epoch 395/1000\n",
      "125/125 - 1s - loss: 0.0813 - my_accuracy: 0.9339 - val_loss: 0.0903 - val_my_accuracy: 0.9280 - 926ms/epoch - 7ms/step\n",
      "Epoch 396/1000\n",
      "125/125 - 1s - loss: 0.0826 - my_accuracy: 0.9322 - val_loss: 0.0794 - val_my_accuracy: 0.9350 - 858ms/epoch - 7ms/step\n",
      "Epoch 397/1000\n",
      "125/125 - 1s - loss: 0.0814 - my_accuracy: 0.9354 - val_loss: 0.0835 - val_my_accuracy: 0.9315 - 1s/epoch - 9ms/step\n",
      "Epoch 398/1000\n",
      "125/125 - 1s - loss: 0.0814 - my_accuracy: 0.9339 - val_loss: 0.0806 - val_my_accuracy: 0.9344 - 761ms/epoch - 6ms/step\n",
      "Epoch 399/1000\n",
      "125/125 - 1s - loss: 0.0794 - my_accuracy: 0.9362 - val_loss: 0.0739 - val_my_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
      "Epoch 400/1000\n",
      "125/125 - 1s - loss: 0.0851 - my_accuracy: 0.9293 - val_loss: 0.0840 - val_my_accuracy: 0.9317 - 865ms/epoch - 7ms/step\n",
      "Epoch 401/1000\n",
      "125/125 - 1s - loss: 0.0832 - my_accuracy: 0.9325 - val_loss: 0.0919 - val_my_accuracy: 0.9205 - 849ms/epoch - 7ms/step\n",
      "Epoch 402/1000\n",
      "125/125 - 1s - loss: 0.0781 - my_accuracy: 0.9377 - val_loss: 0.0815 - val_my_accuracy: 0.9354 - 1s/epoch - 9ms/step\n",
      "Epoch 403/1000\n",
      "125/125 - 1s - loss: 0.0807 - my_accuracy: 0.9338 - val_loss: 0.0801 - val_my_accuracy: 0.9333 - 890ms/epoch - 7ms/step\n",
      "Epoch 404/1000\n",
      "125/125 - 1s - loss: 0.0815 - my_accuracy: 0.9343 - val_loss: 0.0789 - val_my_accuracy: 0.9358 - 908ms/epoch - 7ms/step\n",
      "Epoch 405/1000\n",
      "125/125 - 1s - loss: 0.0807 - my_accuracy: 0.9347 - val_loss: 0.0812 - val_my_accuracy: 0.9337 - 791ms/epoch - 6ms/step\n",
      "Epoch 406/1000\n",
      "125/125 - 1s - loss: 0.0804 - my_accuracy: 0.9342 - val_loss: 0.0777 - val_my_accuracy: 0.9418 - 872ms/epoch - 7ms/step\n",
      "Epoch 407/1000\n",
      "125/125 - 1s - loss: 0.0818 - my_accuracy: 0.9338 - val_loss: 0.0809 - val_my_accuracy: 0.9363 - 807ms/epoch - 6ms/step\n",
      "Epoch 408/1000\n",
      "125/125 - 1s - loss: 0.0805 - my_accuracy: 0.9359 - val_loss: 0.0836 - val_my_accuracy: 0.9298 - 728ms/epoch - 6ms/step\n",
      "Epoch 409/1000\n",
      "125/125 - 1s - loss: 0.0780 - my_accuracy: 0.9375 - val_loss: 0.0762 - val_my_accuracy: 0.9405 - 832ms/epoch - 7ms/step\n",
      "Epoch 410/1000\n",
      "125/125 - 1s - loss: 0.0834 - my_accuracy: 0.9327 - val_loss: 0.0885 - val_my_accuracy: 0.9278 - 764ms/epoch - 6ms/step\n",
      "Epoch 411/1000\n",
      "125/125 - 1s - loss: 0.0798 - my_accuracy: 0.9361 - val_loss: 0.0820 - val_my_accuracy: 0.9321 - 886ms/epoch - 7ms/step\n",
      "Epoch 412/1000\n",
      "125/125 - 1s - loss: 0.0807 - my_accuracy: 0.9338 - val_loss: 0.0807 - val_my_accuracy: 0.9334 - 918ms/epoch - 7ms/step\n",
      "Epoch 413/1000\n",
      "125/125 - 1s - loss: 0.0802 - my_accuracy: 0.9353 - val_loss: 0.0775 - val_my_accuracy: 0.9373 - 883ms/epoch - 7ms/step\n",
      "Epoch 414/1000\n",
      "125/125 - 1s - loss: 0.0797 - my_accuracy: 0.9363 - val_loss: 0.0747 - val_my_accuracy: 0.9441 - 978ms/epoch - 8ms/step\n",
      "Epoch 415/1000\n",
      "125/125 - 1s - loss: 0.0787 - my_accuracy: 0.9357 - val_loss: 0.0898 - val_my_accuracy: 0.9260 - 813ms/epoch - 7ms/step\n",
      "Epoch 416/1000\n",
      "125/125 - 1s - loss: 0.0801 - my_accuracy: 0.9357 - val_loss: 0.0803 - val_my_accuracy: 0.9326 - 677ms/epoch - 5ms/step\n",
      "Epoch 417/1000\n",
      "125/125 - 1s - loss: 0.0831 - my_accuracy: 0.9324 - val_loss: 0.0741 - val_my_accuracy: 0.9437 - 798ms/epoch - 6ms/step\n",
      "Epoch 418/1000\n",
      "125/125 - 1s - loss: 0.0769 - my_accuracy: 0.9385 - val_loss: 0.0755 - val_my_accuracy: 0.9437 - 754ms/epoch - 6ms/step\n",
      "Epoch 419/1000\n",
      "125/125 - 1s - loss: 0.0768 - my_accuracy: 0.9383 - val_loss: 0.0884 - val_my_accuracy: 0.9269 - 716ms/epoch - 6ms/step\n",
      "Epoch 420/1000\n",
      "125/125 - 1s - loss: 0.0790 - my_accuracy: 0.9363 - val_loss: 0.0786 - val_my_accuracy: 0.9385 - 1s/epoch - 8ms/step\n",
      "Epoch 421/1000\n",
      "125/125 - 1s - loss: 0.0781 - my_accuracy: 0.9372 - val_loss: 0.0754 - val_my_accuracy: 0.9406 - 882ms/epoch - 7ms/step\n",
      "Epoch 422/1000\n",
      "125/125 - 1s - loss: 0.0782 - my_accuracy: 0.9369 - val_loss: 0.0774 - val_my_accuracy: 0.9376 - 1s/epoch - 9ms/step\n",
      "Epoch 423/1000\n",
      "125/125 - 1s - loss: 0.0784 - my_accuracy: 0.9375 - val_loss: 0.0912 - val_my_accuracy: 0.9233 - 887ms/epoch - 7ms/step\n",
      "Epoch 424/1000\n",
      "125/125 - 1s - loss: 0.0785 - my_accuracy: 0.9368 - val_loss: 0.0760 - val_my_accuracy: 0.9423 - 631ms/epoch - 5ms/step\n",
      "Epoch 425/1000\n",
      "125/125 - 1s - loss: 0.0792 - my_accuracy: 0.9372 - val_loss: 0.0777 - val_my_accuracy: 0.9349 - 668ms/epoch - 5ms/step\n",
      "Epoch 426/1000\n",
      "125/125 - 1s - loss: 0.0775 - my_accuracy: 0.9378 - val_loss: 0.0776 - val_my_accuracy: 0.9381 - 837ms/epoch - 7ms/step\n",
      "Epoch 427/1000\n",
      "125/125 - 1s - loss: 0.0753 - my_accuracy: 0.9401 - val_loss: 0.0759 - val_my_accuracy: 0.9405 - 744ms/epoch - 6ms/step\n",
      "Epoch 428/1000\n",
      "125/125 - 1s - loss: 0.0796 - my_accuracy: 0.9355 - val_loss: 0.0824 - val_my_accuracy: 0.9324 - 944ms/epoch - 8ms/step\n",
      "Epoch 429/1000\n",
      "125/125 - 1s - loss: 0.0801 - my_accuracy: 0.9349 - val_loss: 0.0731 - val_my_accuracy: 0.9443 - 1s/epoch - 8ms/step\n",
      "Epoch 430/1000\n",
      "125/125 - 1s - loss: 0.0789 - my_accuracy: 0.9367 - val_loss: 0.0835 - val_my_accuracy: 0.9291 - 1s/epoch - 8ms/step\n",
      "Epoch 431/1000\n",
      "125/125 - 1s - loss: 0.0814 - my_accuracy: 0.9337 - val_loss: 0.0768 - val_my_accuracy: 0.9424 - 953ms/epoch - 8ms/step\n",
      "Epoch 432/1000\n",
      "125/125 - 1s - loss: 0.0783 - my_accuracy: 0.9368 - val_loss: 0.0760 - val_my_accuracy: 0.9398 - 1s/epoch - 10ms/step\n",
      "Epoch 433/1000\n",
      "125/125 - 1s - loss: 0.0756 - my_accuracy: 0.9400 - val_loss: 0.0829 - val_my_accuracy: 0.9294 - 896ms/epoch - 7ms/step\n",
      "Epoch 434/1000\n",
      "125/125 - 1s - loss: 0.0785 - my_accuracy: 0.9368 - val_loss: 0.0784 - val_my_accuracy: 0.9388 - 847ms/epoch - 7ms/step\n",
      "Epoch 435/1000\n",
      "125/125 - 1s - loss: 0.0774 - my_accuracy: 0.9375 - val_loss: 0.0704 - val_my_accuracy: 0.9473 - 1s/epoch - 9ms/step\n",
      "Epoch 436/1000\n",
      "125/125 - 1s - loss: 0.0785 - my_accuracy: 0.9365 - val_loss: 0.0751 - val_my_accuracy: 0.9423 - 1s/epoch - 10ms/step\n",
      "Epoch 437/1000\n",
      "125/125 - 1s - loss: 0.0779 - my_accuracy: 0.9373 - val_loss: 0.0777 - val_my_accuracy: 0.9365 - 830ms/epoch - 7ms/step\n",
      "Epoch 438/1000\n",
      "125/125 - 1s - loss: 0.0797 - my_accuracy: 0.9351 - val_loss: 0.0759 - val_my_accuracy: 0.9395 - 842ms/epoch - 7ms/step\n",
      "Epoch 439/1000\n",
      "125/125 - 1s - loss: 0.0771 - my_accuracy: 0.9383 - val_loss: 0.0802 - val_my_accuracy: 0.9329 - 817ms/epoch - 7ms/step\n",
      "Epoch 440/1000\n",
      "125/125 - 1s - loss: 0.0801 - my_accuracy: 0.9351 - val_loss: 0.0777 - val_my_accuracy: 0.9376 - 770ms/epoch - 6ms/step\n",
      "Epoch 441/1000\n",
      "125/125 - 1s - loss: 0.0767 - my_accuracy: 0.9390 - val_loss: 0.0748 - val_my_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
      "Epoch 442/1000\n",
      "125/125 - 1s - loss: 0.0766 - my_accuracy: 0.9397 - val_loss: 0.0777 - val_my_accuracy: 0.9368 - 957ms/epoch - 8ms/step\n",
      "Epoch 443/1000\n",
      "125/125 - 1s - loss: 0.0817 - my_accuracy: 0.9331 - val_loss: 0.0823 - val_my_accuracy: 0.9310 - 840ms/epoch - 7ms/step\n",
      "Epoch 444/1000\n",
      "125/125 - 1s - loss: 0.0777 - my_accuracy: 0.9369 - val_loss: 0.0822 - val_my_accuracy: 0.9320 - 757ms/epoch - 6ms/step\n",
      "Epoch 445/1000\n",
      "125/125 - 1s - loss: 0.0781 - my_accuracy: 0.9377 - val_loss: 0.0791 - val_my_accuracy: 0.9347 - 816ms/epoch - 7ms/step\n",
      "Epoch 446/1000\n",
      "125/125 - 1s - loss: 0.0792 - my_accuracy: 0.9356 - val_loss: 0.0757 - val_my_accuracy: 0.9404 - 795ms/epoch - 6ms/step\n",
      "Epoch 447/1000\n",
      "125/125 - 1s - loss: 0.0825 - my_accuracy: 0.9327 - val_loss: 0.0860 - val_my_accuracy: 0.9265 - 796ms/epoch - 6ms/step\n",
      "Epoch 448/1000\n",
      "125/125 - 1s - loss: 0.0771 - my_accuracy: 0.9380 - val_loss: 0.0833 - val_my_accuracy: 0.9310 - 1s/epoch - 8ms/step\n",
      "Epoch 449/1000\n",
      "125/125 - 1s - loss: 0.0802 - my_accuracy: 0.9343 - val_loss: 0.0735 - val_my_accuracy: 0.9415 - 903ms/epoch - 7ms/step\n",
      "Epoch 450/1000\n",
      "125/125 - 1s - loss: 0.0786 - my_accuracy: 0.9363 - val_loss: 0.0836 - val_my_accuracy: 0.9321 - 1s/epoch - 8ms/step\n",
      "Epoch 451/1000\n",
      "125/125 - 1s - loss: 0.0758 - my_accuracy: 0.9392 - val_loss: 0.0736 - val_my_accuracy: 0.9412 - 1s/epoch - 9ms/step\n",
      "Epoch 452/1000\n",
      "125/125 - 1s - loss: 0.0781 - my_accuracy: 0.9358 - val_loss: 0.0820 - val_my_accuracy: 0.9305 - 952ms/epoch - 8ms/step\n",
      "Epoch 453/1000\n",
      "125/125 - 1s - loss: 0.0778 - my_accuracy: 0.9372 - val_loss: 0.0791 - val_my_accuracy: 0.9365 - 1s/epoch - 8ms/step\n",
      "Epoch 454/1000\n",
      "125/125 - 1s - loss: 0.0791 - my_accuracy: 0.9368 - val_loss: 0.0747 - val_my_accuracy: 0.9423 - 840ms/epoch - 7ms/step\n",
      "Epoch 455/1000\n",
      "125/125 - 1s - loss: 0.0760 - my_accuracy: 0.9393 - val_loss: 0.0743 - val_my_accuracy: 0.9395 - 1s/epoch - 10ms/step\n",
      "Epoch 456/1000\n",
      "125/125 - 1s - loss: 0.0768 - my_accuracy: 0.9383 - val_loss: 0.0807 - val_my_accuracy: 0.9383 - 1s/epoch - 8ms/step\n",
      "Epoch 457/1000\n",
      "125/125 - 1s - loss: 0.0773 - my_accuracy: 0.9379 - val_loss: 0.0739 - val_my_accuracy: 0.9408 - 1s/epoch - 8ms/step\n",
      "Epoch 458/1000\n",
      "125/125 - 1s - loss: 0.0799 - my_accuracy: 0.9344 - val_loss: 0.0927 - val_my_accuracy: 0.9203 - 818ms/epoch - 7ms/step\n",
      "Epoch 459/1000\n",
      "125/125 - 1s - loss: 0.0792 - my_accuracy: 0.9347 - val_loss: 0.0759 - val_my_accuracy: 0.9396 - 817ms/epoch - 7ms/step\n",
      "Epoch 460/1000\n",
      "125/125 - 1s - loss: 0.0752 - my_accuracy: 0.9397 - val_loss: 0.0747 - val_my_accuracy: 0.9402 - 925ms/epoch - 7ms/step\n",
      "Epoch 461/1000\n",
      "125/125 - 1s - loss: 0.0768 - my_accuracy: 0.9392 - val_loss: 0.0735 - val_my_accuracy: 0.9427 - 1s/epoch - 8ms/step\n",
      "Epoch 462/1000\n",
      "125/125 - 1s - loss: 0.0769 - my_accuracy: 0.9379 - val_loss: 0.0775 - val_my_accuracy: 0.9390 - 994ms/epoch - 8ms/step\n",
      "Epoch 463/1000\n",
      "125/125 - 1s - loss: 0.0768 - my_accuracy: 0.9375 - val_loss: 0.0777 - val_my_accuracy: 0.9360 - 818ms/epoch - 7ms/step\n",
      "Epoch 464/1000\n",
      "125/125 - 1s - loss: 0.0764 - my_accuracy: 0.9380 - val_loss: 0.0794 - val_my_accuracy: 0.9349 - 755ms/epoch - 6ms/step\n",
      "Epoch 465/1000\n",
      "125/125 - 1s - loss: 0.0753 - my_accuracy: 0.9399 - val_loss: 0.0740 - val_my_accuracy: 0.9423 - 872ms/epoch - 7ms/step\n",
      "Epoch 466/1000\n",
      "125/125 - 1s - loss: 0.0762 - my_accuracy: 0.9386 - val_loss: 0.0740 - val_my_accuracy: 0.9428 - 903ms/epoch - 7ms/step\n",
      "Epoch 467/1000\n",
      "125/125 - 1s - loss: 0.0752 - my_accuracy: 0.9394 - val_loss: 0.0771 - val_my_accuracy: 0.9376 - 845ms/epoch - 7ms/step\n",
      "Epoch 468/1000\n",
      "125/125 - 1s - loss: 0.0773 - my_accuracy: 0.9375 - val_loss: 0.0779 - val_my_accuracy: 0.9373 - 738ms/epoch - 6ms/step\n",
      "Epoch 469/1000\n",
      "125/125 - 1s - loss: 0.0761 - my_accuracy: 0.9385 - val_loss: 0.0717 - val_my_accuracy: 0.9465 - 755ms/epoch - 6ms/step\n",
      "Epoch 470/1000\n",
      "125/125 - 1s - loss: 0.0763 - my_accuracy: 0.9385 - val_loss: 0.0691 - val_my_accuracy: 0.9501 - 846ms/epoch - 7ms/step\n",
      "Epoch 471/1000\n",
      "125/125 - 1s - loss: 0.0784 - my_accuracy: 0.9358 - val_loss: 0.0802 - val_my_accuracy: 0.9315 - 1s/epoch - 8ms/step\n",
      "Epoch 472/1000\n",
      "125/125 - 1s - loss: 0.0780 - my_accuracy: 0.9365 - val_loss: 0.0752 - val_my_accuracy: 0.9426 - 1s/epoch - 9ms/step\n",
      "Epoch 473/1000\n",
      "125/125 - 1s - loss: 0.0753 - my_accuracy: 0.9391 - val_loss: 0.0782 - val_my_accuracy: 0.9362 - 966ms/epoch - 8ms/step\n",
      "Epoch 474/1000\n",
      "125/125 - 1s - loss: 0.0743 - my_accuracy: 0.9398 - val_loss: 0.0770 - val_my_accuracy: 0.9387 - 785ms/epoch - 6ms/step\n",
      "Epoch 475/1000\n",
      "125/125 - 1s - loss: 0.0774 - my_accuracy: 0.9377 - val_loss: 0.0729 - val_my_accuracy: 0.9446 - 778ms/epoch - 6ms/step\n",
      "Epoch 476/1000\n",
      "125/125 - 1s - loss: 0.0790 - my_accuracy: 0.9355 - val_loss: 0.0776 - val_my_accuracy: 0.9354 - 745ms/epoch - 6ms/step\n",
      "Epoch 477/1000\n",
      "125/125 - 1s - loss: 0.0783 - my_accuracy: 0.9371 - val_loss: 0.0742 - val_my_accuracy: 0.9423 - 923ms/epoch - 7ms/step\n",
      "Epoch 478/1000\n",
      "125/125 - 1s - loss: 0.0753 - my_accuracy: 0.9396 - val_loss: 0.0710 - val_my_accuracy: 0.9437 - 959ms/epoch - 8ms/step\n",
      "Epoch 479/1000\n",
      "125/125 - 1s - loss: 0.0727 - my_accuracy: 0.9421 - val_loss: 0.0689 - val_my_accuracy: 0.9486 - 777ms/epoch - 6ms/step\n",
      "Epoch 480/1000\n",
      "125/125 - 1s - loss: 0.0741 - my_accuracy: 0.9401 - val_loss: 0.0752 - val_my_accuracy: 0.9429 - 968ms/epoch - 8ms/step\n",
      "Epoch 481/1000\n",
      "125/125 - 1s - loss: 0.0753 - my_accuracy: 0.9402 - val_loss: 0.0792 - val_my_accuracy: 0.9340 - 1s/epoch - 8ms/step\n",
      "Epoch 482/1000\n",
      "125/125 - 1s - loss: 0.0768 - my_accuracy: 0.9372 - val_loss: 0.0859 - val_my_accuracy: 0.9309 - 1s/epoch - 9ms/step\n",
      "Epoch 483/1000\n",
      "125/125 - 1s - loss: 0.0770 - my_accuracy: 0.9376 - val_loss: 0.0763 - val_my_accuracy: 0.9380 - 880ms/epoch - 7ms/step\n",
      "Epoch 484/1000\n",
      "125/125 - 1s - loss: 0.0765 - my_accuracy: 0.9376 - val_loss: 0.0780 - val_my_accuracy: 0.9368 - 831ms/epoch - 7ms/step\n",
      "Epoch 485/1000\n",
      "125/125 - 1s - loss: 0.0763 - my_accuracy: 0.9382 - val_loss: 0.0972 - val_my_accuracy: 0.9180 - 826ms/epoch - 7ms/step\n",
      "Epoch 486/1000\n",
      "125/125 - 1s - loss: 0.0806 - my_accuracy: 0.9342 - val_loss: 0.0806 - val_my_accuracy: 0.9341 - 993ms/epoch - 8ms/step\n",
      "Epoch 487/1000\n",
      "125/125 - 1s - loss: 0.0757 - my_accuracy: 0.9391 - val_loss: 0.0739 - val_my_accuracy: 0.9410 - 1s/epoch - 8ms/step\n",
      "Epoch 488/1000\n",
      "125/125 - 1s - loss: 0.0795 - my_accuracy: 0.9355 - val_loss: 0.0811 - val_my_accuracy: 0.9351 - 971ms/epoch - 8ms/step\n",
      "Epoch 489/1000\n",
      "125/125 - 1s - loss: 0.0784 - my_accuracy: 0.9365 - val_loss: 0.0797 - val_my_accuracy: 0.9347 - 914ms/epoch - 7ms/step\n",
      "Epoch 490/1000\n",
      "125/125 - 1s - loss: 0.0758 - my_accuracy: 0.9389 - val_loss: 0.0709 - val_my_accuracy: 0.9436 - 1s/epoch - 9ms/step\n",
      "Epoch 491/1000\n",
      "125/125 - 1s - loss: 0.0732 - my_accuracy: 0.9416 - val_loss: 0.0735 - val_my_accuracy: 0.9417 - 907ms/epoch - 7ms/step\n",
      "Epoch 492/1000\n",
      "125/125 - 1s - loss: 0.0760 - my_accuracy: 0.9380 - val_loss: 0.0799 - val_my_accuracy: 0.9366 - 847ms/epoch - 7ms/step\n",
      "Epoch 493/1000\n",
      "125/125 - 1s - loss: 0.0752 - my_accuracy: 0.9394 - val_loss: 0.0785 - val_my_accuracy: 0.9339 - 769ms/epoch - 6ms/step\n",
      "Epoch 494/1000\n",
      "125/125 - 1s - loss: 0.0752 - my_accuracy: 0.9395 - val_loss: 0.0748 - val_my_accuracy: 0.9401 - 743ms/epoch - 6ms/step\n",
      "Epoch 495/1000\n",
      "125/125 - 1s - loss: 0.0771 - my_accuracy: 0.9366 - val_loss: 0.0730 - val_my_accuracy: 0.9412 - 946ms/epoch - 8ms/step\n",
      "Epoch 496/1000\n",
      "125/125 - 1s - loss: 0.0787 - my_accuracy: 0.9360 - val_loss: 0.0766 - val_my_accuracy: 0.9390 - 842ms/epoch - 7ms/step\n",
      "Epoch 497/1000\n",
      "125/125 - 1s - loss: 0.0778 - my_accuracy: 0.9362 - val_loss: 0.0721 - val_my_accuracy: 0.9454 - 818ms/epoch - 7ms/step\n",
      "Epoch 498/1000\n",
      "125/125 - 1s - loss: 0.0747 - my_accuracy: 0.9394 - val_loss: 0.0742 - val_my_accuracy: 0.9406 - 720ms/epoch - 6ms/step\n",
      "Epoch 499/1000\n",
      "125/125 - 1s - loss: 0.0747 - my_accuracy: 0.9393 - val_loss: 0.0818 - val_my_accuracy: 0.9344 - 644ms/epoch - 5ms/step\n",
      "Epoch 500/1000\n",
      "125/125 - 1s - loss: 0.0746 - my_accuracy: 0.9397 - val_loss: 0.0802 - val_my_accuracy: 0.9351 - 541ms/epoch - 4ms/step\n",
      "Epoch 501/1000\n",
      "125/125 - 0s - loss: 0.0735 - my_accuracy: 0.9410 - val_loss: 0.0770 - val_my_accuracy: 0.9382 - 464ms/epoch - 4ms/step\n",
      "Epoch 502/1000\n",
      "125/125 - 0s - loss: 0.0758 - my_accuracy: 0.9391 - val_loss: 0.0706 - val_my_accuracy: 0.9454 - 484ms/epoch - 4ms/step\n",
      "Epoch 503/1000\n",
      "125/125 - 0s - loss: 0.0754 - my_accuracy: 0.9395 - val_loss: 0.0747 - val_my_accuracy: 0.9404 - 497ms/epoch - 4ms/step\n",
      "Epoch 504/1000\n",
      "125/125 - 1s - loss: 0.0758 - my_accuracy: 0.9388 - val_loss: 0.0711 - val_my_accuracy: 0.9448 - 560ms/epoch - 4ms/step\n",
      "Epoch 505/1000\n",
      "125/125 - 1s - loss: 0.0752 - my_accuracy: 0.9396 - val_loss: 0.0775 - val_my_accuracy: 0.9367 - 530ms/epoch - 4ms/step\n",
      "Epoch 506/1000\n",
      "125/125 - 0s - loss: 0.0721 - my_accuracy: 0.9420 - val_loss: 0.0724 - val_my_accuracy: 0.9440 - 481ms/epoch - 4ms/step\n",
      "Epoch 507/1000\n",
      "125/125 - 0s - loss: 0.0743 - my_accuracy: 0.9400 - val_loss: 0.0687 - val_my_accuracy: 0.9491 - 459ms/epoch - 4ms/step\n",
      "Epoch 508/1000\n",
      "125/125 - 0s - loss: 0.0822 - my_accuracy: 0.9320 - val_loss: 0.0755 - val_my_accuracy: 0.9395 - 499ms/epoch - 4ms/step\n",
      "Epoch 509/1000\n",
      "125/125 - 1s - loss: 0.0734 - my_accuracy: 0.9402 - val_loss: 0.0722 - val_my_accuracy: 0.9406 - 546ms/epoch - 4ms/step\n",
      "Epoch 510/1000\n",
      "125/125 - 0s - loss: 0.0746 - my_accuracy: 0.9393 - val_loss: 0.0712 - val_my_accuracy: 0.9462 - 460ms/epoch - 4ms/step\n",
      "Epoch 511/1000\n",
      "125/125 - 0s - loss: 0.0765 - my_accuracy: 0.9383 - val_loss: 0.0715 - val_my_accuracy: 0.9443 - 458ms/epoch - 4ms/step\n",
      "Epoch 512/1000\n",
      "125/125 - 0s - loss: 0.0737 - my_accuracy: 0.9407 - val_loss: 0.0741 - val_my_accuracy: 0.9431 - 497ms/epoch - 4ms/step\n",
      "Epoch 513/1000\n",
      "125/125 - 0s - loss: 0.0745 - my_accuracy: 0.9393 - val_loss: 0.0815 - val_my_accuracy: 0.9301 - 466ms/epoch - 4ms/step\n",
      "Epoch 514/1000\n",
      "125/125 - 0s - loss: 0.0736 - my_accuracy: 0.9404 - val_loss: 0.0750 - val_my_accuracy: 0.9405 - 490ms/epoch - 4ms/step\n",
      "Epoch 515/1000\n",
      "125/125 - 0s - loss: 0.0737 - my_accuracy: 0.9408 - val_loss: 0.0817 - val_my_accuracy: 0.9310 - 467ms/epoch - 4ms/step\n",
      "Epoch 516/1000\n",
      "125/125 - 0s - loss: 0.0781 - my_accuracy: 0.9363 - val_loss: 0.0804 - val_my_accuracy: 0.9315 - 472ms/epoch - 4ms/step\n",
      "Epoch 517/1000\n",
      "125/125 - 0s - loss: 0.0755 - my_accuracy: 0.9385 - val_loss: 0.0714 - val_my_accuracy: 0.9432 - 460ms/epoch - 4ms/step\n",
      "Epoch 518/1000\n",
      "125/125 - 0s - loss: 0.0740 - my_accuracy: 0.9392 - val_loss: 0.0744 - val_my_accuracy: 0.9424 - 452ms/epoch - 4ms/step\n",
      "Epoch 519/1000\n",
      "125/125 - 0s - loss: 0.0784 - my_accuracy: 0.9355 - val_loss: 0.0716 - val_my_accuracy: 0.9431 - 478ms/epoch - 4ms/step\n",
      "Epoch 520/1000\n",
      "125/125 - 0s - loss: 0.0745 - my_accuracy: 0.9392 - val_loss: 0.0787 - val_my_accuracy: 0.9348 - 469ms/epoch - 4ms/step\n",
      "Epoch 521/1000\n",
      "125/125 - 0s - loss: 0.0761 - my_accuracy: 0.9381 - val_loss: 0.0788 - val_my_accuracy: 0.9367 - 467ms/epoch - 4ms/step\n",
      "Epoch 522/1000\n",
      "125/125 - 0s - loss: 0.0770 - my_accuracy: 0.9377 - val_loss: 0.0688 - val_my_accuracy: 0.9471 - 478ms/epoch - 4ms/step\n",
      "Epoch 523/1000\n",
      "125/125 - 0s - loss: 0.0726 - my_accuracy: 0.9415 - val_loss: 0.0740 - val_my_accuracy: 0.9399 - 456ms/epoch - 4ms/step\n",
      "Epoch 524/1000\n",
      "125/125 - 0s - loss: 0.0744 - my_accuracy: 0.9385 - val_loss: 0.0764 - val_my_accuracy: 0.9366 - 434ms/epoch - 3ms/step\n",
      "Epoch 525/1000\n",
      "125/125 - 0s - loss: 0.0752 - my_accuracy: 0.9383 - val_loss: 0.0679 - val_my_accuracy: 0.9474 - 474ms/epoch - 4ms/step\n",
      "Epoch 526/1000\n",
      "125/125 - 0s - loss: 0.0725 - my_accuracy: 0.9416 - val_loss: 0.0684 - val_my_accuracy: 0.9479 - 436ms/epoch - 3ms/step\n",
      "Epoch 527/1000\n",
      "125/125 - 0s - loss: 0.0741 - my_accuracy: 0.9406 - val_loss: 0.0769 - val_my_accuracy: 0.9376 - 498ms/epoch - 4ms/step\n",
      "Epoch 528/1000\n",
      "125/125 - 0s - loss: 0.0736 - my_accuracy: 0.9404 - val_loss: 0.0761 - val_my_accuracy: 0.9373 - 466ms/epoch - 4ms/step\n",
      "Epoch 529/1000\n",
      "125/125 - 0s - loss: 0.0742 - my_accuracy: 0.9408 - val_loss: 0.0673 - val_my_accuracy: 0.9491 - 490ms/epoch - 4ms/step\n",
      "Epoch 530/1000\n",
      "125/125 - 0s - loss: 0.0798 - my_accuracy: 0.9341 - val_loss: 0.0756 - val_my_accuracy: 0.9370 - 464ms/epoch - 4ms/step\n",
      "Epoch 531/1000\n",
      "125/125 - 0s - loss: 0.0726 - my_accuracy: 0.9417 - val_loss: 0.0864 - val_my_accuracy: 0.9257 - 481ms/epoch - 4ms/step\n",
      "Epoch 532/1000\n",
      "125/125 - 0s - loss: 0.0736 - my_accuracy: 0.9400 - val_loss: 0.0839 - val_my_accuracy: 0.9330 - 492ms/epoch - 4ms/step\n",
      "Epoch 533/1000\n",
      "125/125 - 1s - loss: 0.0734 - my_accuracy: 0.9403 - val_loss: 0.0694 - val_my_accuracy: 0.9463 - 503ms/epoch - 4ms/step\n",
      "Epoch 534/1000\n",
      "125/125 - 0s - loss: 0.0759 - my_accuracy: 0.9375 - val_loss: 0.0723 - val_my_accuracy: 0.9415 - 468ms/epoch - 4ms/step\n",
      "Epoch 535/1000\n",
      "125/125 - 0s - loss: 0.0755 - my_accuracy: 0.9389 - val_loss: 0.0696 - val_my_accuracy: 0.9448 - 470ms/epoch - 4ms/step\n",
      "Epoch 536/1000\n",
      "125/125 - 0s - loss: 0.0772 - my_accuracy: 0.9353 - val_loss: 0.0728 - val_my_accuracy: 0.9402 - 498ms/epoch - 4ms/step\n",
      "Epoch 537/1000\n",
      "125/125 - 1s - loss: 0.0729 - my_accuracy: 0.9413 - val_loss: 0.0735 - val_my_accuracy: 0.9410 - 555ms/epoch - 4ms/step\n",
      "Epoch 538/1000\n",
      "125/125 - 0s - loss: 0.0761 - my_accuracy: 0.9366 - val_loss: 0.0785 - val_my_accuracy: 0.9333 - 493ms/epoch - 4ms/step\n",
      "Epoch 539/1000\n",
      "125/125 - 1s - loss: 0.0733 - my_accuracy: 0.9401 - val_loss: 0.0818 - val_my_accuracy: 0.9327 - 521ms/epoch - 4ms/step\n",
      "Epoch 540/1000\n",
      "125/125 - 0s - loss: 0.0731 - my_accuracy: 0.9410 - val_loss: 0.0790 - val_my_accuracy: 0.9356 - 490ms/epoch - 4ms/step\n",
      "Epoch 541/1000\n",
      "125/125 - 1s - loss: 0.0721 - my_accuracy: 0.9417 - val_loss: 0.0865 - val_my_accuracy: 0.9243 - 618ms/epoch - 5ms/step\n",
      "Epoch 542/1000\n",
      "125/125 - 1s - loss: 0.0744 - my_accuracy: 0.9389 - val_loss: 0.0689 - val_my_accuracy: 0.9442 - 702ms/epoch - 6ms/step\n",
      "Epoch 543/1000\n",
      "125/125 - 1s - loss: 0.0720 - my_accuracy: 0.9418 - val_loss: 0.0713 - val_my_accuracy: 0.9462 - 580ms/epoch - 5ms/step\n",
      "Epoch 544/1000\n",
      "125/125 - 1s - loss: 0.0736 - my_accuracy: 0.9405 - val_loss: 0.0774 - val_my_accuracy: 0.9354 - 527ms/epoch - 4ms/step\n",
      "Epoch 545/1000\n",
      "125/125 - 1s - loss: 0.0737 - my_accuracy: 0.9401 - val_loss: 0.0746 - val_my_accuracy: 0.9426 - 513ms/epoch - 4ms/step\n",
      "Epoch 546/1000\n",
      "125/125 - 1s - loss: 0.0731 - my_accuracy: 0.9403 - val_loss: 0.0774 - val_my_accuracy: 0.9370 - 520ms/epoch - 4ms/step\n",
      "Epoch 547/1000\n",
      "125/125 - 0s - loss: 0.0727 - my_accuracy: 0.9406 - val_loss: 0.0752 - val_my_accuracy: 0.9361 - 434ms/epoch - 3ms/step\n",
      "Epoch 548/1000\n",
      "125/125 - 0s - loss: 0.0737 - my_accuracy: 0.9406 - val_loss: 0.0728 - val_my_accuracy: 0.9398 - 428ms/epoch - 3ms/step\n",
      "Epoch 549/1000\n",
      "125/125 - 0s - loss: 0.0723 - my_accuracy: 0.9419 - val_loss: 0.0751 - val_my_accuracy: 0.9393 - 463ms/epoch - 4ms/step\n",
      "Epoch 550/1000\n",
      "125/125 - 1s - loss: 0.0751 - my_accuracy: 0.9376 - val_loss: 0.0715 - val_my_accuracy: 0.9449 - 534ms/epoch - 4ms/step\n",
      "Epoch 551/1000\n",
      "125/125 - 0s - loss: 0.0721 - my_accuracy: 0.9413 - val_loss: 0.0804 - val_my_accuracy: 0.9371 - 451ms/epoch - 4ms/step\n",
      "Epoch 552/1000\n",
      "125/125 - 0s - loss: 0.0742 - my_accuracy: 0.9393 - val_loss: 0.0792 - val_my_accuracy: 0.9346 - 495ms/epoch - 4ms/step\n",
      "Epoch 553/1000\n",
      "125/125 - 0s - loss: 0.0724 - my_accuracy: 0.9415 - val_loss: 0.0779 - val_my_accuracy: 0.9372 - 438ms/epoch - 4ms/step\n",
      "Epoch 554/1000\n",
      "125/125 - 0s - loss: 0.0720 - my_accuracy: 0.9424 - val_loss: 0.0674 - val_my_accuracy: 0.9482 - 488ms/epoch - 4ms/step\n",
      "Epoch 555/1000\n",
      "125/125 - 0s - loss: 0.0742 - my_accuracy: 0.9394 - val_loss: 0.0894 - val_my_accuracy: 0.9285 - 424ms/epoch - 3ms/step\n",
      "Epoch 556/1000\n",
      "125/125 - 0s - loss: 0.0731 - my_accuracy: 0.9410 - val_loss: 0.0791 - val_my_accuracy: 0.9360 - 448ms/epoch - 4ms/step\n",
      "Epoch 557/1000\n",
      "125/125 - 0s - loss: 0.0734 - my_accuracy: 0.9408 - val_loss: 0.0710 - val_my_accuracy: 0.9445 - 475ms/epoch - 4ms/step\n",
      "Epoch 558/1000\n",
      "125/125 - 1s - loss: 0.0756 - my_accuracy: 0.9383 - val_loss: 0.0745 - val_my_accuracy: 0.9406 - 509ms/epoch - 4ms/step\n",
      "Epoch 559/1000\n",
      "125/125 - 0s - loss: 0.0741 - my_accuracy: 0.9399 - val_loss: 0.0747 - val_my_accuracy: 0.9393 - 481ms/epoch - 4ms/step\n",
      "Epoch 560/1000\n",
      "125/125 - 1s - loss: 0.0723 - my_accuracy: 0.9408 - val_loss: 0.0691 - val_my_accuracy: 0.9473 - 501ms/epoch - 4ms/step\n",
      "Epoch 561/1000\n",
      "125/125 - 0s - loss: 0.0709 - my_accuracy: 0.9438 - val_loss: 0.0759 - val_my_accuracy: 0.9392 - 453ms/epoch - 4ms/step\n",
      "Epoch 562/1000\n",
      "125/125 - 0s - loss: 0.0737 - my_accuracy: 0.9406 - val_loss: 0.0746 - val_my_accuracy: 0.9405 - 462ms/epoch - 4ms/step\n",
      "Epoch 563/1000\n",
      "125/125 - 0s - loss: 0.0727 - my_accuracy: 0.9400 - val_loss: 0.0738 - val_my_accuracy: 0.9408 - 482ms/epoch - 4ms/step\n",
      "Epoch 564/1000\n",
      "125/125 - 0s - loss: 0.0710 - my_accuracy: 0.9429 - val_loss: 0.0734 - val_my_accuracy: 0.9413 - 451ms/epoch - 4ms/step\n",
      "Epoch 565/1000\n",
      "125/125 - 0s - loss: 0.0752 - my_accuracy: 0.9381 - val_loss: 0.0724 - val_my_accuracy: 0.9412 - 455ms/epoch - 4ms/step\n",
      "Epoch 566/1000\n",
      "125/125 - 0s - loss: 0.0740 - my_accuracy: 0.9391 - val_loss: 0.0686 - val_my_accuracy: 0.9448 - 463ms/epoch - 4ms/step\n",
      "Epoch 567/1000\n",
      "125/125 - 0s - loss: 0.0721 - my_accuracy: 0.9416 - val_loss: 0.0785 - val_my_accuracy: 0.9368 - 460ms/epoch - 4ms/step\n",
      "Epoch 568/1000\n",
      "125/125 - 0s - loss: 0.0742 - my_accuracy: 0.9401 - val_loss: 0.0693 - val_my_accuracy: 0.9440 - 493ms/epoch - 4ms/step\n",
      "Epoch 569/1000\n",
      "125/125 - 0s - loss: 0.0739 - my_accuracy: 0.9396 - val_loss: 0.0722 - val_my_accuracy: 0.9408 - 452ms/epoch - 4ms/step\n",
      "Epoch 570/1000\n",
      "125/125 - 0s - loss: 0.0760 - my_accuracy: 0.9369 - val_loss: 0.0713 - val_my_accuracy: 0.9402 - 431ms/epoch - 3ms/step\n",
      "Epoch 571/1000\n",
      "125/125 - 0s - loss: 0.0724 - my_accuracy: 0.9407 - val_loss: 0.0657 - val_my_accuracy: 0.9489 - 426ms/epoch - 3ms/step\n",
      "Epoch 572/1000\n",
      "125/125 - 0s - loss: 0.0720 - my_accuracy: 0.9419 - val_loss: 0.0685 - val_my_accuracy: 0.9451 - 484ms/epoch - 4ms/step\n",
      "Epoch 573/1000\n",
      "125/125 - 0s - loss: 0.0716 - my_accuracy: 0.9411 - val_loss: 0.0708 - val_my_accuracy: 0.9421 - 484ms/epoch - 4ms/step\n",
      "Epoch 574/1000\n",
      "125/125 - 1s - loss: 0.0723 - my_accuracy: 0.9405 - val_loss: 0.0773 - val_my_accuracy: 0.9378 - 517ms/epoch - 4ms/step\n",
      "Epoch 575/1000\n",
      "125/125 - 1s - loss: 0.0773 - my_accuracy: 0.9369 - val_loss: 0.0634 - val_my_accuracy: 0.9532 - 543ms/epoch - 4ms/step\n",
      "Epoch 576/1000\n",
      "125/125 - 0s - loss: 0.0724 - my_accuracy: 0.9404 - val_loss: 0.0737 - val_my_accuracy: 0.9418 - 475ms/epoch - 4ms/step\n",
      "Epoch 577/1000\n",
      "125/125 - 0s - loss: 0.0701 - my_accuracy: 0.9445 - val_loss: 0.0755 - val_my_accuracy: 0.9398 - 450ms/epoch - 4ms/step\n",
      "Epoch 578/1000\n",
      "125/125 - 0s - loss: 0.0745 - my_accuracy: 0.9383 - val_loss: 0.0853 - val_my_accuracy: 0.9274 - 476ms/epoch - 4ms/step\n",
      "Epoch 579/1000\n",
      "125/125 - 0s - loss: 0.0717 - my_accuracy: 0.9419 - val_loss: 0.0725 - val_my_accuracy: 0.9410 - 440ms/epoch - 4ms/step\n",
      "Epoch 580/1000\n",
      "125/125 - 0s - loss: 0.0747 - my_accuracy: 0.9401 - val_loss: 0.0778 - val_my_accuracy: 0.9373 - 485ms/epoch - 4ms/step\n",
      "Epoch 581/1000\n",
      "125/125 - 0s - loss: 0.0738 - my_accuracy: 0.9399 - val_loss: 0.0704 - val_my_accuracy: 0.9443 - 444ms/epoch - 4ms/step\n",
      "Epoch 582/1000\n",
      "125/125 - 0s - loss: 0.0706 - my_accuracy: 0.9425 - val_loss: 0.0714 - val_my_accuracy: 0.9414 - 483ms/epoch - 4ms/step\n",
      "Epoch 583/1000\n",
      "125/125 - 0s - loss: 0.0747 - my_accuracy: 0.9395 - val_loss: 0.0730 - val_my_accuracy: 0.9405 - 467ms/epoch - 4ms/step\n",
      "Epoch 584/1000\n",
      "125/125 - 1s - loss: 0.0719 - my_accuracy: 0.9416 - val_loss: 0.0673 - val_my_accuracy: 0.9473 - 560ms/epoch - 4ms/step\n",
      "Epoch 585/1000\n",
      "125/125 - 0s - loss: 0.0708 - my_accuracy: 0.9427 - val_loss: 0.0711 - val_my_accuracy: 0.9437 - 433ms/epoch - 3ms/step\n",
      "Epoch 586/1000\n",
      "125/125 - 0s - loss: 0.0710 - my_accuracy: 0.9430 - val_loss: 0.0682 - val_my_accuracy: 0.9452 - 492ms/epoch - 4ms/step\n",
      "Epoch 587/1000\n",
      "125/125 - 0s - loss: 0.0685 - my_accuracy: 0.9460 - val_loss: 0.0668 - val_my_accuracy: 0.9467 - 459ms/epoch - 4ms/step\n",
      "Epoch 588/1000\n",
      "125/125 - 0s - loss: 0.0724 - my_accuracy: 0.9407 - val_loss: 0.0822 - val_my_accuracy: 0.9295 - 480ms/epoch - 4ms/step\n",
      "Epoch 589/1000\n",
      "125/125 - 0s - loss: 0.0745 - my_accuracy: 0.9397 - val_loss: 0.0774 - val_my_accuracy: 0.9368 - 422ms/epoch - 3ms/step\n",
      "Epoch 590/1000\n",
      "125/125 - 0s - loss: 0.0741 - my_accuracy: 0.9390 - val_loss: 0.0742 - val_my_accuracy: 0.9428 - 445ms/epoch - 4ms/step\n",
      "Epoch 591/1000\n",
      "125/125 - 0s - loss: 0.0745 - my_accuracy: 0.9387 - val_loss: 0.0693 - val_my_accuracy: 0.9460 - 482ms/epoch - 4ms/step\n",
      "Epoch 592/1000\n",
      "125/125 - 0s - loss: 0.0698 - my_accuracy: 0.9438 - val_loss: 0.0722 - val_my_accuracy: 0.9404 - 498ms/epoch - 4ms/step\n",
      "Epoch 593/1000\n",
      "125/125 - 0s - loss: 0.0702 - my_accuracy: 0.9434 - val_loss: 0.0719 - val_my_accuracy: 0.9410 - 490ms/epoch - 4ms/step\n",
      "Epoch 594/1000\n",
      "125/125 - 1s - loss: 0.0716 - my_accuracy: 0.9415 - val_loss: 0.0723 - val_my_accuracy: 0.9424 - 541ms/epoch - 4ms/step\n",
      "Epoch 595/1000\n",
      "125/125 - 1s - loss: 0.0689 - my_accuracy: 0.9448 - val_loss: 0.0727 - val_my_accuracy: 0.9442 - 630ms/epoch - 5ms/step\n",
      "Epoch 596/1000\n",
      "125/125 - 1s - loss: 0.0713 - my_accuracy: 0.9418 - val_loss: 0.0768 - val_my_accuracy: 0.9380 - 629ms/epoch - 5ms/step\n",
      "Epoch 597/1000\n",
      "125/125 - 1s - loss: 0.0705 - my_accuracy: 0.9433 - val_loss: 0.0715 - val_my_accuracy: 0.9410 - 657ms/epoch - 5ms/step\n",
      "Epoch 598/1000\n",
      "125/125 - 1s - loss: 0.0729 - my_accuracy: 0.9410 - val_loss: 0.0733 - val_my_accuracy: 0.9387 - 643ms/epoch - 5ms/step\n",
      "Epoch 599/1000\n",
      "125/125 - 1s - loss: 0.0702 - my_accuracy: 0.9416 - val_loss: 0.0682 - val_my_accuracy: 0.9454 - 639ms/epoch - 5ms/step\n",
      "Epoch 600/1000\n",
      "125/125 - 1s - loss: 0.0698 - my_accuracy: 0.9438 - val_loss: 0.0660 - val_my_accuracy: 0.9492 - 532ms/epoch - 4ms/step\n",
      "Epoch 601/1000\n",
      "125/125 - 0s - loss: 0.0704 - my_accuracy: 0.9433 - val_loss: 0.0634 - val_my_accuracy: 0.9535 - 451ms/epoch - 4ms/step\n",
      "Epoch 602/1000\n",
      "125/125 - 1s - loss: 0.0694 - my_accuracy: 0.9444 - val_loss: 0.0704 - val_my_accuracy: 0.9428 - 515ms/epoch - 4ms/step\n",
      "Epoch 603/1000\n",
      "125/125 - 0s - loss: 0.0685 - my_accuracy: 0.9448 - val_loss: 0.0707 - val_my_accuracy: 0.9419 - 480ms/epoch - 4ms/step\n",
      "Epoch 604/1000\n",
      "125/125 - 0s - loss: 0.0707 - my_accuracy: 0.9425 - val_loss: 0.0665 - val_my_accuracy: 0.9483 - 435ms/epoch - 3ms/step\n",
      "Epoch 605/1000\n",
      "125/125 - 0s - loss: 0.0697 - my_accuracy: 0.9437 - val_loss: 0.0761 - val_my_accuracy: 0.9371 - 462ms/epoch - 4ms/step\n",
      "Epoch 606/1000\n",
      "125/125 - 0s - loss: 0.0754 - my_accuracy: 0.9373 - val_loss: 0.0675 - val_my_accuracy: 0.9471 - 488ms/epoch - 4ms/step\n",
      "Epoch 607/1000\n",
      "125/125 - 1s - loss: 0.0705 - my_accuracy: 0.9429 - val_loss: 0.0794 - val_my_accuracy: 0.9346 - 543ms/epoch - 4ms/step\n",
      "Epoch 608/1000\n",
      "125/125 - 0s - loss: 0.0715 - my_accuracy: 0.9410 - val_loss: 0.0685 - val_my_accuracy: 0.9443 - 467ms/epoch - 4ms/step\n",
      "Epoch 609/1000\n",
      "125/125 - 0s - loss: 0.0696 - my_accuracy: 0.9433 - val_loss: 0.0690 - val_my_accuracy: 0.9454 - 457ms/epoch - 4ms/step\n",
      "Epoch 610/1000\n",
      "125/125 - 0s - loss: 0.0729 - my_accuracy: 0.9398 - val_loss: 0.0687 - val_my_accuracy: 0.9453 - 417ms/epoch - 3ms/step\n",
      "Epoch 611/1000\n",
      "125/125 - 0s - loss: 0.0744 - my_accuracy: 0.9390 - val_loss: 0.0769 - val_my_accuracy: 0.9372 - 461ms/epoch - 4ms/step\n",
      "Epoch 612/1000\n",
      "125/125 - 0s - loss: 0.0693 - my_accuracy: 0.9445 - val_loss: 0.0714 - val_my_accuracy: 0.9429 - 490ms/epoch - 4ms/step\n",
      "Epoch 613/1000\n",
      "125/125 - 0s - loss: 0.0687 - my_accuracy: 0.9441 - val_loss: 0.0742 - val_my_accuracy: 0.9429 - 475ms/epoch - 4ms/step\n",
      "Epoch 614/1000\n",
      "125/125 - 0s - loss: 0.0729 - my_accuracy: 0.9411 - val_loss: 0.0691 - val_my_accuracy: 0.9472 - 468ms/epoch - 4ms/step\n",
      "Epoch 615/1000\n",
      "125/125 - 0s - loss: 0.0699 - my_accuracy: 0.9428 - val_loss: 0.0792 - val_my_accuracy: 0.9349 - 472ms/epoch - 4ms/step\n",
      "Epoch 616/1000\n",
      "125/125 - 0s - loss: 0.0695 - my_accuracy: 0.9447 - val_loss: 0.0667 - val_my_accuracy: 0.9465 - 466ms/epoch - 4ms/step\n",
      "Epoch 617/1000\n",
      "125/125 - 0s - loss: 0.0726 - my_accuracy: 0.9413 - val_loss: 0.0738 - val_my_accuracy: 0.9395 - 461ms/epoch - 4ms/step\n",
      "Epoch 618/1000\n",
      "125/125 - 1s - loss: 0.0739 - my_accuracy: 0.9396 - val_loss: 0.0732 - val_my_accuracy: 0.9406 - 500ms/epoch - 4ms/step\n",
      "Epoch 619/1000\n",
      "125/125 - 1s - loss: 0.0698 - my_accuracy: 0.9436 - val_loss: 0.0696 - val_my_accuracy: 0.9424 - 517ms/epoch - 4ms/step\n",
      "Epoch 620/1000\n",
      "125/125 - 1s - loss: 0.0708 - my_accuracy: 0.9422 - val_loss: 0.0650 - val_my_accuracy: 0.9518 - 575ms/epoch - 5ms/step\n",
      "Epoch 621/1000\n",
      "125/125 - 1s - loss: 0.0726 - my_accuracy: 0.9409 - val_loss: 0.0699 - val_my_accuracy: 0.9421 - 744ms/epoch - 6ms/step\n",
      "Epoch 622/1000\n",
      "125/125 - 1s - loss: 0.0674 - my_accuracy: 0.9455 - val_loss: 0.0644 - val_my_accuracy: 0.9520 - 681ms/epoch - 5ms/step\n",
      "Epoch 623/1000\n",
      "125/125 - 1s - loss: 0.0697 - my_accuracy: 0.9442 - val_loss: 0.0736 - val_my_accuracy: 0.9371 - 607ms/epoch - 5ms/step\n",
      "Epoch 624/1000\n",
      "125/125 - 1s - loss: 0.0677 - my_accuracy: 0.9453 - val_loss: 0.0714 - val_my_accuracy: 0.9432 - 588ms/epoch - 5ms/step\n",
      "Epoch 625/1000\n",
      "125/125 - 1s - loss: 0.0700 - my_accuracy: 0.9435 - val_loss: 0.0684 - val_my_accuracy: 0.9456 - 623ms/epoch - 5ms/step\n",
      "Epoch 626/1000\n",
      "125/125 - 1s - loss: 0.0705 - my_accuracy: 0.9427 - val_loss: 0.0780 - val_my_accuracy: 0.9327 - 643ms/epoch - 5ms/step\n",
      "Epoch 627/1000\n",
      "125/125 - 1s - loss: 0.0683 - my_accuracy: 0.9451 - val_loss: 0.0688 - val_my_accuracy: 0.9446 - 677ms/epoch - 5ms/step\n",
      "Epoch 628/1000\n",
      "125/125 - 1s - loss: 0.0690 - my_accuracy: 0.9443 - val_loss: 0.0698 - val_my_accuracy: 0.9476 - 768ms/epoch - 6ms/step\n",
      "Epoch 629/1000\n",
      "125/125 - 1s - loss: 0.0710 - my_accuracy: 0.9425 - val_loss: 0.0644 - val_my_accuracy: 0.9503 - 715ms/epoch - 6ms/step\n",
      "Epoch 630/1000\n",
      "125/125 - 1s - loss: 0.0692 - my_accuracy: 0.9441 - val_loss: 0.0674 - val_my_accuracy: 0.9459 - 744ms/epoch - 6ms/step\n",
      "Epoch 631/1000\n",
      "125/125 - 1s - loss: 0.0700 - my_accuracy: 0.9420 - val_loss: 0.0755 - val_my_accuracy: 0.9354 - 751ms/epoch - 6ms/step\n",
      "Epoch 632/1000\n",
      "125/125 - 1s - loss: 0.0727 - my_accuracy: 0.9403 - val_loss: 0.0697 - val_my_accuracy: 0.9452 - 705ms/epoch - 6ms/step\n",
      "Epoch 633/1000\n",
      "125/125 - 1s - loss: 0.0680 - my_accuracy: 0.9450 - val_loss: 0.0803 - val_my_accuracy: 0.9336 - 671ms/epoch - 5ms/step\n",
      "Epoch 634/1000\n",
      "125/125 - 1s - loss: 0.0693 - my_accuracy: 0.9435 - val_loss: 0.0742 - val_my_accuracy: 0.9392 - 696ms/epoch - 6ms/step\n",
      "Epoch 635/1000\n",
      "125/125 - 1s - loss: 0.0741 - my_accuracy: 0.9383 - val_loss: 0.0685 - val_my_accuracy: 0.9442 - 573ms/epoch - 5ms/step\n",
      "Epoch 636/1000\n",
      "125/125 - 1s - loss: 0.0707 - my_accuracy: 0.9427 - val_loss: 0.0659 - val_my_accuracy: 0.9462 - 629ms/epoch - 5ms/step\n",
      "Epoch 637/1000\n",
      "125/125 - 1s - loss: 0.0701 - my_accuracy: 0.9428 - val_loss: 0.0722 - val_my_accuracy: 0.9418 - 657ms/epoch - 5ms/step\n",
      "Epoch 638/1000\n",
      "125/125 - 1s - loss: 0.0663 - my_accuracy: 0.9468 - val_loss: 0.0699 - val_my_accuracy: 0.9424 - 646ms/epoch - 5ms/step\n",
      "Epoch 639/1000\n",
      "125/125 - 1s - loss: 0.0713 - my_accuracy: 0.9417 - val_loss: 0.0694 - val_my_accuracy: 0.9425 - 702ms/epoch - 6ms/step\n",
      "Epoch 640/1000\n",
      "125/125 - 1s - loss: 0.0693 - my_accuracy: 0.9438 - val_loss: 0.0667 - val_my_accuracy: 0.9491 - 683ms/epoch - 5ms/step\n",
      "Epoch 641/1000\n",
      "125/125 - 1s - loss: 0.0707 - my_accuracy: 0.9419 - val_loss: 0.0747 - val_my_accuracy: 0.9374 - 558ms/epoch - 4ms/step\n",
      "Epoch 642/1000\n",
      "125/125 - 1s - loss: 0.0682 - my_accuracy: 0.9445 - val_loss: 0.0649 - val_my_accuracy: 0.9480 - 532ms/epoch - 4ms/step\n",
      "Epoch 643/1000\n",
      "125/125 - 1s - loss: 0.0688 - my_accuracy: 0.9439 - val_loss: 0.0779 - val_my_accuracy: 0.9338 - 573ms/epoch - 5ms/step\n",
      "Epoch 644/1000\n",
      "125/125 - 0s - loss: 0.0713 - my_accuracy: 0.9427 - val_loss: 0.0670 - val_my_accuracy: 0.9464 - 480ms/epoch - 4ms/step\n",
      "Epoch 645/1000\n",
      "125/125 - 0s - loss: 0.0671 - my_accuracy: 0.9465 - val_loss: 0.0759 - val_my_accuracy: 0.9376 - 461ms/epoch - 4ms/step\n",
      "Epoch 646/1000\n",
      "125/125 - 1s - loss: 0.0702 - my_accuracy: 0.9431 - val_loss: 0.0662 - val_my_accuracy: 0.9489 - 529ms/epoch - 4ms/step\n",
      "Epoch 647/1000\n",
      "125/125 - 0s - loss: 0.0704 - my_accuracy: 0.9427 - val_loss: 0.0704 - val_my_accuracy: 0.9433 - 491ms/epoch - 4ms/step\n",
      "Epoch 648/1000\n",
      "125/125 - 1s - loss: 0.0694 - my_accuracy: 0.9432 - val_loss: 0.0685 - val_my_accuracy: 0.9456 - 511ms/epoch - 4ms/step\n",
      "Epoch 649/1000\n",
      "125/125 - 1s - loss: 0.0680 - my_accuracy: 0.9442 - val_loss: 0.0605 - val_my_accuracy: 0.9562 - 665ms/epoch - 5ms/step\n",
      "Epoch 650/1000\n",
      "125/125 - 1s - loss: 0.0678 - my_accuracy: 0.9452 - val_loss: 0.0681 - val_my_accuracy: 0.9414 - 588ms/epoch - 5ms/step\n",
      "Epoch 651/1000\n",
      "125/125 - 1s - loss: 0.0694 - my_accuracy: 0.9433 - val_loss: 0.0615 - val_my_accuracy: 0.9525 - 519ms/epoch - 4ms/step\n",
      "Epoch 652/1000\n",
      "125/125 - 1s - loss: 0.0680 - my_accuracy: 0.9454 - val_loss: 0.0756 - val_my_accuracy: 0.9388 - 659ms/epoch - 5ms/step\n",
      "Epoch 653/1000\n",
      "125/125 - 1s - loss: 0.0677 - my_accuracy: 0.9439 - val_loss: 0.0649 - val_my_accuracy: 0.9481 - 642ms/epoch - 5ms/step\n",
      "Epoch 654/1000\n",
      "125/125 - 1s - loss: 0.0691 - my_accuracy: 0.9437 - val_loss: 0.0729 - val_my_accuracy: 0.9391 - 692ms/epoch - 6ms/step\n",
      "Epoch 655/1000\n",
      "125/125 - 1s - loss: 0.0688 - my_accuracy: 0.9443 - val_loss: 0.0660 - val_my_accuracy: 0.9487 - 654ms/epoch - 5ms/step\n",
      "Epoch 656/1000\n",
      "125/125 - 1s - loss: 0.0693 - my_accuracy: 0.9432 - val_loss: 0.0634 - val_my_accuracy: 0.9520 - 620ms/epoch - 5ms/step\n",
      "Epoch 657/1000\n",
      "125/125 - 1s - loss: 0.0698 - my_accuracy: 0.9431 - val_loss: 0.0746 - val_my_accuracy: 0.9356 - 614ms/epoch - 5ms/step\n",
      "Epoch 658/1000\n",
      "125/125 - 1s - loss: 0.0715 - my_accuracy: 0.9412 - val_loss: 0.0715 - val_my_accuracy: 0.9440 - 600ms/epoch - 5ms/step\n",
      "Epoch 659/1000\n",
      "125/125 - 1s - loss: 0.0686 - my_accuracy: 0.9448 - val_loss: 0.0665 - val_my_accuracy: 0.9481 - 531ms/epoch - 4ms/step\n",
      "Epoch 660/1000\n",
      "125/125 - 0s - loss: 0.0679 - my_accuracy: 0.9451 - val_loss: 0.0664 - val_my_accuracy: 0.9463 - 453ms/epoch - 4ms/step\n",
      "Epoch 661/1000\n",
      "125/125 - 0s - loss: 0.0714 - my_accuracy: 0.9405 - val_loss: 0.0812 - val_my_accuracy: 0.9318 - 437ms/epoch - 3ms/step\n",
      "Epoch 662/1000\n",
      "125/125 - 0s - loss: 0.0719 - my_accuracy: 0.9405 - val_loss: 0.0620 - val_my_accuracy: 0.9518 - 461ms/epoch - 4ms/step\n",
      "Epoch 663/1000\n",
      "125/125 - 0s - loss: 0.0727 - my_accuracy: 0.9395 - val_loss: 0.0776 - val_my_accuracy: 0.9344 - 447ms/epoch - 4ms/step\n",
      "Epoch 664/1000\n",
      "125/125 - 0s - loss: 0.0694 - my_accuracy: 0.9431 - val_loss: 0.0670 - val_my_accuracy: 0.9480 - 477ms/epoch - 4ms/step\n",
      "Epoch 665/1000\n",
      "125/125 - 0s - loss: 0.0738 - my_accuracy: 0.9385 - val_loss: 0.0691 - val_my_accuracy: 0.9456 - 456ms/epoch - 4ms/step\n",
      "Epoch 666/1000\n",
      "125/125 - 0s - loss: 0.0669 - my_accuracy: 0.9456 - val_loss: 0.0629 - val_my_accuracy: 0.9518 - 457ms/epoch - 4ms/step\n",
      "Epoch 667/1000\n",
      "125/125 - 0s - loss: 0.0679 - my_accuracy: 0.9460 - val_loss: 0.0692 - val_my_accuracy: 0.9435 - 438ms/epoch - 4ms/step\n",
      "Epoch 668/1000\n",
      "125/125 - 0s - loss: 0.0685 - my_accuracy: 0.9444 - val_loss: 0.0668 - val_my_accuracy: 0.9426 - 450ms/epoch - 4ms/step\n",
      "Epoch 669/1000\n",
      "125/125 - 0s - loss: 0.0672 - my_accuracy: 0.9448 - val_loss: 0.0706 - val_my_accuracy: 0.9445 - 459ms/epoch - 4ms/step\n",
      "Epoch 670/1000\n",
      "125/125 - 0s - loss: 0.0687 - my_accuracy: 0.9437 - val_loss: 0.0886 - val_my_accuracy: 0.9307 - 433ms/epoch - 3ms/step\n",
      "Epoch 671/1000\n",
      "125/125 - 0s - loss: 0.0716 - my_accuracy: 0.9412 - val_loss: 0.0689 - val_my_accuracy: 0.9442 - 434ms/epoch - 3ms/step\n",
      "Epoch 672/1000\n",
      "125/125 - 0s - loss: 0.0683 - my_accuracy: 0.9451 - val_loss: 0.0630 - val_my_accuracy: 0.9529 - 445ms/epoch - 4ms/step\n",
      "Epoch 673/1000\n",
      "125/125 - 0s - loss: 0.0664 - my_accuracy: 0.9453 - val_loss: 0.0751 - val_my_accuracy: 0.9369 - 436ms/epoch - 3ms/step\n",
      "Epoch 674/1000\n",
      "125/125 - 0s - loss: 0.0668 - my_accuracy: 0.9454 - val_loss: 0.0666 - val_my_accuracy: 0.9451 - 453ms/epoch - 4ms/step\n",
      "Epoch 675/1000\n",
      "125/125 - 0s - loss: 0.0676 - my_accuracy: 0.9446 - val_loss: 0.0657 - val_my_accuracy: 0.9495 - 473ms/epoch - 4ms/step\n",
      "Epoch 676/1000\n",
      "125/125 - 0s - loss: 0.0710 - my_accuracy: 0.9415 - val_loss: 0.0761 - val_my_accuracy: 0.9391 - 476ms/epoch - 4ms/step\n",
      "Epoch 677/1000\n",
      "125/125 - 1s - loss: 0.0696 - my_accuracy: 0.9436 - val_loss: 0.0881 - val_my_accuracy: 0.9249 - 507ms/epoch - 4ms/step\n",
      "Epoch 678/1000\n",
      "125/125 - 0s - loss: 0.0650 - my_accuracy: 0.9480 - val_loss: 0.0628 - val_my_accuracy: 0.9511 - 489ms/epoch - 4ms/step\n",
      "Epoch 679/1000\n",
      "125/125 - 1s - loss: 0.0668 - my_accuracy: 0.9449 - val_loss: 0.0695 - val_my_accuracy: 0.9442 - 684ms/epoch - 5ms/step\n",
      "Epoch 680/1000\n",
      "125/125 - 1s - loss: 0.0657 - my_accuracy: 0.9467 - val_loss: 0.0698 - val_my_accuracy: 0.9442 - 661ms/epoch - 5ms/step\n",
      "Epoch 681/1000\n",
      "125/125 - 1s - loss: 0.0683 - my_accuracy: 0.9435 - val_loss: 0.0706 - val_my_accuracy: 0.9399 - 669ms/epoch - 5ms/step\n",
      "Epoch 682/1000\n",
      "125/125 - 1s - loss: 0.0706 - my_accuracy: 0.9424 - val_loss: 0.0684 - val_my_accuracy: 0.9464 - 574ms/epoch - 5ms/step\n",
      "Epoch 683/1000\n",
      "125/125 - 1s - loss: 0.0693 - my_accuracy: 0.9430 - val_loss: 0.0633 - val_my_accuracy: 0.9500 - 593ms/epoch - 5ms/step\n",
      "Epoch 684/1000\n",
      "125/125 - 1s - loss: 0.0635 - my_accuracy: 0.9495 - val_loss: 0.0631 - val_my_accuracy: 0.9481 - 646ms/epoch - 5ms/step\n",
      "Epoch 685/1000\n",
      "125/125 - 1s - loss: 0.0664 - my_accuracy: 0.9459 - val_loss: 0.0770 - val_my_accuracy: 0.9406 - 659ms/epoch - 5ms/step\n",
      "Epoch 686/1000\n",
      "125/125 - 1s - loss: 0.0699 - my_accuracy: 0.9424 - val_loss: 0.0732 - val_my_accuracy: 0.9354 - 631ms/epoch - 5ms/step\n",
      "Epoch 687/1000\n",
      "125/125 - 1s - loss: 0.0661 - my_accuracy: 0.9468 - val_loss: 0.0689 - val_my_accuracy: 0.9444 - 641ms/epoch - 5ms/step\n",
      "Epoch 688/1000\n",
      "125/125 - 1s - loss: 0.0699 - my_accuracy: 0.9419 - val_loss: 0.0712 - val_my_accuracy: 0.9411 - 612ms/epoch - 5ms/step\n",
      "Epoch 689/1000\n",
      "125/125 - 1s - loss: 0.0655 - my_accuracy: 0.9470 - val_loss: 0.0673 - val_my_accuracy: 0.9479 - 630ms/epoch - 5ms/step\n",
      "Epoch 690/1000\n",
      "125/125 - 1s - loss: 0.0684 - my_accuracy: 0.9442 - val_loss: 0.0632 - val_my_accuracy: 0.9485 - 629ms/epoch - 5ms/step\n",
      "Epoch 691/1000\n",
      "125/125 - 1s - loss: 0.0655 - my_accuracy: 0.9470 - val_loss: 0.0666 - val_my_accuracy: 0.9470 - 610ms/epoch - 5ms/step\n",
      "Epoch 692/1000\n",
      "125/125 - 1s - loss: 0.0662 - my_accuracy: 0.9463 - val_loss: 0.0709 - val_my_accuracy: 0.9421 - 590ms/epoch - 5ms/step\n",
      "Epoch 693/1000\n",
      "125/125 - 1s - loss: 0.0680 - my_accuracy: 0.9439 - val_loss: 0.0703 - val_my_accuracy: 0.9473 - 561ms/epoch - 4ms/step\n",
      "Epoch 694/1000\n",
      "125/125 - 0s - loss: 0.0680 - my_accuracy: 0.9457 - val_loss: 0.0744 - val_my_accuracy: 0.9388 - 435ms/epoch - 3ms/step\n",
      "Epoch 695/1000\n",
      "125/125 - 0s - loss: 0.0686 - my_accuracy: 0.9436 - val_loss: 0.0689 - val_my_accuracy: 0.9438 - 436ms/epoch - 3ms/step\n",
      "Epoch 696/1000\n",
      "125/125 - 0s - loss: 0.0713 - my_accuracy: 0.9414 - val_loss: 0.0670 - val_my_accuracy: 0.9456 - 417ms/epoch - 3ms/step\n",
      "Epoch 697/1000\n",
      "125/125 - 0s - loss: 0.0666 - my_accuracy: 0.9460 - val_loss: 0.0585 - val_my_accuracy: 0.9565 - 481ms/epoch - 4ms/step\n",
      "Epoch 698/1000\n",
      "125/125 - 0s - loss: 0.0639 - my_accuracy: 0.9493 - val_loss: 0.0670 - val_my_accuracy: 0.9440 - 449ms/epoch - 4ms/step\n",
      "Epoch 699/1000\n",
      "125/125 - 0s - loss: 0.0657 - my_accuracy: 0.9459 - val_loss: 0.0592 - val_my_accuracy: 0.9529 - 486ms/epoch - 4ms/step\n",
      "Epoch 700/1000\n",
      "125/125 - 0s - loss: 0.0659 - my_accuracy: 0.9465 - val_loss: 0.0669 - val_my_accuracy: 0.9458 - 476ms/epoch - 4ms/step\n",
      "Epoch 701/1000\n",
      "125/125 - 1s - loss: 0.0644 - my_accuracy: 0.9474 - val_loss: 0.0619 - val_my_accuracy: 0.9525 - 542ms/epoch - 4ms/step\n",
      "Epoch 702/1000\n",
      "125/125 - 0s - loss: 0.0680 - my_accuracy: 0.9448 - val_loss: 0.0791 - val_my_accuracy: 0.9363 - 482ms/epoch - 4ms/step\n",
      "Epoch 703/1000\n",
      "125/125 - 1s - loss: 0.0668 - my_accuracy: 0.9459 - val_loss: 0.0677 - val_my_accuracy: 0.9423 - 692ms/epoch - 6ms/step\n",
      "Epoch 704/1000\n",
      "125/125 - 1s - loss: 0.0659 - my_accuracy: 0.9467 - val_loss: 0.0618 - val_my_accuracy: 0.9515 - 629ms/epoch - 5ms/step\n",
      "Epoch 705/1000\n",
      "125/125 - 1s - loss: 0.0652 - my_accuracy: 0.9472 - val_loss: 0.0771 - val_my_accuracy: 0.9353 - 595ms/epoch - 5ms/step\n",
      "Epoch 706/1000\n",
      "125/125 - 1s - loss: 0.0659 - my_accuracy: 0.9475 - val_loss: 0.0674 - val_my_accuracy: 0.9473 - 662ms/epoch - 5ms/step\n",
      "Epoch 707/1000\n",
      "125/125 - 1s - loss: 0.0681 - my_accuracy: 0.9447 - val_loss: 0.0654 - val_my_accuracy: 0.9485 - 648ms/epoch - 5ms/step\n",
      "Epoch 708/1000\n",
      "125/125 - 1s - loss: 0.0648 - my_accuracy: 0.9469 - val_loss: 0.0697 - val_my_accuracy: 0.9413 - 597ms/epoch - 5ms/step\n",
      "Epoch 709/1000\n",
      "125/125 - 1s - loss: 0.0646 - my_accuracy: 0.9478 - val_loss: 0.0672 - val_my_accuracy: 0.9459 - 674ms/epoch - 5ms/step\n",
      "Epoch 710/1000\n",
      "125/125 - 1s - loss: 0.0666 - my_accuracy: 0.9453 - val_loss: 0.0661 - val_my_accuracy: 0.9470 - 608ms/epoch - 5ms/step\n",
      "Epoch 711/1000\n",
      "125/125 - 1s - loss: 0.0686 - my_accuracy: 0.9435 - val_loss: 0.0629 - val_my_accuracy: 0.9505 - 670ms/epoch - 5ms/step\n",
      "Epoch 712/1000\n",
      "125/125 - 1s - loss: 0.0683 - my_accuracy: 0.9442 - val_loss: 0.0642 - val_my_accuracy: 0.9480 - 600ms/epoch - 5ms/step\n",
      "Epoch 713/1000\n",
      "125/125 - 1s - loss: 0.0674 - my_accuracy: 0.9460 - val_loss: 0.0688 - val_my_accuracy: 0.9406 - 609ms/epoch - 5ms/step\n",
      "Epoch 714/1000\n",
      "125/125 - 1s - loss: 0.0643 - my_accuracy: 0.9484 - val_loss: 0.0698 - val_my_accuracy: 0.9426 - 642ms/epoch - 5ms/step\n",
      "Epoch 715/1000\n",
      "125/125 - 1s - loss: 0.0678 - my_accuracy: 0.9435 - val_loss: 0.0721 - val_my_accuracy: 0.9413 - 609ms/epoch - 5ms/step\n",
      "Epoch 716/1000\n",
      "125/125 - 1s - loss: 0.0672 - my_accuracy: 0.9441 - val_loss: 0.0588 - val_my_accuracy: 0.9546 - 593ms/epoch - 5ms/step\n",
      "Epoch 717/1000\n",
      "125/125 - 0s - loss: 0.0668 - my_accuracy: 0.9457 - val_loss: 0.0600 - val_my_accuracy: 0.9552 - 481ms/epoch - 4ms/step\n",
      "Epoch 718/1000\n",
      "125/125 - 0s - loss: 0.0661 - my_accuracy: 0.9462 - val_loss: 0.0632 - val_my_accuracy: 0.9491 - 465ms/epoch - 4ms/step\n",
      "Epoch 719/1000\n",
      "125/125 - 0s - loss: 0.0652 - my_accuracy: 0.9461 - val_loss: 0.0632 - val_my_accuracy: 0.9495 - 454ms/epoch - 4ms/step\n",
      "Epoch 720/1000\n",
      "125/125 - 1s - loss: 0.0644 - my_accuracy: 0.9480 - val_loss: 0.0627 - val_my_accuracy: 0.9504 - 520ms/epoch - 4ms/step\n",
      "Epoch 721/1000\n",
      "125/125 - 0s - loss: 0.0678 - my_accuracy: 0.9448 - val_loss: 0.0654 - val_my_accuracy: 0.9478 - 465ms/epoch - 4ms/step\n",
      "Epoch 722/1000\n",
      "125/125 - 0s - loss: 0.0663 - my_accuracy: 0.9452 - val_loss: 0.0619 - val_my_accuracy: 0.9522 - 499ms/epoch - 4ms/step\n",
      "Epoch 723/1000\n",
      "125/125 - 0s - loss: 0.0655 - my_accuracy: 0.9464 - val_loss: 0.0639 - val_my_accuracy: 0.9488 - 483ms/epoch - 4ms/step\n",
      "Epoch 724/1000\n",
      "125/125 - 1s - loss: 0.0641 - my_accuracy: 0.9478 - val_loss: 0.0725 - val_my_accuracy: 0.9399 - 535ms/epoch - 4ms/step\n",
      "Epoch 725/1000\n",
      "125/125 - 0s - loss: 0.0682 - my_accuracy: 0.9434 - val_loss: 0.0642 - val_my_accuracy: 0.9512 - 488ms/epoch - 4ms/step\n",
      "Epoch 726/1000\n",
      "125/125 - 0s - loss: 0.0660 - my_accuracy: 0.9455 - val_loss: 0.0686 - val_my_accuracy: 0.9434 - 471ms/epoch - 4ms/step\n",
      "Epoch 727/1000\n",
      "125/125 - 1s - loss: 0.0642 - my_accuracy: 0.9474 - val_loss: 0.0689 - val_my_accuracy: 0.9424 - 564ms/epoch - 5ms/step\n",
      "Epoch 728/1000\n",
      "125/125 - 1s - loss: 0.0649 - my_accuracy: 0.9472 - val_loss: 0.0724 - val_my_accuracy: 0.9395 - 616ms/epoch - 5ms/step\n",
      "Epoch 729/1000\n",
      "125/125 - 1s - loss: 0.0668 - my_accuracy: 0.9449 - val_loss: 0.0636 - val_my_accuracy: 0.9490 - 537ms/epoch - 4ms/step\n",
      "Epoch 730/1000\n",
      "125/125 - 0s - loss: 0.0663 - my_accuracy: 0.9456 - val_loss: 0.0880 - val_my_accuracy: 0.9210 - 487ms/epoch - 4ms/step\n",
      "Epoch 731/1000\n",
      "125/125 - 0s - loss: 0.0662 - my_accuracy: 0.9458 - val_loss: 0.0718 - val_my_accuracy: 0.9430 - 488ms/epoch - 4ms/step\n",
      "Epoch 732/1000\n",
      "125/125 - 0s - loss: 0.0609 - my_accuracy: 0.9519 - val_loss: 0.0712 - val_my_accuracy: 0.9409 - 465ms/epoch - 4ms/step\n",
      "Epoch 733/1000\n",
      "125/125 - 1s - loss: 0.0644 - my_accuracy: 0.9472 - val_loss: 0.0580 - val_my_accuracy: 0.9550 - 505ms/epoch - 4ms/step\n",
      "Epoch 734/1000\n",
      "125/125 - 1s - loss: 0.0653 - my_accuracy: 0.9467 - val_loss: 0.0691 - val_my_accuracy: 0.9427 - 513ms/epoch - 4ms/step\n",
      "Epoch 735/1000\n",
      "125/125 - 1s - loss: 0.0663 - my_accuracy: 0.9455 - val_loss: 0.0670 - val_my_accuracy: 0.9452 - 599ms/epoch - 5ms/step\n",
      "Epoch 736/1000\n",
      "125/125 - 1s - loss: 0.0681 - my_accuracy: 0.9440 - val_loss: 0.0763 - val_my_accuracy: 0.9340 - 612ms/epoch - 5ms/step\n",
      "Epoch 737/1000\n",
      "125/125 - 1s - loss: 0.0642 - my_accuracy: 0.9477 - val_loss: 0.0609 - val_my_accuracy: 0.9516 - 605ms/epoch - 5ms/step\n",
      "Epoch 738/1000\n",
      "125/125 - 1s - loss: 0.0643 - my_accuracy: 0.9484 - val_loss: 0.0654 - val_my_accuracy: 0.9490 - 563ms/epoch - 5ms/step\n",
      "Epoch 739/1000\n",
      "125/125 - 1s - loss: 0.0697 - my_accuracy: 0.9421 - val_loss: 0.0576 - val_my_accuracy: 0.9557 - 581ms/epoch - 5ms/step\n",
      "Epoch 740/1000\n",
      "125/125 - 1s - loss: 0.0642 - my_accuracy: 0.9478 - val_loss: 0.0722 - val_my_accuracy: 0.9389 - 622ms/epoch - 5ms/step\n",
      "Epoch 741/1000\n",
      "125/125 - 0s - loss: 0.0621 - my_accuracy: 0.9493 - val_loss: 0.0703 - val_my_accuracy: 0.9418 - 460ms/epoch - 4ms/step\n",
      "Epoch 742/1000\n",
      "125/125 - 0s - loss: 0.0653 - my_accuracy: 0.9464 - val_loss: 0.0844 - val_my_accuracy: 0.9278 - 449ms/epoch - 4ms/step\n",
      "Epoch 743/1000\n",
      "125/125 - 1s - loss: 0.0644 - my_accuracy: 0.9475 - val_loss: 0.0645 - val_my_accuracy: 0.9486 - 654ms/epoch - 5ms/step\n",
      "Epoch 744/1000\n",
      "125/125 - 1s - loss: 0.0652 - my_accuracy: 0.9463 - val_loss: 0.0594 - val_my_accuracy: 0.9546 - 516ms/epoch - 4ms/step\n",
      "Epoch 745/1000\n",
      "125/125 - 1s - loss: 0.0634 - my_accuracy: 0.9479 - val_loss: 0.0625 - val_my_accuracy: 0.9482 - 584ms/epoch - 5ms/step\n",
      "Epoch 746/1000\n",
      "125/125 - 0s - loss: 0.0633 - my_accuracy: 0.9488 - val_loss: 0.0627 - val_my_accuracy: 0.9492 - 474ms/epoch - 4ms/step\n",
      "Epoch 747/1000\n",
      "125/125 - 1s - loss: 0.0659 - my_accuracy: 0.9449 - val_loss: 0.0644 - val_my_accuracy: 0.9470 - 505ms/epoch - 4ms/step\n",
      "Epoch 748/1000\n",
      "125/125 - 0s - loss: 0.0654 - my_accuracy: 0.9460 - val_loss: 0.0670 - val_my_accuracy: 0.9456 - 491ms/epoch - 4ms/step\n",
      "Epoch 749/1000\n",
      "125/125 - 0s - loss: 0.0635 - my_accuracy: 0.9481 - val_loss: 0.0589 - val_my_accuracy: 0.9541 - 487ms/epoch - 4ms/step\n",
      "Epoch 750/1000\n",
      "125/125 - 0s - loss: 0.0638 - my_accuracy: 0.9477 - val_loss: 0.0671 - val_my_accuracy: 0.9470 - 491ms/epoch - 4ms/step\n",
      "Epoch 751/1000\n",
      "125/125 - 0s - loss: 0.0606 - my_accuracy: 0.9521 - val_loss: 0.0625 - val_my_accuracy: 0.9488 - 485ms/epoch - 4ms/step\n",
      "Epoch 752/1000\n",
      "125/125 - 0s - loss: 0.0664 - my_accuracy: 0.9458 - val_loss: 0.0708 - val_my_accuracy: 0.9406 - 485ms/epoch - 4ms/step\n",
      "Epoch 753/1000\n",
      "125/125 - 1s - loss: 0.0623 - my_accuracy: 0.9492 - val_loss: 0.0610 - val_my_accuracy: 0.9500 - 702ms/epoch - 6ms/step\n",
      "Epoch 754/1000\n",
      "125/125 - 1s - loss: 0.0629 - my_accuracy: 0.9493 - val_loss: 0.0660 - val_my_accuracy: 0.9438 - 709ms/epoch - 6ms/step\n",
      "Epoch 755/1000\n",
      "125/125 - 1s - loss: 0.0627 - my_accuracy: 0.9495 - val_loss: 0.0606 - val_my_accuracy: 0.9510 - 643ms/epoch - 5ms/step\n",
      "Epoch 756/1000\n",
      "125/125 - 1s - loss: 0.0641 - my_accuracy: 0.9469 - val_loss: 0.0696 - val_my_accuracy: 0.9410 - 590ms/epoch - 5ms/step\n",
      "Epoch 757/1000\n",
      "125/125 - 1s - loss: 0.0669 - my_accuracy: 0.9446 - val_loss: 0.0603 - val_my_accuracy: 0.9530 - 591ms/epoch - 5ms/step\n",
      "Epoch 758/1000\n",
      "125/125 - 0s - loss: 0.0620 - my_accuracy: 0.9496 - val_loss: 0.0569 - val_my_accuracy: 0.9553 - 498ms/epoch - 4ms/step\n",
      "Epoch 759/1000\n",
      "125/125 - 0s - loss: 0.0607 - my_accuracy: 0.9507 - val_loss: 0.0622 - val_my_accuracy: 0.9515 - 484ms/epoch - 4ms/step\n",
      "Epoch 760/1000\n",
      "125/125 - 0s - loss: 0.0681 - my_accuracy: 0.9441 - val_loss: 0.0612 - val_my_accuracy: 0.9501 - 436ms/epoch - 3ms/step\n",
      "Epoch 761/1000\n",
      "125/125 - 0s - loss: 0.0653 - my_accuracy: 0.9464 - val_loss: 0.0752 - val_my_accuracy: 0.9394 - 499ms/epoch - 4ms/step\n",
      "Epoch 762/1000\n",
      "125/125 - 1s - loss: 0.0624 - my_accuracy: 0.9499 - val_loss: 0.0627 - val_my_accuracy: 0.9518 - 507ms/epoch - 4ms/step\n",
      "Epoch 763/1000\n",
      "125/125 - 1s - loss: 0.0640 - my_accuracy: 0.9464 - val_loss: 0.0761 - val_my_accuracy: 0.9401 - 566ms/epoch - 5ms/step\n",
      "Epoch 764/1000\n",
      "125/125 - 1s - loss: 0.0639 - my_accuracy: 0.9471 - val_loss: 0.0648 - val_my_accuracy: 0.9457 - 514ms/epoch - 4ms/step\n",
      "Epoch 765/1000\n",
      "125/125 - 0s - loss: 0.0642 - my_accuracy: 0.9465 - val_loss: 0.0595 - val_my_accuracy: 0.9524 - 491ms/epoch - 4ms/step\n",
      "Epoch 766/1000\n",
      "125/125 - 1s - loss: 0.0644 - my_accuracy: 0.9471 - val_loss: 0.0570 - val_my_accuracy: 0.9553 - 525ms/epoch - 4ms/step\n",
      "Epoch 767/1000\n",
      "125/125 - 1s - loss: 0.0633 - my_accuracy: 0.9478 - val_loss: 0.0711 - val_my_accuracy: 0.9401 - 513ms/epoch - 4ms/step\n",
      "Epoch 768/1000\n",
      "125/125 - 1s - loss: 0.0629 - my_accuracy: 0.9479 - val_loss: 0.0584 - val_my_accuracy: 0.9540 - 515ms/epoch - 4ms/step\n",
      "Epoch 769/1000\n",
      "125/125 - 1s - loss: 0.0631 - my_accuracy: 0.9483 - val_loss: 0.0570 - val_my_accuracy: 0.9557 - 503ms/epoch - 4ms/step\n",
      "Epoch 770/1000\n",
      "125/125 - 1s - loss: 0.0653 - my_accuracy: 0.9462 - val_loss: 0.0569 - val_my_accuracy: 0.9554 - 524ms/epoch - 4ms/step\n",
      "Epoch 771/1000\n",
      "125/125 - 0s - loss: 0.0616 - my_accuracy: 0.9493 - val_loss: 0.0602 - val_my_accuracy: 0.9521 - 485ms/epoch - 4ms/step\n",
      "Epoch 772/1000\n",
      "125/125 - 0s - loss: 0.0591 - my_accuracy: 0.9522 - val_loss: 0.0611 - val_my_accuracy: 0.9528 - 490ms/epoch - 4ms/step\n",
      "Epoch 773/1000\n",
      "125/125 - 0s - loss: 0.0657 - my_accuracy: 0.9453 - val_loss: 0.0624 - val_my_accuracy: 0.9492 - 488ms/epoch - 4ms/step\n",
      "Epoch 774/1000\n",
      "125/125 - 1s - loss: 0.0630 - my_accuracy: 0.9473 - val_loss: 0.0655 - val_my_accuracy: 0.9462 - 665ms/epoch - 5ms/step\n",
      "Epoch 775/1000\n",
      "125/125 - 1s - loss: 0.0618 - my_accuracy: 0.9503 - val_loss: 0.0620 - val_my_accuracy: 0.9485 - 799ms/epoch - 6ms/step\n",
      "Epoch 776/1000\n",
      "125/125 - 1s - loss: 0.0602 - my_accuracy: 0.9514 - val_loss: 0.0593 - val_my_accuracy: 0.9540 - 726ms/epoch - 6ms/step\n",
      "Epoch 777/1000\n",
      "125/125 - 1s - loss: 0.0636 - my_accuracy: 0.9477 - val_loss: 0.0585 - val_my_accuracy: 0.9528 - 654ms/epoch - 5ms/step\n",
      "Epoch 778/1000\n",
      "125/125 - 1s - loss: 0.0631 - my_accuracy: 0.9491 - val_loss: 0.0639 - val_my_accuracy: 0.9467 - 706ms/epoch - 6ms/step\n",
      "Epoch 779/1000\n",
      "125/125 - 1s - loss: 0.0634 - my_accuracy: 0.9477 - val_loss: 0.0723 - val_my_accuracy: 0.9404 - 675ms/epoch - 5ms/step\n",
      "Epoch 780/1000\n",
      "125/125 - 1s - loss: 0.0636 - my_accuracy: 0.9473 - val_loss: 0.0614 - val_my_accuracy: 0.9507 - 616ms/epoch - 5ms/step\n",
      "Epoch 781/1000\n",
      "125/125 - 1s - loss: 0.0644 - my_accuracy: 0.9473 - val_loss: 0.0566 - val_my_accuracy: 0.9554 - 602ms/epoch - 5ms/step\n",
      "Epoch 782/1000\n",
      "125/125 - 0s - loss: 0.0608 - my_accuracy: 0.9507 - val_loss: 0.0565 - val_my_accuracy: 0.9567 - 494ms/epoch - 4ms/step\n",
      "Epoch 783/1000\n",
      "125/125 - 1s - loss: 0.0604 - my_accuracy: 0.9509 - val_loss: 0.0763 - val_my_accuracy: 0.9402 - 602ms/epoch - 5ms/step\n",
      "Epoch 784/1000\n",
      "125/125 - 1s - loss: 0.0640 - my_accuracy: 0.9468 - val_loss: 0.0619 - val_my_accuracy: 0.9481 - 536ms/epoch - 4ms/step\n",
      "Epoch 785/1000\n",
      "125/125 - 1s - loss: 0.0600 - my_accuracy: 0.9517 - val_loss: 0.0605 - val_my_accuracy: 0.9511 - 528ms/epoch - 4ms/step\n",
      "Epoch 786/1000\n",
      "125/125 - 1s - loss: 0.0606 - my_accuracy: 0.9503 - val_loss: 0.0623 - val_my_accuracy: 0.9501 - 522ms/epoch - 4ms/step\n",
      "Epoch 787/1000\n",
      "125/125 - 0s - loss: 0.0667 - my_accuracy: 0.9451 - val_loss: 0.0596 - val_my_accuracy: 0.9517 - 496ms/epoch - 4ms/step\n",
      "Epoch 788/1000\n",
      "125/125 - 1s - loss: 0.0613 - my_accuracy: 0.9500 - val_loss: 0.0572 - val_my_accuracy: 0.9547 - 540ms/epoch - 4ms/step\n",
      "Epoch 789/1000\n",
      "125/125 - 1s - loss: 0.0604 - my_accuracy: 0.9511 - val_loss: 0.0677 - val_my_accuracy: 0.9432 - 512ms/epoch - 4ms/step\n",
      "Epoch 790/1000\n",
      "125/125 - 0s - loss: 0.0635 - my_accuracy: 0.9476 - val_loss: 0.0621 - val_my_accuracy: 0.9512 - 480ms/epoch - 4ms/step\n",
      "Epoch 791/1000\n",
      "125/125 - 1s - loss: 0.0627 - my_accuracy: 0.9485 - val_loss: 0.0629 - val_my_accuracy: 0.9477 - 523ms/epoch - 4ms/step\n",
      "Epoch 792/1000\n",
      "125/125 - 1s - loss: 0.0624 - my_accuracy: 0.9486 - val_loss: 0.0591 - val_my_accuracy: 0.9536 - 514ms/epoch - 4ms/step\n",
      "Epoch 793/1000\n",
      "125/125 - 0s - loss: 0.0605 - my_accuracy: 0.9513 - val_loss: 0.0700 - val_my_accuracy: 0.9411 - 480ms/epoch - 4ms/step\n",
      "Epoch 794/1000\n",
      "125/125 - 0s - loss: 0.0668 - my_accuracy: 0.9446 - val_loss: 0.0731 - val_my_accuracy: 0.9430 - 469ms/epoch - 4ms/step\n",
      "Epoch 795/1000\n",
      "125/125 - 1s - loss: 0.0597 - my_accuracy: 0.9516 - val_loss: 0.0567 - val_my_accuracy: 0.9538 - 532ms/epoch - 4ms/step\n",
      "Epoch 796/1000\n",
      "125/125 - 1s - loss: 0.0603 - my_accuracy: 0.9508 - val_loss: 0.0593 - val_my_accuracy: 0.9528 - 507ms/epoch - 4ms/step\n",
      "Epoch 797/1000\n",
      "125/125 - 1s - loss: 0.0632 - my_accuracy: 0.9474 - val_loss: 0.0608 - val_my_accuracy: 0.9514 - 548ms/epoch - 4ms/step\n",
      "Epoch 798/1000\n",
      "125/125 - 1s - loss: 0.0612 - my_accuracy: 0.9498 - val_loss: 0.0579 - val_my_accuracy: 0.9552 - 576ms/epoch - 5ms/step\n",
      "Epoch 799/1000\n",
      "125/125 - 0s - loss: 0.0627 - my_accuracy: 0.9483 - val_loss: 0.0540 - val_my_accuracy: 0.9598 - 480ms/epoch - 4ms/step\n",
      "Epoch 800/1000\n",
      "125/125 - 1s - loss: 0.0619 - my_accuracy: 0.9482 - val_loss: 0.0545 - val_my_accuracy: 0.9592 - 546ms/epoch - 4ms/step\n",
      "Epoch 801/1000\n",
      "125/125 - 1s - loss: 0.0618 - my_accuracy: 0.9489 - val_loss: 0.0606 - val_my_accuracy: 0.9495 - 524ms/epoch - 4ms/step\n",
      "Epoch 802/1000\n",
      "125/125 - 0s - loss: 0.0625 - my_accuracy: 0.9480 - val_loss: 0.0588 - val_my_accuracy: 0.9537 - 482ms/epoch - 4ms/step\n",
      "Epoch 803/1000\n",
      "125/125 - 0s - loss: 0.0601 - my_accuracy: 0.9512 - val_loss: 0.0635 - val_my_accuracy: 0.9515 - 482ms/epoch - 4ms/step\n",
      "Epoch 804/1000\n",
      "125/125 - 0s - loss: 0.0608 - my_accuracy: 0.9500 - val_loss: 0.0558 - val_my_accuracy: 0.9542 - 499ms/epoch - 4ms/step\n",
      "Epoch 805/1000\n",
      "125/125 - 1s - loss: 0.0603 - my_accuracy: 0.9506 - val_loss: 0.0601 - val_my_accuracy: 0.9507 - 507ms/epoch - 4ms/step\n",
      "Epoch 806/1000\n",
      "125/125 - 1s - loss: 0.0615 - my_accuracy: 0.9495 - val_loss: 0.0680 - val_my_accuracy: 0.9416 - 502ms/epoch - 4ms/step\n",
      "Epoch 807/1000\n",
      "125/125 - 0s - loss: 0.0598 - my_accuracy: 0.9509 - val_loss: 0.0567 - val_my_accuracy: 0.9552 - 488ms/epoch - 4ms/step\n",
      "Epoch 808/1000\n",
      "125/125 - 1s - loss: 0.0613 - my_accuracy: 0.9484 - val_loss: 0.0587 - val_my_accuracy: 0.9519 - 515ms/epoch - 4ms/step\n",
      "Epoch 809/1000\n",
      "125/125 - 1s - loss: 0.0598 - my_accuracy: 0.9507 - val_loss: 0.0633 - val_my_accuracy: 0.9515 - 507ms/epoch - 4ms/step\n",
      "Epoch 810/1000\n",
      "125/125 - 1s - loss: 0.0605 - my_accuracy: 0.9511 - val_loss: 0.0543 - val_my_accuracy: 0.9591 - 502ms/epoch - 4ms/step\n",
      "Epoch 811/1000\n",
      "125/125 - 0s - loss: 0.0579 - my_accuracy: 0.9530 - val_loss: 0.0625 - val_my_accuracy: 0.9480 - 497ms/epoch - 4ms/step\n",
      "Epoch 812/1000\n",
      "125/125 - 0s - loss: 0.0583 - my_accuracy: 0.9524 - val_loss: 0.0579 - val_my_accuracy: 0.9523 - 477ms/epoch - 4ms/step\n",
      "Epoch 813/1000\n",
      "125/125 - 1s - loss: 0.0607 - my_accuracy: 0.9496 - val_loss: 0.0636 - val_my_accuracy: 0.9474 - 508ms/epoch - 4ms/step\n",
      "Epoch 814/1000\n",
      "125/125 - 1s - loss: 0.0605 - my_accuracy: 0.9500 - val_loss: 0.0579 - val_my_accuracy: 0.9517 - 502ms/epoch - 4ms/step\n",
      "Epoch 815/1000\n",
      "125/125 - 0s - loss: 0.0605 - my_accuracy: 0.9500 - val_loss: 0.0546 - val_my_accuracy: 0.9557 - 489ms/epoch - 4ms/step\n",
      "Epoch 816/1000\n",
      "125/125 - 0s - loss: 0.0648 - my_accuracy: 0.9467 - val_loss: 0.0565 - val_my_accuracy: 0.9553 - 484ms/epoch - 4ms/step\n",
      "Epoch 817/1000\n",
      "125/125 - 0s - loss: 0.0614 - my_accuracy: 0.9487 - val_loss: 0.0599 - val_my_accuracy: 0.9515 - 494ms/epoch - 4ms/step\n",
      "Epoch 818/1000\n",
      "125/125 - 0s - loss: 0.0626 - my_accuracy: 0.9484 - val_loss: 0.0601 - val_my_accuracy: 0.9521 - 490ms/epoch - 4ms/step\n",
      "Epoch 819/1000\n",
      "125/125 - 1s - loss: 0.0587 - my_accuracy: 0.9514 - val_loss: 0.0603 - val_my_accuracy: 0.9512 - 501ms/epoch - 4ms/step\n",
      "Epoch 820/1000\n",
      "125/125 - 0s - loss: 0.0586 - my_accuracy: 0.9521 - val_loss: 0.0584 - val_my_accuracy: 0.9536 - 496ms/epoch - 4ms/step\n",
      "Epoch 821/1000\n",
      "125/125 - 1s - loss: 0.0638 - my_accuracy: 0.9468 - val_loss: 0.0646 - val_my_accuracy: 0.9457 - 507ms/epoch - 4ms/step\n",
      "Epoch 822/1000\n",
      "125/125 - 1s - loss: 0.0609 - my_accuracy: 0.9496 - val_loss: 0.0605 - val_my_accuracy: 0.9488 - 535ms/epoch - 4ms/step\n",
      "Epoch 823/1000\n",
      "125/125 - 0s - loss: 0.0615 - my_accuracy: 0.9495 - val_loss: 0.0583 - val_my_accuracy: 0.9549 - 496ms/epoch - 4ms/step\n",
      "Epoch 824/1000\n",
      "125/125 - 1s - loss: 0.0607 - my_accuracy: 0.9496 - val_loss: 0.0598 - val_my_accuracy: 0.9531 - 623ms/epoch - 5ms/step\n",
      "Epoch 825/1000\n",
      "125/125 - 1s - loss: 0.0597 - my_accuracy: 0.9501 - val_loss: 0.0616 - val_my_accuracy: 0.9492 - 664ms/epoch - 5ms/step\n",
      "Epoch 826/1000\n",
      "125/125 - 1s - loss: 0.0627 - my_accuracy: 0.9473 - val_loss: 0.0585 - val_my_accuracy: 0.9537 - 639ms/epoch - 5ms/step\n",
      "Epoch 827/1000\n",
      "125/125 - 1s - loss: 0.0623 - my_accuracy: 0.9474 - val_loss: 0.0558 - val_my_accuracy: 0.9553 - 553ms/epoch - 4ms/step\n",
      "Epoch 828/1000\n",
      "125/125 - 1s - loss: 0.0590 - my_accuracy: 0.9517 - val_loss: 0.0694 - val_my_accuracy: 0.9453 - 538ms/epoch - 4ms/step\n",
      "Epoch 829/1000\n",
      "125/125 - 1s - loss: 0.0638 - my_accuracy: 0.9462 - val_loss: 0.0623 - val_my_accuracy: 0.9471 - 508ms/epoch - 4ms/step\n",
      "Epoch 830/1000\n",
      "125/125 - 0s - loss: 0.0588 - my_accuracy: 0.9515 - val_loss: 0.0593 - val_my_accuracy: 0.9492 - 494ms/epoch - 4ms/step\n",
      "Epoch 831/1000\n",
      "125/125 - 1s - loss: 0.0638 - my_accuracy: 0.9478 - val_loss: 0.0727 - val_my_accuracy: 0.9373 - 549ms/epoch - 4ms/step\n",
      "Epoch 832/1000\n",
      "125/125 - 1s - loss: 0.0612 - my_accuracy: 0.9495 - val_loss: 0.0541 - val_my_accuracy: 0.9598 - 502ms/epoch - 4ms/step\n",
      "Epoch 833/1000\n",
      "125/125 - 1s - loss: 0.0593 - my_accuracy: 0.9519 - val_loss: 0.0584 - val_my_accuracy: 0.9520 - 510ms/epoch - 4ms/step\n",
      "Epoch 834/1000\n",
      "125/125 - 1s - loss: 0.0597 - my_accuracy: 0.9509 - val_loss: 0.0648 - val_my_accuracy: 0.9468 - 502ms/epoch - 4ms/step\n",
      "Epoch 835/1000\n",
      "125/125 - 0s - loss: 0.0606 - my_accuracy: 0.9491 - val_loss: 0.0567 - val_my_accuracy: 0.9547 - 493ms/epoch - 4ms/step\n",
      "Epoch 836/1000\n",
      "125/125 - 1s - loss: 0.0570 - my_accuracy: 0.9541 - val_loss: 0.0561 - val_my_accuracy: 0.9560 - 522ms/epoch - 4ms/step\n",
      "Epoch 837/1000\n",
      "125/125 - 1s - loss: 0.0642 - my_accuracy: 0.9464 - val_loss: 0.0600 - val_my_accuracy: 0.9518 - 509ms/epoch - 4ms/step\n",
      "Epoch 838/1000\n",
      "125/125 - 1s - loss: 0.0598 - my_accuracy: 0.9511 - val_loss: 0.0679 - val_my_accuracy: 0.9455 - 511ms/epoch - 4ms/step\n",
      "Epoch 839/1000\n",
      "125/125 - 1s - loss: 0.0593 - my_accuracy: 0.9506 - val_loss: 0.0615 - val_my_accuracy: 0.9489 - 569ms/epoch - 5ms/step\n",
      "Epoch 840/1000\n",
      "125/125 - 0s - loss: 0.0597 - my_accuracy: 0.9512 - val_loss: 0.0566 - val_my_accuracy: 0.9553 - 478ms/epoch - 4ms/step\n",
      "Epoch 841/1000\n",
      "125/125 - 1s - loss: 0.0625 - my_accuracy: 0.9477 - val_loss: 0.0570 - val_my_accuracy: 0.9536 - 621ms/epoch - 5ms/step\n",
      "Epoch 842/1000\n",
      "125/125 - 1s - loss: 0.0618 - my_accuracy: 0.9489 - val_loss: 0.0664 - val_my_accuracy: 0.9421 - 706ms/epoch - 6ms/step\n",
      "Epoch 843/1000\n",
      "125/125 - 1s - loss: 0.0601 - my_accuracy: 0.9506 - val_loss: 0.0590 - val_my_accuracy: 0.9524 - 741ms/epoch - 6ms/step\n",
      "Epoch 844/1000\n",
      "125/125 - 1s - loss: 0.0581 - my_accuracy: 0.9524 - val_loss: 0.0577 - val_my_accuracy: 0.9531 - 689ms/epoch - 6ms/step\n",
      "Epoch 845/1000\n",
      "125/125 - 1s - loss: 0.0616 - my_accuracy: 0.9495 - val_loss: 0.0531 - val_my_accuracy: 0.9597 - 704ms/epoch - 6ms/step\n",
      "Epoch 846/1000\n",
      "125/125 - 1s - loss: 0.0576 - my_accuracy: 0.9528 - val_loss: 0.0555 - val_my_accuracy: 0.9562 - 738ms/epoch - 6ms/step\n",
      "Epoch 847/1000\n",
      "125/125 - 1s - loss: 0.0582 - my_accuracy: 0.9529 - val_loss: 0.0542 - val_my_accuracy: 0.9563 - 652ms/epoch - 5ms/step\n",
      "Epoch 848/1000\n",
      "125/125 - 1s - loss: 0.0582 - my_accuracy: 0.9529 - val_loss: 0.0533 - val_my_accuracy: 0.9583 - 742ms/epoch - 6ms/step\n",
      "Epoch 849/1000\n",
      "125/125 - 1s - loss: 0.0576 - my_accuracy: 0.9527 - val_loss: 0.0579 - val_my_accuracy: 0.9541 - 682ms/epoch - 5ms/step\n",
      "Epoch 850/1000\n",
      "125/125 - 1s - loss: 0.0589 - my_accuracy: 0.9511 - val_loss: 0.0569 - val_my_accuracy: 0.9553 - 700ms/epoch - 6ms/step\n",
      "Epoch 851/1000\n",
      "125/125 - 1s - loss: 0.0656 - my_accuracy: 0.9455 - val_loss: 0.0584 - val_my_accuracy: 0.9510 - 706ms/epoch - 6ms/step\n",
      "Epoch 852/1000\n",
      "125/125 - 1s - loss: 0.0604 - my_accuracy: 0.9494 - val_loss: 0.0657 - val_my_accuracy: 0.9475 - 727ms/epoch - 6ms/step\n",
      "Epoch 853/1000\n",
      "125/125 - 1s - loss: 0.0636 - my_accuracy: 0.9467 - val_loss: 0.0590 - val_my_accuracy: 0.9522 - 673ms/epoch - 5ms/step\n",
      "Epoch 854/1000\n",
      "125/125 - 1s - loss: 0.0593 - my_accuracy: 0.9514 - val_loss: 0.0558 - val_my_accuracy: 0.9547 - 675ms/epoch - 5ms/step\n",
      "Epoch 855/1000\n",
      "125/125 - 1s - loss: 0.0593 - my_accuracy: 0.9515 - val_loss: 0.0610 - val_my_accuracy: 0.9520 - 668ms/epoch - 5ms/step\n",
      "Epoch 856/1000\n",
      "125/125 - 1s - loss: 0.0604 - my_accuracy: 0.9500 - val_loss: 0.0533 - val_my_accuracy: 0.9575 - 677ms/epoch - 5ms/step\n",
      "Epoch 857/1000\n",
      "125/125 - 0s - loss: 0.0597 - my_accuracy: 0.9502 - val_loss: 0.0584 - val_my_accuracy: 0.9532 - 469ms/epoch - 4ms/step\n",
      "Epoch 858/1000\n",
      "125/125 - 0s - loss: 0.0614 - my_accuracy: 0.9490 - val_loss: 0.0628 - val_my_accuracy: 0.9491 - 482ms/epoch - 4ms/step\n",
      "Epoch 859/1000\n",
      "125/125 - 0s - loss: 0.0586 - my_accuracy: 0.9517 - val_loss: 0.0549 - val_my_accuracy: 0.9556 - 464ms/epoch - 4ms/step\n",
      "Epoch 860/1000\n",
      "125/125 - 1s - loss: 0.0600 - my_accuracy: 0.9507 - val_loss: 0.0605 - val_my_accuracy: 0.9508 - 510ms/epoch - 4ms/step\n",
      "Epoch 861/1000\n",
      "125/125 - 0s - loss: 0.0571 - my_accuracy: 0.9538 - val_loss: 0.0636 - val_my_accuracy: 0.9474 - 479ms/epoch - 4ms/step\n",
      "Epoch 862/1000\n",
      "125/125 - 0s - loss: 0.0629 - my_accuracy: 0.9478 - val_loss: 0.0543 - val_my_accuracy: 0.9543 - 493ms/epoch - 4ms/step\n",
      "Epoch 863/1000\n",
      "125/125 - 0s - loss: 0.0603 - my_accuracy: 0.9516 - val_loss: 0.0547 - val_my_accuracy: 0.9582 - 482ms/epoch - 4ms/step\n",
      "Epoch 864/1000\n",
      "125/125 - 1s - loss: 0.0576 - my_accuracy: 0.9530 - val_loss: 0.0679 - val_my_accuracy: 0.9413 - 517ms/epoch - 4ms/step\n",
      "Epoch 865/1000\n",
      "125/125 - 1s - loss: 0.0596 - my_accuracy: 0.9505 - val_loss: 0.0532 - val_my_accuracy: 0.9589 - 602ms/epoch - 5ms/step\n",
      "Epoch 866/1000\n",
      "125/125 - 1s - loss: 0.0633 - my_accuracy: 0.9470 - val_loss: 0.0566 - val_my_accuracy: 0.9554 - 543ms/epoch - 4ms/step\n",
      "Epoch 867/1000\n",
      "125/125 - 1s - loss: 0.0594 - my_accuracy: 0.9507 - val_loss: 0.0527 - val_my_accuracy: 0.9590 - 519ms/epoch - 4ms/step\n",
      "Epoch 868/1000\n",
      "125/125 - 0s - loss: 0.0616 - my_accuracy: 0.9489 - val_loss: 0.0776 - val_my_accuracy: 0.9377 - 486ms/epoch - 4ms/step\n",
      "Epoch 869/1000\n",
      "125/125 - 0s - loss: 0.0575 - my_accuracy: 0.9532 - val_loss: 0.0580 - val_my_accuracy: 0.9547 - 481ms/epoch - 4ms/step\n",
      "Epoch 870/1000\n",
      "125/125 - 0s - loss: 0.0601 - my_accuracy: 0.9508 - val_loss: 0.0563 - val_my_accuracy: 0.9521 - 460ms/epoch - 4ms/step\n",
      "Epoch 871/1000\n",
      "125/125 - 1s - loss: 0.0601 - my_accuracy: 0.9501 - val_loss: 0.0555 - val_my_accuracy: 0.9576 - 548ms/epoch - 4ms/step\n",
      "Epoch 872/1000\n",
      "125/125 - 1s - loss: 0.0597 - my_accuracy: 0.9504 - val_loss: 0.0587 - val_my_accuracy: 0.9493 - 513ms/epoch - 4ms/step\n",
      "Epoch 873/1000\n",
      "125/125 - 0s - loss: 0.0640 - my_accuracy: 0.9468 - val_loss: 0.0639 - val_my_accuracy: 0.9471 - 466ms/epoch - 4ms/step\n",
      "Epoch 874/1000\n",
      "125/125 - 0s - loss: 0.0615 - my_accuracy: 0.9491 - val_loss: 0.0663 - val_my_accuracy: 0.9445 - 487ms/epoch - 4ms/step\n",
      "Epoch 875/1000\n",
      "125/125 - 0s - loss: 0.0608 - my_accuracy: 0.9493 - val_loss: 0.0520 - val_my_accuracy: 0.9602 - 492ms/epoch - 4ms/step\n",
      "Epoch 876/1000\n",
      "125/125 - 0s - loss: 0.0578 - my_accuracy: 0.9521 - val_loss: 0.0612 - val_my_accuracy: 0.9472 - 452ms/epoch - 4ms/step\n",
      "Epoch 877/1000\n",
      "125/125 - 1s - loss: 0.0587 - my_accuracy: 0.9512 - val_loss: 0.0603 - val_my_accuracy: 0.9503 - 509ms/epoch - 4ms/step\n",
      "Epoch 878/1000\n",
      "125/125 - 1s - loss: 0.0612 - my_accuracy: 0.9487 - val_loss: 0.0621 - val_my_accuracy: 0.9479 - 532ms/epoch - 4ms/step\n",
      "Epoch 879/1000\n",
      "125/125 - 0s - loss: 0.0586 - my_accuracy: 0.9520 - val_loss: 0.0527 - val_my_accuracy: 0.9598 - 498ms/epoch - 4ms/step\n",
      "Epoch 880/1000\n",
      "125/125 - 0s - loss: 0.0581 - my_accuracy: 0.9515 - val_loss: 0.0659 - val_my_accuracy: 0.9459 - 497ms/epoch - 4ms/step\n",
      "Epoch 881/1000\n",
      "125/125 - 0s - loss: 0.0577 - my_accuracy: 0.9525 - val_loss: 0.0523 - val_my_accuracy: 0.9590 - 464ms/epoch - 4ms/step\n",
      "Epoch 882/1000\n",
      "125/125 - 0s - loss: 0.0594 - my_accuracy: 0.9515 - val_loss: 0.0543 - val_my_accuracy: 0.9568 - 493ms/epoch - 4ms/step\n",
      "Epoch 883/1000\n",
      "125/125 - 1s - loss: 0.0588 - my_accuracy: 0.9509 - val_loss: 0.0596 - val_my_accuracy: 0.9512 - 505ms/epoch - 4ms/step\n",
      "Epoch 884/1000\n",
      "125/125 - 1s - loss: 0.0588 - my_accuracy: 0.9521 - val_loss: 0.0567 - val_my_accuracy: 0.9534 - 514ms/epoch - 4ms/step\n",
      "Epoch 885/1000\n",
      "125/125 - 1s - loss: 0.0595 - my_accuracy: 0.9513 - val_loss: 0.0578 - val_my_accuracy: 0.9527 - 532ms/epoch - 4ms/step\n",
      "Epoch 886/1000\n",
      "125/125 - 0s - loss: 0.0594 - my_accuracy: 0.9514 - val_loss: 0.0581 - val_my_accuracy: 0.9538 - 478ms/epoch - 4ms/step\n",
      "Epoch 887/1000\n",
      "125/125 - 0s - loss: 0.0594 - my_accuracy: 0.9506 - val_loss: 0.0568 - val_my_accuracy: 0.9543 - 495ms/epoch - 4ms/step\n",
      "Epoch 888/1000\n",
      "125/125 - 1s - loss: 0.0577 - my_accuracy: 0.9522 - val_loss: 0.0555 - val_my_accuracy: 0.9568 - 523ms/epoch - 4ms/step\n",
      "Epoch 889/1000\n",
      "125/125 - 1s - loss: 0.0585 - my_accuracy: 0.9514 - val_loss: 0.0567 - val_my_accuracy: 0.9533 - 598ms/epoch - 5ms/step\n",
      "Epoch 890/1000\n",
      "125/125 - 1s - loss: 0.0572 - my_accuracy: 0.9529 - val_loss: 0.0581 - val_my_accuracy: 0.9519 - 552ms/epoch - 4ms/step\n",
      "Epoch 891/1000\n",
      "125/125 - 1s - loss: 0.0597 - my_accuracy: 0.9501 - val_loss: 0.0520 - val_my_accuracy: 0.9597 - 515ms/epoch - 4ms/step\n",
      "Epoch 892/1000\n",
      "125/125 - 1s - loss: 0.0570 - my_accuracy: 0.9538 - val_loss: 0.0552 - val_my_accuracy: 0.9558 - 566ms/epoch - 5ms/step\n",
      "Epoch 893/1000\n",
      "125/125 - 0s - loss: 0.0590 - my_accuracy: 0.9507 - val_loss: 0.0567 - val_my_accuracy: 0.9551 - 484ms/epoch - 4ms/step\n",
      "Epoch 894/1000\n",
      "125/125 - 0s - loss: 0.0633 - my_accuracy: 0.9467 - val_loss: 0.0597 - val_my_accuracy: 0.9500 - 487ms/epoch - 4ms/step\n",
      "Epoch 895/1000\n",
      "125/125 - 1s - loss: 0.0579 - my_accuracy: 0.9522 - val_loss: 0.0594 - val_my_accuracy: 0.9524 - 517ms/epoch - 4ms/step\n",
      "Epoch 896/1000\n",
      "125/125 - 1s - loss: 0.0586 - my_accuracy: 0.9518 - val_loss: 0.0536 - val_my_accuracy: 0.9576 - 528ms/epoch - 4ms/step\n",
      "Epoch 897/1000\n",
      "125/125 - 1s - loss: 0.0597 - my_accuracy: 0.9510 - val_loss: 0.0549 - val_my_accuracy: 0.9559 - 594ms/epoch - 5ms/step\n",
      "Epoch 898/1000\n",
      "125/125 - 1s - loss: 0.0567 - my_accuracy: 0.9532 - val_loss: 0.0626 - val_my_accuracy: 0.9479 - 693ms/epoch - 6ms/step\n",
      "Epoch 899/1000\n",
      "125/125 - 1s - loss: 0.0604 - my_accuracy: 0.9497 - val_loss: 0.0551 - val_my_accuracy: 0.9562 - 681ms/epoch - 5ms/step\n",
      "Epoch 900/1000\n",
      "125/125 - 1s - loss: 0.0590 - my_accuracy: 0.9515 - val_loss: 0.0567 - val_my_accuracy: 0.9539 - 718ms/epoch - 6ms/step\n",
      "Epoch 901/1000\n",
      "125/125 - 1s - loss: 0.0604 - my_accuracy: 0.9501 - val_loss: 0.0659 - val_my_accuracy: 0.9449 - 754ms/epoch - 6ms/step\n",
      "Epoch 902/1000\n",
      "125/125 - 1s - loss: 0.0607 - my_accuracy: 0.9502 - val_loss: 0.0524 - val_my_accuracy: 0.9606 - 743ms/epoch - 6ms/step\n",
      "Epoch 903/1000\n",
      "125/125 - 1s - loss: 0.0561 - my_accuracy: 0.9545 - val_loss: 0.0602 - val_my_accuracy: 0.9521 - 648ms/epoch - 5ms/step\n",
      "Epoch 904/1000\n",
      "125/125 - 1s - loss: 0.0608 - my_accuracy: 0.9501 - val_loss: 0.0544 - val_my_accuracy: 0.9565 - 721ms/epoch - 6ms/step\n",
      "Epoch 905/1000\n",
      "125/125 - 1s - loss: 0.0564 - my_accuracy: 0.9540 - val_loss: 0.0580 - val_my_accuracy: 0.9514 - 795ms/epoch - 6ms/step\n",
      "Epoch 906/1000\n",
      "125/125 - 1s - loss: 0.0558 - my_accuracy: 0.9545 - val_loss: 0.0549 - val_my_accuracy: 0.9561 - 701ms/epoch - 6ms/step\n",
      "Epoch 907/1000\n",
      "125/125 - 1s - loss: 0.0601 - my_accuracy: 0.9498 - val_loss: 0.0588 - val_my_accuracy: 0.9511 - 768ms/epoch - 6ms/step\n",
      "Epoch 908/1000\n",
      "125/125 - 1s - loss: 0.0593 - my_accuracy: 0.9509 - val_loss: 0.0742 - val_my_accuracy: 0.9392 - 629ms/epoch - 5ms/step\n",
      "Epoch 909/1000\n",
      "125/125 - 1s - loss: 0.0620 - my_accuracy: 0.9480 - val_loss: 0.0645 - val_my_accuracy: 0.9457 - 503ms/epoch - 4ms/step\n",
      "Epoch 910/1000\n",
      "125/125 - 1s - loss: 0.0600 - my_accuracy: 0.9495 - val_loss: 0.0501 - val_my_accuracy: 0.9621 - 533ms/epoch - 4ms/step\n",
      "Epoch 911/1000\n",
      "125/125 - 1s - loss: 0.0560 - my_accuracy: 0.9542 - val_loss: 0.0581 - val_my_accuracy: 0.9501 - 558ms/epoch - 4ms/step\n",
      "Epoch 912/1000\n",
      "125/125 - 1s - loss: 0.0568 - my_accuracy: 0.9530 - val_loss: 0.0571 - val_my_accuracy: 0.9537 - 546ms/epoch - 4ms/step\n",
      "Epoch 913/1000\n",
      "125/125 - 1s - loss: 0.0573 - my_accuracy: 0.9533 - val_loss: 0.0524 - val_my_accuracy: 0.9573 - 542ms/epoch - 4ms/step\n",
      "Epoch 914/1000\n",
      "125/125 - 1s - loss: 0.0587 - my_accuracy: 0.9510 - val_loss: 0.0544 - val_my_accuracy: 0.9554 - 555ms/epoch - 4ms/step\n",
      "Epoch 915/1000\n",
      "125/125 - 1s - loss: 0.0573 - my_accuracy: 0.9525 - val_loss: 0.0535 - val_my_accuracy: 0.9571 - 570ms/epoch - 5ms/step\n",
      "Epoch 916/1000\n",
      "125/125 - 1s - loss: 0.0595 - my_accuracy: 0.9505 - val_loss: 0.0560 - val_my_accuracy: 0.9545 - 571ms/epoch - 5ms/step\n",
      "Epoch 917/1000\n",
      "125/125 - 1s - loss: 0.0598 - my_accuracy: 0.9507 - val_loss: 0.0602 - val_my_accuracy: 0.9501 - 542ms/epoch - 4ms/step\n",
      "Epoch 918/1000\n",
      "125/125 - 0s - loss: 0.0586 - my_accuracy: 0.9509 - val_loss: 0.0545 - val_my_accuracy: 0.9557 - 476ms/epoch - 4ms/step\n",
      "Epoch 919/1000\n",
      "125/125 - 0s - loss: 0.0569 - my_accuracy: 0.9527 - val_loss: 0.0598 - val_my_accuracy: 0.9510 - 493ms/epoch - 4ms/step\n",
      "Epoch 920/1000\n",
      "125/125 - 1s - loss: 0.0605 - my_accuracy: 0.9502 - val_loss: 0.0867 - val_my_accuracy: 0.9308 - 550ms/epoch - 4ms/step\n",
      "Epoch 921/1000\n",
      "125/125 - 1s - loss: 0.0595 - my_accuracy: 0.9507 - val_loss: 0.0557 - val_my_accuracy: 0.9547 - 672ms/epoch - 5ms/step\n",
      "Epoch 922/1000\n",
      "125/125 - 1s - loss: 0.0573 - my_accuracy: 0.9523 - val_loss: 0.0605 - val_my_accuracy: 0.9489 - 763ms/epoch - 6ms/step\n",
      "Epoch 923/1000\n",
      "125/125 - 1s - loss: 0.0602 - my_accuracy: 0.9495 - val_loss: 0.0571 - val_my_accuracy: 0.9518 - 721ms/epoch - 6ms/step\n",
      "Epoch 924/1000\n",
      "125/125 - 1s - loss: 0.0624 - my_accuracy: 0.9483 - val_loss: 0.1090 - val_my_accuracy: 0.9151 - 548ms/epoch - 4ms/step\n",
      "Epoch 925/1000\n",
      "125/125 - 1s - loss: 0.0598 - my_accuracy: 0.9513 - val_loss: 0.0570 - val_my_accuracy: 0.9543 - 517ms/epoch - 4ms/step\n",
      "Epoch 926/1000\n",
      "125/125 - 1s - loss: 0.0564 - my_accuracy: 0.9541 - val_loss: 0.0554 - val_my_accuracy: 0.9547 - 587ms/epoch - 5ms/step\n",
      "Epoch 927/1000\n",
      "125/125 - 1s - loss: 0.0578 - my_accuracy: 0.9511 - val_loss: 0.0524 - val_my_accuracy: 0.9578 - 683ms/epoch - 5ms/step\n",
      "Epoch 928/1000\n",
      "125/125 - 1s - loss: 0.0568 - my_accuracy: 0.9528 - val_loss: 0.0546 - val_my_accuracy: 0.9573 - 716ms/epoch - 6ms/step\n",
      "Epoch 929/1000\n",
      "125/125 - 1s - loss: 0.0609 - my_accuracy: 0.9484 - val_loss: 0.0539 - val_my_accuracy: 0.9566 - 629ms/epoch - 5ms/step\n",
      "Epoch 930/1000\n",
      "125/125 - 0s - loss: 0.0579 - my_accuracy: 0.9518 - val_loss: 0.0608 - val_my_accuracy: 0.9522 - 484ms/epoch - 4ms/step\n",
      "Epoch 931/1000\n",
      "125/125 - 0s - loss: 0.0611 - my_accuracy: 0.9499 - val_loss: 0.0964 - val_my_accuracy: 0.9247 - 460ms/epoch - 4ms/step\n",
      "Epoch 932/1000\n",
      "125/125 - 0s - loss: 0.0603 - my_accuracy: 0.9500 - val_loss: 0.0547 - val_my_accuracy: 0.9559 - 405ms/epoch - 3ms/step\n",
      "Epoch 933/1000\n",
      "125/125 - 0s - loss: 0.0625 - my_accuracy: 0.9479 - val_loss: 0.0538 - val_my_accuracy: 0.9567 - 451ms/epoch - 4ms/step\n",
      "Epoch 934/1000\n",
      "125/125 - 0s - loss: 0.0568 - my_accuracy: 0.9526 - val_loss: 0.0590 - val_my_accuracy: 0.9521 - 445ms/epoch - 4ms/step\n",
      "Epoch 935/1000\n",
      "125/125 - 1s - loss: 0.0560 - my_accuracy: 0.9538 - val_loss: 0.0685 - val_my_accuracy: 0.9417 - 527ms/epoch - 4ms/step\n",
      "Epoch 936/1000\n",
      "125/125 - 0s - loss: 0.0571 - my_accuracy: 0.9530 - val_loss: 0.0608 - val_my_accuracy: 0.9500 - 471ms/epoch - 4ms/step\n",
      "Epoch 937/1000\n",
      "125/125 - 0s - loss: 0.0588 - my_accuracy: 0.9512 - val_loss: 0.0571 - val_my_accuracy: 0.9550 - 452ms/epoch - 4ms/step\n",
      "Epoch 938/1000\n",
      "125/125 - 0s - loss: 0.0647 - my_accuracy: 0.9459 - val_loss: 0.0628 - val_my_accuracy: 0.9475 - 476ms/epoch - 4ms/step\n",
      "Epoch 939/1000\n",
      "125/125 - 1s - loss: 0.0550 - my_accuracy: 0.9551 - val_loss: 0.0565 - val_my_accuracy: 0.9543 - 505ms/epoch - 4ms/step\n",
      "Epoch 940/1000\n",
      "125/125 - 0s - loss: 0.0575 - my_accuracy: 0.9520 - val_loss: 0.0544 - val_my_accuracy: 0.9582 - 443ms/epoch - 4ms/step\n",
      "Epoch 941/1000\n",
      "125/125 - 1s - loss: 0.0572 - my_accuracy: 0.9515 - val_loss: 0.0550 - val_my_accuracy: 0.9556 - 538ms/epoch - 4ms/step\n",
      "Epoch 942/1000\n",
      "125/125 - 1s - loss: 0.0561 - my_accuracy: 0.9536 - val_loss: 0.0662 - val_my_accuracy: 0.9460 - 548ms/epoch - 4ms/step\n",
      "Epoch 943/1000\n",
      "125/125 - 0s - loss: 0.0612 - my_accuracy: 0.9487 - val_loss: 0.0548 - val_my_accuracy: 0.9557 - 419ms/epoch - 3ms/step\n",
      "Epoch 944/1000\n",
      "125/125 - 0s - loss: 0.0593 - my_accuracy: 0.9508 - val_loss: 0.0807 - val_my_accuracy: 0.9324 - 449ms/epoch - 4ms/step\n",
      "Epoch 945/1000\n",
      "125/125 - 0s - loss: 0.0602 - my_accuracy: 0.9498 - val_loss: 0.0565 - val_my_accuracy: 0.9529 - 462ms/epoch - 4ms/step\n",
      "Epoch 946/1000\n",
      "125/125 - 0s - loss: 0.0573 - my_accuracy: 0.9535 - val_loss: 0.0589 - val_my_accuracy: 0.9529 - 431ms/epoch - 3ms/step\n",
      "Epoch 947/1000\n",
      "125/125 - 0s - loss: 0.0568 - my_accuracy: 0.9530 - val_loss: 0.0593 - val_my_accuracy: 0.9492 - 411ms/epoch - 3ms/step\n",
      "Epoch 948/1000\n",
      "125/125 - 0s - loss: 0.0566 - my_accuracy: 0.9522 - val_loss: 0.0522 - val_my_accuracy: 0.9584 - 462ms/epoch - 4ms/step\n",
      "Epoch 949/1000\n",
      "125/125 - 0s - loss: 0.0596 - my_accuracy: 0.9500 - val_loss: 0.0587 - val_my_accuracy: 0.9517 - 436ms/epoch - 3ms/step\n",
      "Epoch 950/1000\n",
      "125/125 - 0s - loss: 0.0575 - my_accuracy: 0.9518 - val_loss: 0.0681 - val_my_accuracy: 0.9487 - 438ms/epoch - 4ms/step\n",
      "Epoch 951/1000\n",
      "125/125 - 0s - loss: 0.0588 - my_accuracy: 0.9503 - val_loss: 0.0571 - val_my_accuracy: 0.9551 - 492ms/epoch - 4ms/step\n",
      "Epoch 952/1000\n",
      "125/125 - 0s - loss: 0.0579 - my_accuracy: 0.9520 - val_loss: 0.0518 - val_my_accuracy: 0.9584 - 425ms/epoch - 3ms/step\n",
      "Epoch 953/1000\n",
      "125/125 - 0s - loss: 0.0610 - my_accuracy: 0.9487 - val_loss: 0.0599 - val_my_accuracy: 0.9493 - 422ms/epoch - 3ms/step\n",
      "Epoch 954/1000\n",
      "125/125 - 1s - loss: 0.0563 - my_accuracy: 0.9531 - val_loss: 0.0618 - val_my_accuracy: 0.9507 - 510ms/epoch - 4ms/step\n",
      "Epoch 955/1000\n",
      "125/125 - 1s - loss: 0.0579 - my_accuracy: 0.9516 - val_loss: 0.0613 - val_my_accuracy: 0.9471 - 553ms/epoch - 4ms/step\n",
      "Epoch 956/1000\n",
      "125/125 - 0s - loss: 0.0578 - my_accuracy: 0.9527 - val_loss: 0.0570 - val_my_accuracy: 0.9536 - 450ms/epoch - 4ms/step\n",
      "Epoch 957/1000\n",
      "125/125 - 0s - loss: 0.0591 - my_accuracy: 0.9515 - val_loss: 0.0503 - val_my_accuracy: 0.9595 - 477ms/epoch - 4ms/step\n",
      "Epoch 958/1000\n",
      "125/125 - 0s - loss: 0.0552 - my_accuracy: 0.9551 - val_loss: 0.0511 - val_my_accuracy: 0.9601 - 411ms/epoch - 3ms/step\n",
      "Epoch 959/1000\n",
      "125/125 - 0s - loss: 0.0591 - my_accuracy: 0.9509 - val_loss: 0.0612 - val_my_accuracy: 0.9498 - 456ms/epoch - 4ms/step\n",
      "Epoch 960/1000\n",
      "125/125 - 0s - loss: 0.0588 - my_accuracy: 0.9507 - val_loss: 0.0580 - val_my_accuracy: 0.9528 - 435ms/epoch - 3ms/step\n",
      "Epoch 961/1000\n",
      "125/125 - 0s - loss: 0.0596 - my_accuracy: 0.9507 - val_loss: 0.0521 - val_my_accuracy: 0.9586 - 431ms/epoch - 3ms/step\n",
      "Epoch 962/1000\n",
      "125/125 - 0s - loss: 0.0560 - my_accuracy: 0.9542 - val_loss: 0.0643 - val_my_accuracy: 0.9487 - 430ms/epoch - 3ms/step\n",
      "Epoch 963/1000\n",
      "125/125 - 0s - loss: 0.0604 - my_accuracy: 0.9490 - val_loss: 0.0621 - val_my_accuracy: 0.9474 - 469ms/epoch - 4ms/step\n",
      "Epoch 964/1000\n",
      "125/125 - 0s - loss: 0.0562 - my_accuracy: 0.9532 - val_loss: 0.0554 - val_my_accuracy: 0.9556 - 406ms/epoch - 3ms/step\n",
      "Epoch 965/1000\n",
      "125/125 - 0s - loss: 0.0596 - my_accuracy: 0.9495 - val_loss: 0.0650 - val_my_accuracy: 0.9426 - 457ms/epoch - 4ms/step\n",
      "Epoch 966/1000\n",
      "125/125 - 0s - loss: 0.0588 - my_accuracy: 0.9497 - val_loss: 0.0538 - val_my_accuracy: 0.9583 - 462ms/epoch - 4ms/step\n",
      "Epoch 967/1000\n",
      "125/125 - 0s - loss: 0.0576 - my_accuracy: 0.9522 - val_loss: 0.0620 - val_my_accuracy: 0.9464 - 447ms/epoch - 4ms/step\n",
      "Epoch 968/1000\n",
      "125/125 - 0s - loss: 0.0589 - my_accuracy: 0.9514 - val_loss: 0.0533 - val_my_accuracy: 0.9581 - 419ms/epoch - 3ms/step\n",
      "Epoch 969/1000\n",
      "125/125 - 0s - loss: 0.0566 - my_accuracy: 0.9526 - val_loss: 0.0498 - val_my_accuracy: 0.9612 - 409ms/epoch - 3ms/step\n",
      "Epoch 970/1000\n",
      "125/125 - 1s - loss: 0.0560 - my_accuracy: 0.9538 - val_loss: 0.0557 - val_my_accuracy: 0.9541 - 554ms/epoch - 4ms/step\n",
      "Epoch 971/1000\n",
      "125/125 - 0s - loss: 0.0542 - my_accuracy: 0.9558 - val_loss: 0.0534 - val_my_accuracy: 0.9569 - 457ms/epoch - 4ms/step\n",
      "Epoch 972/1000\n",
      "125/125 - 0s - loss: 0.0569 - my_accuracy: 0.9530 - val_loss: 0.0636 - val_my_accuracy: 0.9477 - 465ms/epoch - 4ms/step\n",
      "Epoch 973/1000\n",
      "125/125 - 0s - loss: 0.0589 - my_accuracy: 0.9505 - val_loss: 0.0614 - val_my_accuracy: 0.9482 - 427ms/epoch - 3ms/step\n",
      "Epoch 974/1000\n",
      "125/125 - 0s - loss: 0.0560 - my_accuracy: 0.9531 - val_loss: 0.0658 - val_my_accuracy: 0.9451 - 463ms/epoch - 4ms/step\n",
      "Epoch 975/1000\n",
      "125/125 - 0s - loss: 0.0569 - my_accuracy: 0.9535 - val_loss: 0.0533 - val_my_accuracy: 0.9583 - 420ms/epoch - 3ms/step\n",
      "Epoch 976/1000\n",
      "125/125 - 0s - loss: 0.0569 - my_accuracy: 0.9531 - val_loss: 0.0546 - val_my_accuracy: 0.9552 - 433ms/epoch - 3ms/step\n",
      "Epoch 977/1000\n",
      "125/125 - 1s - loss: 0.0593 - my_accuracy: 0.9506 - val_loss: 0.0534 - val_my_accuracy: 0.9568 - 526ms/epoch - 4ms/step\n",
      "Epoch 978/1000\n",
      "125/125 - 1s - loss: 0.0566 - my_accuracy: 0.9530 - val_loss: 0.0607 - val_my_accuracy: 0.9512 - 508ms/epoch - 4ms/step\n",
      "Epoch 979/1000\n",
      "125/125 - 1s - loss: 0.0577 - my_accuracy: 0.9523 - val_loss: 0.0649 - val_my_accuracy: 0.9492 - 516ms/epoch - 4ms/step\n",
      "Epoch 980/1000\n",
      "125/125 - 1s - loss: 0.0631 - my_accuracy: 0.9474 - val_loss: 0.0565 - val_my_accuracy: 0.9522 - 556ms/epoch - 4ms/step\n",
      "Epoch 981/1000\n",
      "125/125 - 0s - loss: 0.0555 - my_accuracy: 0.9544 - val_loss: 0.0517 - val_my_accuracy: 0.9594 - 460ms/epoch - 4ms/step\n",
      "Epoch 982/1000\n",
      "125/125 - 0s - loss: 0.0555 - my_accuracy: 0.9542 - val_loss: 0.0591 - val_my_accuracy: 0.9498 - 419ms/epoch - 3ms/step\n",
      "Epoch 983/1000\n",
      "125/125 - 0s - loss: 0.0602 - my_accuracy: 0.9495 - val_loss: 0.0616 - val_my_accuracy: 0.9491 - 432ms/epoch - 3ms/step\n",
      "Epoch 984/1000\n",
      "125/125 - 0s - loss: 0.0599 - my_accuracy: 0.9505 - val_loss: 0.0729 - val_my_accuracy: 0.9408 - 442ms/epoch - 4ms/step\n",
      "Epoch 985/1000\n",
      "125/125 - 0s - loss: 0.0585 - my_accuracy: 0.9508 - val_loss: 0.0538 - val_my_accuracy: 0.9568 - 417ms/epoch - 3ms/step\n",
      "Epoch 986/1000\n",
      "125/125 - 0s - loss: 0.0558 - my_accuracy: 0.9531 - val_loss: 0.0588 - val_my_accuracy: 0.9520 - 439ms/epoch - 4ms/step\n",
      "Epoch 987/1000\n",
      "125/125 - 0s - loss: 0.0595 - my_accuracy: 0.9498 - val_loss: 0.0558 - val_my_accuracy: 0.9539 - 450ms/epoch - 4ms/step\n",
      "Epoch 988/1000\n",
      "125/125 - 0s - loss: 0.0571 - my_accuracy: 0.9518 - val_loss: 0.0526 - val_my_accuracy: 0.9583 - 428ms/epoch - 3ms/step\n",
      "Epoch 989/1000\n",
      "125/125 - 0s - loss: 0.0598 - my_accuracy: 0.9510 - val_loss: 0.0562 - val_my_accuracy: 0.9525 - 410ms/epoch - 3ms/step\n",
      "Epoch 990/1000\n",
      "125/125 - 0s - loss: 0.0611 - my_accuracy: 0.9492 - val_loss: 0.0573 - val_my_accuracy: 0.9506 - 460ms/epoch - 4ms/step\n",
      "Epoch 991/1000\n",
      "125/125 - 0s - loss: 0.0568 - my_accuracy: 0.9521 - val_loss: 0.0675 - val_my_accuracy: 0.9460 - 402ms/epoch - 3ms/step\n",
      "Epoch 992/1000\n",
      "125/125 - 0s - loss: 0.0585 - my_accuracy: 0.9509 - val_loss: 0.0575 - val_my_accuracy: 0.9532 - 462ms/epoch - 4ms/step\n",
      "Epoch 993/1000\n",
      "125/125 - 0s - loss: 0.0556 - my_accuracy: 0.9533 - val_loss: 0.0531 - val_my_accuracy: 0.9573 - 403ms/epoch - 3ms/step\n",
      "Epoch 994/1000\n",
      "125/125 - 0s - loss: 0.0574 - my_accuracy: 0.9528 - val_loss: 0.0614 - val_my_accuracy: 0.9500 - 445ms/epoch - 4ms/step\n",
      "Epoch 995/1000\n",
      "125/125 - 0s - loss: 0.0571 - my_accuracy: 0.9524 - val_loss: 0.0577 - val_my_accuracy: 0.9525 - 448ms/epoch - 4ms/step\n",
      "Epoch 996/1000\n",
      "125/125 - 0s - loss: 0.0603 - my_accuracy: 0.9500 - val_loss: 0.0523 - val_my_accuracy: 0.9575 - 429ms/epoch - 3ms/step\n",
      "Epoch 997/1000\n",
      "125/125 - 0s - loss: 0.0546 - my_accuracy: 0.9544 - val_loss: 0.0545 - val_my_accuracy: 0.9539 - 454ms/epoch - 4ms/step\n",
      "Epoch 998/1000\n",
      "125/125 - 0s - loss: 0.0601 - my_accuracy: 0.9491 - val_loss: 0.0555 - val_my_accuracy: 0.9543 - 481ms/epoch - 4ms/step\n",
      "Epoch 999/1000\n",
      "125/125 - 0s - loss: 0.0582 - my_accuracy: 0.9510 - val_loss: 0.0571 - val_my_accuracy: 0.9504 - 416ms/epoch - 3ms/step\n",
      "Epoch 1000/1000\n",
      "125/125 - 0s - loss: 0.0574 - my_accuracy: 0.9512 - val_loss: 0.0568 - val_my_accuracy: 0.9534 - 431ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "batchsize = 512\n",
    "history = first_model.fit(x= x_train, y= y_train, batch_size=batchsize, epochs=1000, validation_split=0.2, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "outputs": [],
   "source": [
    "# create test with new generated data\n",
    "x_test, y_test, grid_test = generate_data_grid(20000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.060111064463853836\n",
      "My Accuracy:  0.9501000046730042\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test data\n",
    "loss, my_accuracy_score = first_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Loss: ', loss)\n",
    "print('My Accuracy: ', my_accuracy_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code creates a new model by taking the input and output of the first_model and passing the output through the Lambda(transform) function. This applies the transform function on the output of the first_model changing the accuracy metric to the one of the second model.\n",
    "Finally, it evaluates the second model on the test data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create the second model\n",
    "second_model = Model(inputs=first_model.input,outputs=Lambda(transform)(first_model.output))\n",
    "second_model.compile(optimizer=my_optimizer, loss=['categorical_crossentropy'], metrics=my_accuracy_grid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.8042952418327332\n",
      "My Accuracy:  0.9501000046730042\n"
     ]
    }
   ],
   "source": [
    "loss, my_accuracy_score = second_model.evaluate(x_test, grid_test, verbose=0)\n",
    "print('Loss: ',loss)\n",
    "print('My Accuracy: ',my_accuracy_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}